# Tests d'IntÃ©gration - Let's Go PredictionDex

Ce dossier contient tous les tests d'intÃ©gration pour valider le fonctionnement complet du systÃ¨me.

## ğŸ“‹ Tests Disponibles

### 1. **test_complete_system.py**
Validation complÃ¨te du systÃ¨me end-to-end.

**Ce qui est testÃ©**:
- âœ… 7 services Docker (PostgreSQL, API, Streamlit, MLflow, Prometheus, Grafana, pgAdmin)
- âœ… Stack monitoring (Prometheus targets, mÃ©triques, Grafana dashboards)
- âœ… MLflow (expÃ©riences, Model Registry, runs)
- âœ… API endpoints (health, Pokemon, moves, types, predictions)
- âœ… Base de donnÃ©es (188 Pokemon, 226 moves, 18 types)

**Usage**:
```bash
# Depuis l'hÃ´te
python3 tests/integration/test_complete_system.py

# Via Docker
docker compose --profile tests up tests
```

**RÃ©sultat attendu**: Score â‰¥ 95% (51/52 tests)

---

### 2. **test_monitoring_complete.py**
Test d'intÃ©gration complet de la stack monitoring.

**Ce qui est testÃ©**:
- âœ… Services (Prometheus, Grafana, API, MLflow)
- âœ… Collecte de mÃ©triques (via gÃ©nÃ©ration de trafic API)
- âœ… RequÃªtes Prometheus (mÃ©triques, percentiles, alertes)
- âœ… Dashboards Grafana (datasource, panels, variables)
- âœ… Calcul des percentiles (P50, P95, P99) - sans NaN

**Usage**:
```bash
python3 tests/integration/test_monitoring_complete.py
```

**RÃ©sultat attendu**: Score â‰¥ 80% (17/18 tests)

---

### 3. **test_monitoring_validation.py**
Validation du monitoring avec gÃ©nÃ©ration de rapport HTML.

**Ce qui est testÃ©**:
- âœ… Collecte de mÃ©triques Prometheus
- âœ… RequÃªtes PromQL fonctionnelles
- âœ… Percentiles sans NaN
- âœ… GÃ©nÃ©ration de rapport HTML et JSON

**Usage**:
```bash
python3 tests/integration/test_monitoring_validation.py
```

**Rapports gÃ©nÃ©rÃ©s**:
- `reports/monitoring/validation_report.json`
- `reports/monitoring/validation_report.html`

---

### 4. **test_mlflow_to_api.py**
Test d'intÃ©gration entre MLflow et l'API.

**Ce qui est testÃ©**:
- âœ… Chargement du modÃ¨le depuis MLflow Registry
- âœ… PrÃ©dictions via API avec modÃ¨le MLflow
- âœ… CohÃ©rence entre modÃ¨le local et MLflow

**Usage**:
```bash
pytest tests/integration/test_mlflow_to_api.py -v
```

---

## ğŸš€ ExÃ©cution des Tests

### Option 1: ExÃ©cuter tous les tests (recommandÃ©)

```bash
python3 scripts/run_all_tests.py
```

Cette commande exÃ©cute:
1. Tests unitaires (6 suites)
2. Tests d'intÃ©gration (4 tests)
3. Validation systÃ¨me (1 validation complÃ¨te)

**Options disponibles**:
```bash
# Sauter les tests unitaires
python3 scripts/run_all_tests.py --skip-unit

# Sauter les tests d'intÃ©gration
python3 scripts/run_all_tests.py --skip-integration

# ExÃ©cuter via Docker
python3 scripts/run_all_tests.py --docker
```

---

### Option 2: ExÃ©cuter un test spÃ©cifique

```bash
# Test systÃ¨me complet
python3 tests/integration/test_complete_system.py

# Test monitoring
python3 tests/integration/test_monitoring_complete.py

# Test validation
python3 tests/integration/test_monitoring_validation.py

# Test MLflow (avec pytest)
pytest tests/integration/test_mlflow_to_api.py -v
```

---

### Option 3: ExÃ©cuter via Docker

```bash
# DÃ©marrer tous les services + lancer les tests
docker compose --profile tests up --build tests

# Ou en mode dÃ©tachÃ© puis voir les logs
docker compose --profile tests up -d tests
docker logs -f letsgo_tests
```

---

## ğŸ“Š Rapports GÃ©nÃ©rÃ©s

Tous les rapports sont sauvegardÃ©s dans `reports/`:

```
reports/
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ validation_report.html       # Rapport HTML interactif
â”‚   â”œâ”€â”€ validation_report.json       # DonnÃ©es JSON
â”‚   â”œâ”€â”€ monitoring_validation_report.html
â”‚   â””â”€â”€ integration_test_results.json
â””â”€â”€ validation/
    â””â”€â”€ system_validation_report.json  # RÃ©sultats validation systÃ¨me
```

**Consulter les rapports**:
```bash
# Ouvrir le rapport HTML
xdg-open reports/monitoring/validation_report.html

# Voir le score JSON
cat reports/monitoring/validation_report.json | jq '.validation_score'
```

---

## ğŸ”§ PrÃ©requis

### Services Docker requis

Tous les services doivent Ãªtre dÃ©marrÃ©s:
```bash
docker compose up -d
```

VÃ©rifier que les services sont UP:
```bash
docker compose ps
```

Services nÃ©cessaires:
- âœ… `letsgo_postgres` - Base de donnÃ©es
- âœ… `letsgo_api` - API FastAPI
- âœ… `letsgo_streamlit` - Interface web
- âœ… `letsgo_mlflow` - Tracking ML
- âœ… `letsgo_prometheus` - MÃ©triques
- âœ… `letsgo_grafana` - Dashboards
- âœ… `letsgo_pgadmin` - Admin PostgreSQL

### DÃ©pendances Python

```bash
# Installer les dÃ©pendances de test
pip install -r tests/requirements.txt
```

DÃ©pendances principales:
- `pytest` - Framework de tests
- `requests` - Client HTTP
- `psycopg2-binary` - Client PostgreSQL
- `mlflow` - Client MLflow

---

## ğŸ“ˆ CritÃ¨res de SuccÃ¨s

### Validation ComplÃ¨te (test_complete_system.py)

| CatÃ©gorie | Score Attendu |
|-----------|---------------|
| Infrastructure | 7/7 (100%) |
| Monitoring | 13/13 (100%) |
| MLflow | 8/9 (88.9%) |
| API | 10/10 (100%) |
| Database | 3/3 (100%) |
| Predictions | 10/10 (100%) |
| **TOTAL** | **â‰¥ 95%** |

### Monitoring (test_monitoring_complete.py)

| CritÃ¨re | Attendu |
|---------|---------|
| Services UP | 4/4 |
| MÃ©triques collectÃ©es | â‰¥ 5 |
| RequÃªtes Prometheus | â‰¥ 10 |
| Percentiles (P50, P95, P99) | Pas de NaN |
| Dashboards Grafana | 2 dashboards |

---

## ğŸ› DÃ©pannage

### Tests Ã©chouent: "Connection refused"

**ProblÃ¨me**: Les services ne sont pas dÃ©marrÃ©s.

**Solution**:
```bash
docker compose up -d
sleep 30  # Attendre que les services soient prÃªts
python3 tests/integration/test_complete_system.py
```

### Percentiles retournent NaN

**ProblÃ¨me**: Pas assez de trafic API gÃ©nÃ©rÃ©.

**Solution**:
```bash
# GÃ©nÃ©rer du trafic d'abord
python3 scripts/generate_monitoring_data.py

# Puis lancer les tests
python3 tests/integration/test_monitoring_complete.py
```

### MLflow tests Ã©chouent

**ProblÃ¨me**: ModÃ¨le pas enregistrÃ© dans MLflow Registry.

**Solution**:
```bash
# Enregistrer le modÃ¨le v2
python3 scripts/mlflow/enable_mlflow.py

# VÃ©rifier dans MLflow UI
curl http://localhost:5001/health
```

### Tests Docker Ã©chouent Ã  builder

**ProblÃ¨me**: Dockerfile.tests manquant ou invalide.

**Solution**:
```bash
# VÃ©rifier que le Dockerfile existe
ls -la docker/Dockerfile.tests

# Rebuild l'image
docker compose --profile tests build tests

# Relancer
docker compose --profile tests up tests
```

---

## ğŸ“ Notes

- Les tests d'intÃ©gration nÃ©cessitent que **tous les services soient UP**
- GÃ©nÃ©rer du trafic API avant de tester le monitoring
- Les rapports HTML sont auto-contenus (CSS inline)
- Les tests sont idempotents (peuvent Ãªtre relancÃ©s sans effets de bord)

---

## ğŸ¯ Prochaines Ã‰tapes

1. âœ… Tous les tests passent (â‰¥95%)
2. âœ… Rapports gÃ©nÃ©rÃ©s et consultables
3. âœ… DÃ©ploiement CI/CD fonctionnel (GitHub Actions)
4. ğŸš€ **Projet prÃªt pour la certification E1/E3**
