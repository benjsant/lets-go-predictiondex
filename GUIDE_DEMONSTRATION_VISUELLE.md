# üé• Guide de D√©monstration Visuelle - PredictionDex
## Certification E1/E3 - Pr√©sentation Professionnelle

**Objectif:** Montrer visuellement TOUS les composants du projet pour la certification RNCP

**Date:** 27 janvier 2026
**Dur√©e d√©mo:** 30-45 minutes
**Public:** Jury de certification E1/E3

---

## üìã Tableau R√©capitulatif - Composant ‚Üí Outil Visuel

| # | Composant | Type | Outil Visuel | URL / Commande | Preuves E1/E3 |
|---|-----------|------|--------------|----------------|---------------|
| 1 | **Interface Streamlit** | Web UI | Navigateur | http://localhost:8502 | C10 - Int√©gration app |
| 2 | **API REST (Swagger)** | Web UI | Navigateur | http://localhost:8080/docs | C9 - API REST avec IA |
| 3 | **Grafana Dashboards** | Web UI | Navigateur | http://localhost:3001 | C11 - Monitoring IA |
| 4 | **Prometheus Metrics** | Web UI | Navigateur | http://localhost:9091 | C11 - M√©triques temps r√©el |
| 5 | **MLflow UI** | Web UI | Navigateur | http://localhost:5001 | C13 - MLOps CI/CD |
| 6 | **Base PostgreSQL** | Database | Visualisation par API + Requ√™tes | http://localhost:8080/docs | E1.3 - Structurer BDD |
| 7 | **ETL Pipeline** | Backend | Logs Docker format√©s | `docker logs letsgo_etl` | E1.1, E1.2 - Collecte/Nettoyage |
| 8 | **ML Training** | Backend | Logs + Notebooks | `docker logs letsgo_ml` | C12 - Optimiser IA |
| 9 | **Drift Detection** | Backend | Rapports HTML Evidently | `api_pokemon/monitoring/reports/` | C11 - Monitoring IA |
| 10 | **Tests Automatis√©s** | CI/CD | GitHub Actions | https://github.com/.../actions | C13 - MLOps CI/CD |
| 11 | **Notebooks Jupyter** | Data Science | Jupyter Lab / VSCode | `notebooks/` | E1.4 - Exploiter donn√©es |
| 12 | **Documentation** | Documentation | Markdown (GitHub/VSCode) | `README.md`, `docs/` | E1.5 - Documenter processus |

---

## üéØ Plan de D√©monstration (30 minutes)

### Phase 1: Interfaces Web Interactives (12 min)

#### 1.1 Interface Streamlit - Application Utilisateur (4 min)
**URL:** http://localhost:8502
**Objectif:** Montrer l'application finale fonctionnelle (C10)

**Parcours de d√©monstration:**

1. **Page Accueil** (30s)
   - Vue d'ensemble du projet
   - Statistiques cl√©s (188 Pok√©mon, 226 capacit√©s, 94.46% accuracy)
   - Navigation vers fonctionnalit√©s

2. **Page "Combat et Pr√©diction"** (2 min) ‚≠ê **FEATURE PRINCIPALE**
   - S√©lectionner Pok√©mon A (ex: Pikachu #25)
   - S√©lectionner Pok√©mon B (ex: Bulbizarre #1)
   - Choisir 4 capacit√©s pr√©-sugg√©r√©es
   - Cliquer "Pr√©dire le vainqueur"
   - **Montrer:** Pr√©diction ML avec probabilit√©s + recommandation meilleure capacit√©
   - **Temps de r√©ponse:** < 500ms

3. **Page "D√©tails Pok√©mon"** (1 min)
   - Rechercher un Pok√©mon (ex: Dracaufeu)
   - Afficher stats, types, capacit√©s apprises, faiblesses
   - **Montrer:** Feature engineering (multiplicateurs de types)

4. **Page "Capacit√©s"** (30s)
   - Filtrer par type (ex: √âlectrik)
   - Trier par puissance
   - **Montrer:** Catalogue complet des 226 moves

5. **Page "Types et Affinit√©s"** (30s)
   - Matrice 18x18 des affinit√©s
   - **Montrer:** R√®gles m√©tier complexes (324 r√®gles)

**Preuves d√©montr√©es:**
- ‚úÖ C10: Int√©gration applicative frontend/backend
- ‚úÖ C9: API REST consomm√©e par Streamlit
- ‚úÖ E1.4: Exploitation des donn√©es via features

---

#### 1.2 API REST - Swagger UI (3 min)
**URL:** http://localhost:8080/docs
**Objectif:** Montrer l'API RESTful production-ready (C9)

**Parcours de d√©monstration:**

1. **Documentation interactive** (30s)
   - Pr√©senter les 5 groupes d'endpoints
   - Montrer descriptions OpenAPI compl√®tes

2. **Endpoint `/pokemon`** (1 min)
   - Cliquer "Try it out"
   - Ex√©cuter `GET /pokemon?limit=10`
   - **Montrer:** Response JSON structur√© (pagination, filtres)

3. **Endpoint `/predict/best-move`** (1 min 30s) ‚≠ê **CORE ML API**
   - Cliquer "Try it out"
   - Body JSON:
   ```json
   {
     "pokemon_a_id": 25,
     "pokemon_b_id": 1,
     "available_moves": ["Fatal-Foudre", "Vive-Attaque", "Tonnerre", "Cage-√âclair"]
   }
   ```
   - Ex√©cuter la requ√™te
   - **Montrer:**
     - Pr√©dictions pour chaque move
     - Recommandation meilleure capacit√©
     - Temps de r√©ponse < 500ms
     - Probabilit√©s de victoire

4. **Endpoint `/health`** (30s)
   - Montrer health check
   - **Montrer:** API operationnelle, metrics disponibles

**Preuves d√©montr√©es:**
- ‚úÖ C9: API REST avec int√©gration IA
- ‚úÖ C12: Optimisation inf√©rence (<500ms)
- ‚úÖ Documentation API compl√®te (OpenAPI 3.0)

---

#### 1.3 Grafana - Dashboards Monitoring (3 min)
**URL:** http://localhost:3001
**Objectif:** Monitoring temps r√©el de l'API et du mod√®le (C11)

**Parcours de d√©monstration:**

1. **Acc√®s Grafana** (30s)
   - Ouvrir http://localhost:3001
   - Login automatique (anonymous auth enabled)

2. **Dashboard "API Performance"** (1 min 30s) ‚≠ê **DASHBOARD PRINCIPAL**
   - Navigate: Dashboards ‚Üí Let's Go PredictionDex - API Performance
   - **Montrer:**
     - ‚úÖ API Status (UP/DOWN)
     - ‚úÖ Request Rate by Endpoint (req/s)
     - ‚úÖ P95 Latency (< 500ms)
     - ‚úÖ Error Rate (%)
     - ‚úÖ Response Status Codes (200, 404, 500)
   - **Action:** Lancer `generate_monitoring_data.py` en parall√®le pour voir m√©triques live

3. **Dashboard "Model Performance"** (1 min)
   - Navigate: Dashboards ‚Üí Let's Go PredictionDex - Model Performance
   - **Montrer:**
     - ‚úÖ Predictions per Minute
     - ‚úÖ Model Accuracy (%)
     - ‚úÖ Prediction Confidence Distribution
     - ‚úÖ Feature Importance (top 10 features)

**Script pour g√©n√©rer m√©triques live:**
```bash
# Terminal s√©par√©
python scripts/generate_monitoring_data.py --mode realistic --duration 5
```

**Preuves d√©montr√©es:**
- ‚úÖ C11: Monitoring IA en production
- ‚úÖ Prometheus + Grafana stack compl√®te
- ‚úÖ M√©triques m√©tier (accuracy, latency, throughput)

---

#### 1.4 Prometheus - M√©triques Brutes (1 min)
**URL:** http://localhost:9091
**Objectif:** Montrer collecte m√©triques sous-jacente (C11)

**Parcours de d√©monstration:**

1. **Acc√®s Prometheus** (30s)
   - Ouvrir http://localhost:9091
   - Navigate: Status ‚Üí Targets

2. **V√©rifier targets** (30s)
   - **Montrer:**
     - ‚úÖ `api` target: UP (http://api:8080/metrics)
     - ‚úÖ `node-exporter` target: UP
     - ‚úÖ Scrape interval: 15s
   - **Expliquer:** Prometheus scrape API `/metrics` endpoint automatiquement

**Preuves d√©montr√©es:**
- ‚úÖ C11: Infrastructure monitoring
- ‚úÖ Auto-discovery des services via Docker labels

---

#### 1.5 MLflow UI - Model Registry (2 min)
**URL:** http://localhost:5001
**Objectif:** MLOps - Versioning et registry des mod√®les (C13)

**Parcours de d√©monstration:**

1. **Acc√®s MLflow** (30s)
   - Ouvrir http://localhost:5001

2. **Experiments** (1 min)
   - Navigate: Experiments ‚Üí battle_winner_v2
   - **Montrer:**
     - ‚úÖ Liste des runs avec m√©triques (accuracy, f1, precision)
     - ‚úÖ Comparaison entre runs
     - ‚úÖ Hyperparam√®tres track√©s automatiquement
     - ‚úÖ Artifacts (model.pkl, confusion_matrix.png)

3. **Models Registry** (30s)
   - Navigate: Models ‚Üí battle_winner_model
   - **Montrer:**
     - ‚úÖ Versions du mod√®le (v1, v2, v3...)
     - ‚úÖ Stage: Production / Staging / Archived
     - ‚úÖ M√©tadonn√©es: accuracy, dataset version, training date

**Preuves d√©montr√©es:**
- ‚úÖ C13: MLOps - Experiment tracking
- ‚úÖ C13: Model Registry avec versioning
- ‚úÖ C13: Auto-promotion mod√®les (meilleur accuracy ‚Üí Production)

---

### Phase 2: Composants Backend Visuels (10 min)

#### 2.1 Base de Donn√©es PostgreSQL - Via API (3 min)
**Objectif:** Montrer structure BDD sans pgAdmin (E1.3)

**M√©thode 1: Via Swagger UI** ‚≠ê **RECOMMAND√â**

1. **Ouvrir** http://localhost:8080/docs

2. **Explorer tables via endpoints:**

**A. Table `pokemon`**
```bash
GET /pokemon?limit=5
# Montrer: id, name, national_number, height, weight, stats
```

**B. Table `types`**
```bash
GET /types
# Montrer: 18 types avec couleurs
```

**C. Table `moves`**
```bash
GET /moves?limit=5
# Montrer: name, power, accuracy, type, category (Physical/Special)
```

**D. Relations `pokemon_moves`**
```bash
GET /pokemon/25/moves
# Montrer: Capacit√©s apprises par Pikachu avec learn_method
```

**E. Relations `pokemon_types` + `type_effectiveness`**
```bash
GET /pokemon/25/types
# Montrer: Types + faiblesses/r√©sistances calcul√©es
```

**M√©thode 2: Via Requ√™tes SQL directes (optionnel)**
```bash
# Connexion PostgreSQL
docker exec -it letsgo_postgres psql -U letsgo_user -d letsgo_db

# Commandes √† montrer
\dt                          # Liste des 11 tables
\d pokemon                   # Structure table pokemon
SELECT COUNT(*) FROM pokemon; # 188 Pok√©mon
SELECT * FROM type_effectiveness LIMIT 10; # 324 r√®gles
```

**Diagramme √† montrer:** (optionnel - si pr√©par√©)
- Sch√©ma relationnel des 11 tables
- Cl√©s √©trang√®res
- Normalisation 3NF

**Preuves d√©montr√©es:**
- ‚úÖ E1.3: Base de donn√©es structur√©e (11 tables, 3NF)
- ‚úÖ E1.3: Relations (FK, many-to-many via junction tables)
- ‚úÖ E1.2: Donn√©es nettoy√©es et normalis√©es
- ‚úÖ E1.1: 188 Pok√©mon + 226 moves + 324 type rules

---

#### 2.2 ETL Pipeline - Logs Format√©s (3 min)
**Objectif:** Montrer collecte et nettoyage donn√©es (E1.1, E1.2)

**M√©thode: Docker Logs avec formatage color√©**

```bash
# Afficher logs ETL complets
docker logs letsgo_etl --tail 200
```

**Points cl√©s √† montrer dans les logs:**

1. **√âtape 1: Initialisation DB** (30s)
```
üîß [1/5] Initialisation des tables PostgreSQL...
   ‚úÖ Table pokemon cr√©√©e
   ‚úÖ Table types cr√©√©e
   ‚úÖ Table moves cr√©√©e
   ‚úÖ Contraintes FK appliqu√©es
```

2. **√âtape 2: Chargement CSV** (1 min)
```
üì¶ [2/5] Chargement donn√©es CSV (151 Pok√©mon Gen1)...
   ‚úÖ 151 Pok√©mon charg√©s depuis CSV
   ‚ö†Ô∏è  Nettoyage: 3 doublons supprim√©s
   ‚ö†Ô∏è  Validation: 2 stats manquantes interpol√©es
```

3. **√âtape 3: Enrichissement Pok√©API** (1 min)
```
üåê [3/5] Enrichissement via Pok√©API (188 Pok√©mon)...
   ‚úÖ Formes Alola ajout√©es (37 Pok√©mon)
   ‚úÖ Statistiques compl√©t√©es
   ‚úÖ Capacit√©s apprises: 4,248 associations
```

4. **√âtape 4: Scraping Pokepedia** (30s)
```
üï∑Ô∏è [4/5] Scraping √©volutions et affinit√©s (Pokepedia)...
   ‚úÖ Cha√Ænes d'√©volution: 78 liens
   ‚úÖ Affinit√©s de types: 324 r√®gles
```

5. **√âtape 5: Validation finale** (30s)
```
‚úÖ [5/5] Validation des donn√©es...
   ‚úÖ 188 Pok√©mon valides
   ‚úÖ 226 capacit√©s valides
   ‚úÖ 324 r√®gles de types compl√®tes
   ‚úÖ 0 donn√©es manquantes
```

**M√©thode alternative: Script validation**
```bash
# Script Python pour valider ETL
python scripts/validate_docker_stack.py --verbose
```

**Preuves d√©montr√©es:**
- ‚úÖ E1.1: Collecte de donn√©es (3 sources)
- ‚úÖ E1.2: Nettoyage (doublons, valeurs manquantes)
- ‚úÖ E1.2: Validation (contraintes, types)
- ‚úÖ Pipeline automatis√© et reproductible

---

#### 2.3 ML Training - Logs + Notebooks (4 min)
**Objectif:** Montrer entra√Ænement mod√®le et optimisations (C12, C13)

**M√©thode 1: Logs Docker** (2 min)

```bash
# Afficher logs ML training
docker logs letsgo_ml --tail 300
```

**Points cl√©s √† montrer:**

1. **Dataset Generation** (30s)
```
üìä [1/4] G√©n√©ration dataset de combats...
   Mode: all_scenarios (best_move + random_move + all_combinations)
   ‚úÖ 898,472 combats simul√©s
   ‚úÖ Train: 718,889 samples (80%)
   ‚úÖ Test: 179,583 samples (20%)
   ‚úÖ Features: 133 (stats + types + STAB + effectiveness)
```

2. **Model Training** (1 min)
```
ü§ñ [2/4] Entra√Ænement XGBoost Classifier...
   Hyperparams tuning: GridSearchCV (12 combinations)
   ‚è±Ô∏è  Training time: 180s
   ‚úÖ Best params: n_estimators=200, max_depth=8, lr=0.1
   ‚úÖ Train accuracy: 96.24%
```

3. **Model Evaluation** (30s)
```
üìà [3/4] √âvaluation sur test set...
   ‚úÖ Test accuracy: 94.46%
   ‚úÖ Precision: 94.21%
   ‚úÖ Recall: 94.11%
   ‚úÖ F1-score: 94.16%
   ‚úÖ AUC-ROC: 0.9876
```

4. **Model Export** (30s)
```
üíæ [4/4] Export du mod√®le...
   ‚úÖ Mod√®le sauvegard√©: models/battle_winner_model_v2.pkl
   ‚úÖ M√©tadonn√©es: models/battle_winner_model_v2_metadata.json
   ‚úÖ Taille: 2.3 MB (compressed)
   ‚úÖ MLflow: Enregistr√© avec run_id abc123
```

**M√©thode 2: Jupyter Notebooks** (2 min) ‚≠ê **PLUS VISUEL**

```bash
# Ouvrir notebooks dans VSCode ou Jupyter
code notebooks/03_training_evaluation.ipynb
```

**Notebooks √† montrer:**

1. **`01_exploration.ipynb`** (30s)
   - Distribution des stats Pok√©mon
   - Analyse des types (bar charts)
   - Corr√©lations entre features

2. **`02_feature_engineering.ipynb`** (30s)
   - Cr√©ation des 133 features
   - Feature importance (bar chart)
   - STAB et multiplicateurs de types

3. **`03_training_evaluation.ipynb`** (1 min) ‚≠ê **PRINCIPAL**
   - Training curves (loss vs epochs)
   - Confusion matrix (heatmap)
   - ROC curves (3 scenarios)
   - Feature importance (top 20)
   - **Montrer:** Graphiques interactifs avec matplotlib

**Preuves d√©montr√©es:**
- ‚úÖ C12: Optimisation IA (GridSearch, hyperparams)
- ‚úÖ C12: Feature engineering (133 features)
- ‚úÖ E1.4: Exploitation donn√©es (notebooks)
- ‚úÖ C13: MLOps pipeline automatis√©
- ‚úÖ Accuracy: 94.46% (validation m√©tier)

---

### Phase 3: Composants Techniques Avanc√©s (8 min)

#### 3.1 Drift Detection - Rapports Evidently (2 min)
**Objectif:** Monitoring qualit√© pr√©dictions en production (C11)

**M√©thode: Rapports HTML Evidently**

1. **G√©n√©rer du trafic pour drift** (1 min)
```bash
# G√©n√©rer 1000 pr√©dictions
python scripts/generate_monitoring_data.py --mode burst --duration 2
```

2. **V√©rifier g√©n√©ration rapport** (30s)
```bash
# Lister rapports g√©n√©r√©s
ls -lh api_pokemon/monitoring/reports/
# Montrer: drift_dashboard_2026-01-27_15-30-00.html
```

3. **Ouvrir rapport HTML** (30s)
```bash
# Ouvrir dans navigateur
xdg-open api_pokemon/monitoring/reports/drift_dashboard_*.html
# Ou: double-clic dans l'explorateur de fichiers
```

**√âl√©ments √† montrer dans le rapport:**

- ‚úÖ **Data Drift Dashboard** (page 1)
  - Nombre de features avec drift d√©tect√©
  - Distribution features (histogrammes)
  - Statistical tests (Kolmogorov-Smirnov)

- ‚úÖ **Feature Drift Details** (page 2)
  - Drift score par feature
  - P-values des tests statistiques
  - Graphiques "Reference vs Current"

- ‚úÖ **Summary** (page 3)
  - Alertes (features en drift)
  - Recommandations (retraining needed?)

**Preuves d√©montr√©es:**
- ‚úÖ C11: Drift detection avec Evidently AI
- ‚úÖ C11: Rapports automatiques (HTML + JSON)
- ‚úÖ C11: Statistical tests professionnels

---

#### 3.2 Tests Automatis√©s - GitHub Actions (3 min)
**Objectif:** CI/CD et qualit√© code (C13)

**M√©thode: GitHub Actions UI**

1. **Acc√®s GitHub Actions** (30s)
```
https://github.com/YOUR_USERNAME/lets-go-predictiondex/actions
```

2. **Workflows √† montrer:** (2 min 30s)

**A. Workflow "Run Tests"** (1 min)
- Navigate: Actions ‚Üí Run Tests ‚Üí Latest run
- **Montrer:**
  - ‚úÖ 252 tests passed
  - ‚úÖ Coverage: 82%
  - ‚úÖ Test matrix: Python 3.11, 3.12
  - ‚úÖ Dur√©e: ~5 minutes
  - ‚úÖ Artifacts: coverage report

**B. Workflow "Build Docker Images"** (1 min)
- Navigate: Actions ‚Üí Build Docker Images ‚Üí Latest run
- **Montrer:**
  - ‚úÖ 5 images build√©es (api, streamlit, etl, ml, mlflow)
  - ‚úÖ Multi-stage builds optimis√©s
  - ‚úÖ Cache layers
  - ‚úÖ Security scan (pas de vuln√©rabilit√©s critiques)

**C. Workflow "Deploy to Staging"** (optionnel)
- **Montrer:**
  - Auto-trigger apr√®s merge sur `main`
  - D√©ploiement automatique
  - Health checks post-d√©ploiement

**D. Workflow "ML Training Pipeline"** (30s)
- Navigate: Actions ‚Üí ML Training Pipeline
- **Montrer:**
  - ‚úÖ Dataset generation
  - ‚úÖ Model training
  - ‚úÖ Model evaluation
  - ‚úÖ Auto-registration MLflow
  - ‚úÖ Artifacts: model.pkl, metrics.json

**M√©thode alternative: Badges README**
```bash
# Montrer badges dans README.md
cat README.md | grep -A 5 "badges"
```

**Preuves d√©montr√©es:**
- ‚úÖ C13: CI/CD complet (4 workflows)
- ‚úÖ C13: Tests automatis√©s (252 tests)
- ‚úÖ C13: Quality gates (coverage, linting)
- ‚úÖ C13: MLOps pipeline automatis√©

---

#### 3.3 Documentation - Markdown & Diagrammes (3 min)
**Objectif:** Documentation compl√®te du processus (E1.5)

**Fichiers √† montrer:**

1. **README.md principal** (1 min)
```bash
# Ouvrir dans VSCode avec preview
code README.md
```
**Points cl√©s:**
- ‚úÖ Badges (Python, Docker, Tests, Coverage)
- ‚úÖ Quick Start (5 min)
- ‚úÖ Architecture diagram (ASCII art)
- ‚úÖ Table of Contents compl√®te
- ‚úÖ Documentation API, monitoring, d√©ploiement

2. **Documentation technique ETL** (1 min)
```bash
# Ouvrir docs ETL
code docs/CERTIFICATION_E1_E3_VALIDATION.md
```
**Points cl√©s:**
- ‚úÖ Validation comp√©tences E1/E3
- ‚úÖ Preuves concr√®tes (code snippets)
- ‚úÖ Scores par comp√©tence
- ‚úÖ Architecture d√©taill√©e

3. **Diagrammes architecturaux** (1 min)

**A. Diagramme global (ASCII art dans README.md)**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           SOURCES DE DONN√âES                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üì¶ CSV   üåê Pok√©API   üï∑Ô∏è Pokepedia         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        ETL PIPELINE (E1.1, E1.2)            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Extraction multi-sources                  ‚îÇ
‚îÇ  ‚Ä¢ Transformation (nettoyage, validation)    ‚îÇ
‚îÇ  ‚Ä¢ Load PostgreSQL (11 tables, 3NF)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      BASE POSTGRESQL (E1.3)                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  188 Pok√©mon ‚Ä¢ 226 Moves ‚Ä¢ 18 Types         ‚îÇ
‚îÇ  11 tables ‚Ä¢ Relations FK ‚Ä¢ Normalisation    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚ñº                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ML       ‚îÇ    ‚îÇ  API REST (C9)    ‚îÇ
‚îÇ  PIPELINE ‚îÇ    ‚îÇ  FastAPI + IA     ‚îÇ
‚îÇ  (C12)    ‚îÇ    ‚îÇ  8 endpoints      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                ‚îÇ
      ‚ñº                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MLflow   ‚îÇ    ‚îÇ  Streamlit (C10)  ‚îÇ
‚îÇ  Registry ‚îÇ    ‚îÇ  8 pages          ‚îÇ
‚îÇ  (C13)    ‚îÇ    ‚îÇ  Interface User   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     MONITORING (C11)                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Prometheus ‚Ä¢ Grafana ‚Ä¢ Evidently Drift     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**B. Diagramme CI/CD**
- GitHub Actions workflows
- Tests ‚Üí Build ‚Üí Deploy pipeline
- MLflow integration

**Preuves d√©montr√©es:**
- ‚úÖ E1.5: Documentation compl√®te et structur√©e
- ‚úÖ E1.5: Diagrammes architecturaux
- ‚úÖ E1.5: Guide d'installation et d√©ploiement
- ‚úÖ E1.5: Documentation API (OpenAPI/Swagger)

---

## üöÄ Scripts de D√©monstration Automatis√©s

### Script 1: D√©marrage Stack Compl√®te
**Fichier:** `/mnt/Data/Dev/projet_python_ia_v1/lets-go-predictiondex/scripts/start_docker_stack.py`

```bash
# D√©marre tous les services Docker en une commande
python scripts/start_docker_stack.py

# Sortie format√©e:
# ==================================================
# üöÄ D√©marrage PredictionDex - Full Stack
# ==================================================
# ‚úÖ Docker et Docker Compose d√©tect√©s
# ‚úÖ Fichier .env cr√©√©
# üì¶ Construction des images... (3 min)
# üöÄ D√©marrage des services... (30s)
# üîç V√©rification des services...
#    ‚úÖ PostgreSQL (5432)
#    ‚úÖ API FastAPI (8080)
#    ‚úÖ Streamlit (8502)
#    ‚úÖ Prometheus (9091)
#    ‚úÖ Grafana (3001)
#    ‚úÖ MLflow (5001)
# ==================================================
# ‚úÖ Tous les services sont op√©rationnels!
# ==================================================
# üåê URLs disponibles:
#    API (Swagger):    http://localhost:8080/docs
#    Streamlit:        http://localhost:8502
#    Grafana:          http://localhost:3001
#    Prometheus:       http://localhost:9091
#    MLflow:           http://localhost:5001
```

---

### Script 2: Validation Stack
**Fichier:** `/mnt/Data/Dev/projet_python_ia_v1/lets-go-predictiondex/scripts/validate_docker_stack.py`

```bash
# Valide tous les services (health checks)
python scripts/validate_docker_stack.py --verbose

# Sortie format√©e:
# ==================================================
# üîç Validation de la stack Docker
# ==================================================
# 1Ô∏è‚É£ Services Docker
# ‚úÖ postgres          [5432]  - PostgreSQL
# ‚úÖ api               [8080]  - API FastAPI
# ‚úÖ streamlit         [8502]  - Interface Streamlit
# ‚úÖ prometheus        [9091]  - Prometheus
# ‚úÖ grafana           [3001]  - Grafana
# ‚úÖ mlflow            [5001]  - MLflow
#
# 2Ô∏è‚É£ Endpoints API
#    6/6 endpoints fonctionnels
#
# 3Ô∏è‚É£ Prometheus Targets
#    2/2 targets UP
#
# 4Ô∏è‚É£ Grafana Datasources
#    1 datasource(s) configur√©e(s)
#
# ==================================================
# ‚úÖ Tous les services sont op√©rationnels!
# ==================================================
```

---

### Script 3: G√©n√©ration M√©triques de Monitoring
**Fichier:** `/mnt/Data/Dev/projet_python_ia_v1/lets-go-predictiondex/scripts/generate_monitoring_data.py`

```bash
# G√©n√®re trafic r√©aliste pour dashboards Grafana
python scripts/generate_monitoring_data.py --mode realistic --duration 5

# Sortie format√©e en temps r√©el:
# ==================================================
# üéØ G√©n√©rateur de m√©triques Prometheus/Grafana
# ==================================================
# üîß Initialisation...
#    ‚úÖ API accessible
#    ‚úÖ 188 Pok√©mon charg√©s
#    ‚úÖ Prometheus accessible
#    ‚úÖ Grafana accessible
#
# üë• Mode REALISTIC - 5 minutes
# ==================================================
# Simulation: 5-10 utilisateurs avec patterns r√©alistes
#
# [  30s] Pr√©dictions:    15 | Lectures:   8 | Erreurs:  1 | Latence: P50=245ms P95=387ms P99=456ms
# [  60s] Pr√©dictions:    32 | Lectures:  17 | Erreurs:  3 | Latence: P50=238ms P95=401ms P99=478ms
# [  90s] Pr√©dictions:    49 | Lectures:  25 | Erreurs:  5 | Latence: P50=241ms P95=395ms P99=467ms
# [ 120s] Pr√©dictions:    67 | Lectures:  34 | Erreurs:  7 | Latence: P50=247ms P95=408ms P99=489ms
# [ 150s] Pr√©dictions:    84 | Lectures:  42 | Erreurs:  9 | Latence: P50=239ms P95=392ms P99=471ms
#
# ==================================================
# ‚úÖ Mode realistic termin√©!
# ==================================================
# üìä Statistiques finales:
#    Dur√©e totale: 5.0 minutes
#    Total requ√™tes: 135
#    Pr√©dictions: 84 (62.2%)
#    Lectures: 42 (31.1%)
#    Erreurs: 9 (6.7%)
#    D√©bit moyen: 27.0 req/min
#
#    Latences pr√©dictions:
#       Moyenne: 243.2ms
#       P50: 241.0ms
#       P95: 395.0ms
#       P99: 478.0ms
#
# üí° Consultez Grafana: http://localhost:3001
# üí° Consultez Prometheus: http://localhost:9091
```

**Options du script:**
```bash
# Mode burst (trafic intense)
python scripts/generate_monitoring_data.py --mode burst --duration 10

# Mode spike (pics al√©atoires)
python scripts/generate_monitoring_data.py --mode spike --duration 15
```

---

## üìä Checklist D√©monstration

### Avant la D√©monstration

- [ ] D√©marrer stack Docker: `python scripts/start_docker_stack.py`
- [ ] Valider services: `python scripts/validate_docker_stack.py`
- [ ] Pr√©-charger notebooks dans VSCode
- [ ] Ouvrir 5 onglets navigateur:
  - [ ] http://localhost:8502 (Streamlit)
  - [ ] http://localhost:8080/docs (Swagger)
  - [ ] http://localhost:3001 (Grafana)
  - [ ] http://localhost:5001 (MLflow)
  - [ ] https://github.com/YOUR_REPO/actions (GitHub Actions)
- [ ] Lancer g√©n√©ration m√©triques en arri√®re-plan:
  ```bash
  python scripts/generate_monitoring_data.py --mode realistic --duration 30 &
  ```

### Pendant la D√©monstration

**Phase 1: Interfaces Web (12 min)**
- [ ] Streamlit: 4 min
- [ ] Swagger API: 3 min
- [ ] Grafana: 3 min
- [ ] Prometheus: 1 min
- [ ] MLflow: 2 min

**Phase 2: Backend (10 min)**
- [ ] PostgreSQL via API: 3 min
- [ ] ETL logs: 3 min
- [ ] ML training (logs + notebooks): 4 min

**Phase 3: Technique (8 min)**
- [ ] Drift detection: 2 min
- [ ] GitHub Actions: 3 min
- [ ] Documentation: 3 min

### Apr√®s la D√©monstration

- [ ] Montrer README.md complet
- [ ] Pr√©senter architecture globale
- [ ] Questions/R√©ponses

---

## üéØ Points Forts √† Insister

### Pour E1 (Collecte et Traitement Donn√©es)

1. **3 sources de donn√©es** (CSV, Pok√©API, Pokepedia)
2. **Pipeline ETL automatis√©** avec validation
3. **898,472 combats simul√©s** pour dataset ML
4. **Base normalis√©e 3NF** (11 tables, FK, contraintes)
5. **Feature engineering** (133 features)

### Pour E3 (Int√©gration IA Production)

1. **API REST production-ready** (FastAPI + OpenAPI)
2. **Interface utilisateur fonctionnelle** (Streamlit 8 pages)
3. **Monitoring complet** (Prometheus + Grafana + Evidently)
4. **MLOps pipeline** (MLflow + GitHub Actions)
5. **Performance optimis√©e** (< 500ms, 94.46% accuracy)

---

## üí° Astuces Pr√©sentation

### Timing

- **30 min minimum** (essentiel)
- **45 min id√©al** (complet)
- **15 min Q&A** (questions jury)

### Pr√©paration Technique

1. **Tester la d√©mo 2 fois avant**
2. **Avoir plan B si services down:**
   - Screenshots pr√©-pr√©par√©s
   - Vid√©o screencast backup
3. **V√©rifier r√©solution √©cran** (1920x1080 minimum)
4. **Fermer applications inutiles** (performances)

### Communication

1. **Commencer par vue d'ensemble** (architecture globale)
2. **Montrer d'abord l'application finale** (Streamlit)
3. **Puis descendre vers technique** (API, DB, ML)
4. **Finir par CI/CD et qualit√©** (tests, monitoring)
5. **Toujours lier √† comp√©tences E1/E3** (mentionner codes)

### Phrases Cl√©s

- "Ce composant valide la comp√©tence **E1.1** (collecte de donn√©es)"
- "Ici on voit **C9** (API REST avec IA int√©gr√©e)"
- "Ce dashboard d√©montre **C11** (monitoring IA en production)"
- "Ce pipeline illustre **C13** (MLOps automatis√©)"

---

## üîß D√©pannage D√©mo

### Si un service ne d√©marre pas

```bash
# V√©rifier logs
docker logs letsgo_<service_name>

# Red√©marrer service sp√©cifique
docker-compose restart <service_name>

# Rebuild si n√©cessaire
docker-compose up -d --build <service_name>
```

### Si Grafana ne montre pas de donn√©es

```bash
# G√©n√©rer trafic
python scripts/generate_monitoring_data.py --mode burst --duration 2

# V√©rifier Prometheus targets
curl http://localhost:9091/api/v1/targets
```

### Si notebooks ne s'affichent pas

```bash
# Ouvrir avec VSCode
code notebooks/

# Ou d√©marrer Jupyter
jupyter lab notebooks/
```

---

## üìÅ Fichiers Cl√©s √† Conna√Ætre

### Scripts D√©monstration

- `/scripts/start_docker_stack.py` - D√©marrage complet
- `/scripts/validate_docker_stack.py` - Validation services
- `/scripts/generate_monitoring_data.py` - G√©n√©ration m√©triques

### Documentation

- `/README.md` - Documentation principale
- `/docs/CERTIFICATION_E1_E3_VALIDATION.md` - Validation comp√©tences
- `/docs/EXPLICATIONS_TECHNIQUES_ML_MONITORING.md` - D√©tails techniques

### Code Principal

- `/api_pokemon/main.py` - API FastAPI (C9)
- `/interface/app.py` - Streamlit (C10)
- `/machine_learning/run_machine_learning.py` - ML pipeline (C12)
- `/etl_pokemon/pipeline.py` - ETL pipeline (E1.1, E1.2)

### Configuration

- `/docker-compose.yml` - Orchestration compl√®te (9 services)
- `/.github/workflows/` - CI/CD GitHub Actions (C13)
- `/docker/grafana/dashboards/` - Dashboards Grafana (C11)

---

## üìö Ressources Compl√©mentaires

### Documentation Externe

- **FastAPI:** https://fastapi.tiangolo.com/
- **Streamlit:** https://docs.streamlit.io/
- **XGBoost:** https://xgboost.readthedocs.io/
- **MLflow:** https://mlflow.org/docs/latest/
- **Prometheus:** https://prometheus.io/docs/
- **Grafana:** https://grafana.com/docs/
- **Evidently AI:** https://docs.evidentlyai.com/

### Documentation Projet

- [README principal](README.md)
- [Guide d√©ploiement](docs/deployment/QUICK_START.md)
- [Documentation API](http://localhost:8080/docs)
- [Explications ML](docs/EXPLICATIONS_TECHNIQUES_ML_MONITORING.md)

---

## ‚úÖ Validation Finale

### Avant de Pr√©senter

**V√©rifier que TOUS ces √©l√©ments sont d√©montrables:**

#### E1 - Collecte et Traitement Donn√©es
- [x] E1.1: 3 sources de donn√©es (CSV, Pok√©API, Pokepedia)
- [x] E1.2: Nettoyage et validation (logs ETL)
- [x] E1.3: Base PostgreSQL (11 tables via API)
- [x] E1.4: Feature engineering (133 features, notebooks)
- [x] E1.5: Documentation compl√®te (README, diagrammes)

#### E3 - Int√©gration IA Production
- [x] C9: API REST avec IA (Swagger UI fonctionnel)
- [x] C10: Interface applicative (Streamlit 8 pages)
- [x] C11: Monitoring IA (Grafana + Prometheus + Evidently)
- [x] C12: Optimisation IA (< 500ms, 94.46% accuracy)
- [x] C13: MLOps CI/CD (MLflow + GitHub Actions)

---

**Derni√®re mise √† jour:** 27 janvier 2026
**Version:** 1.0
**Auteur:** PredictionDex Team
**Objectif:** Certification RNCP Niveau 6 - E1/E3

---

**üéØ Bon courage pour la d√©monstration ! üöÄ**
