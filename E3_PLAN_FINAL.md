# Plan E3 Final - ImplÃ©mentation ML & MLOps

**Date**: 2026-01-20
**BasÃ© sur**: Plan ChatGPT + AmÃ©liorations proposÃ©es

---

## ðŸŽ¯ Objectif ML

### Question MÃ©tier
**"Cette capacitÃ© est-elle efficace contre ce PokÃ©mon dÃ©fenseur ?"**

### Type de ML
- **Classification binaire supervisÃ©e**
- **Target**: `is_effective âˆˆ {0, 1}`
- **RÃ¨gle**: `is_effective = 1 if type_multiplier >= 2 else 0`

### Justification
âœ… Simple et explicable
âœ… AlignÃ© avec les rÃ¨gles PokÃ©mon officielles
âœ… DÃ©fendable en jury
âœ… Suffisant pour valider le bloc E3

---

## ðŸ“Š Dataset ML

### Source
Base PostgreSQL (188 PokÃ©mon, 226 capacitÃ©s damaging)

### Taille ThÃ©orique
```
188 Ã— 188 Ã— 226 = 7,982,656 combinaisons possibles
```

### StratÃ©gie d'Ã‰chantillonnage Intelligent

**ProblÃ¨me**: Dataset complet trop large et avec beaucoup de bruit

**Solution**:
1. Garder **TOUTES** les combinaisons efficaces (type_multiplier >= 2)
2. Ã‰chantillonner **15%** des combinaisons non efficaces
3. RÃ©sultat: ~500K-1M lignes (optimal pour RandomForest)

### Features (19 au total)

| CatÃ©gorie | Features | Type |
|-----------|----------|------|
| **Attacker** (4) | type_1, type_2, attack, sp_attack | categorical + numerical |
| **Defender** (4) | type_1, type_2, defense, sp_defense | categorical + numerical |
| **Move** (4) | type, category, power, accuracy | categorical + numerical |
| **Computed** (7) | type_multiplier, is_stab, stat_ratio, has_dual_type_attacker, has_dual_type_defender | numerical + boolean |

### Target
```python
is_effective = 1 if type_multiplier >= 2 else 0
```

### Format
- **Raw**: `data/ml/raw/battle_samples.parquet`
- **Train**: `data/ml/processed/train.parquet` (80%)
- **Test**: `data/ml/processed/test.parquet` (20%)
- **Split**: Stratified (preserve class distribution)

---

## ðŸ§  ModÃ¨le ML

### ModÃ¨les Ã  Tester (Notebooks)
1. **Logistic Regression** (baseline)
2. **Random Forest** â­ (recommandÃ©)
3. **XGBoost** (optionnel si temps disponible)

### ModÃ¨le Final Retenu
**RandomForestClassifier**

**HyperparamÃ¨tres suggÃ©rÃ©s**:
```python
RandomForestClassifier(
    n_estimators=100,
    max_depth=15,
    min_samples_split=10,
    random_state=42,
    n_jobs=-1
)
```

**Justification**:
- âœ… Robuste aux donnÃ©es brutes (pas besoin de scaling)
- âœ… GÃ¨re bien les features catÃ©gorielles (aprÃ¨s encoding)
- âœ… InterprÃ©table (feature importance)
- âœ… Performant sans tuning excessif
- âœ… TrÃ¨s bien acceptÃ© en jury

### MÃ©triques de Performance Attendues
- **Accuracy**: >= 85%
- **F1-Score**: >= 80%
- **Precision/Recall**: Ã‰quilibrÃ©s

---

## ðŸ”„ Workflow de DÃ©veloppement

### Phase 1: Dataset Generation âœ… (En cours)
**Script**: [machine_learning/build_classification_dataset.py](machine_learning/build_classification_dataset.py)

**Actions**:
1. âœ… CrÃ©er le script de gÃ©nÃ©ration
2. â³ ExÃ©cuter le script (via Docker)
3. â³ Valider la qualitÃ© du dataset

**Commande**:
```bash
docker compose exec api python machine_learning/build_classification_dataset.py
```

---

### Phase 2: Notebooks Jupyter (R&D)

#### Notebook 1: Exploration
**Fichier**: [notebooks/01_exploration.ipynb](notebooks/01_exploration.ipynb)

**Objectifs**:
- Charger `data/ml/processed/train.parquet`
- EDA (Exploratory Data Analysis)
- Distribution des features
- CorrÃ©lations
- Distribution de la target (is_effective)
- Identification des valeurs manquantes
- Visualisations (histogrammes, boxplots, heatmap)

---

#### Notebook 2: Feature Engineering
**Fichier**: [notebooks/02_feature_engineering.ipynb](notebooks/02_feature_engineering.ipynb)

**Objectifs**:
- Encoder les features catÃ©gorielles:
  - LabelEncoder pour les types
  - OneHotEncoder pour move_category
- Normalisation si nÃ©cessaire (RandomForest n'en a pas besoin)
- SÃ©lection des features importantes
- Validation de la pipeline de preprocessing

---

#### Notebook 3: Training & Evaluation
**Fichier**: [notebooks/03_training_evaluation.ipynb](notebooks/03_training_evaluation.ipynb)

**Objectifs**:
- Tester plusieurs modÃ¨les (Logistic Regression, Random Forest)
- Comparer les performances
- Tuning des hyperparamÃ¨tres (GridSearchCV ou RandomizedSearchCV)
- Ã‰valuation finale:
  - Accuracy, Precision, Recall, F1-Score
  - Confusion Matrix
  - Feature Importance (pour RandomForest)
  - ROC Curve / AUC
- Export du modÃ¨le final vers `models/`

---

### Phase 3: Script Production

**Fichier**: [machine_learning/train_model.py](machine_learning/train_model.py)

**Objectifs**:
- Reprendre le code validÃ© dans les notebooks
- Script reproductible (pas d'interaction manuelle)
- Charger train/test depuis `data/ml/processed/`
- EntraÃ®ner RandomForestClassifier
- Ã‰valuer les performances
- Exporter:
  - `models/pokemon_move_model.joblib`
  - `models/model_metadata.json`

**Commande**:
```bash
python machine_learning/train_model.py
```

**Output** (`models/model_metadata.json`):
```json
{
  "model_type": "RandomForestClassifier",
  "version": "1.0.0",
  "features": ["attacker_type_1", "attacker_type_2", ...],
  "accuracy": 0.92,
  "f1_score": 0.91,
  "precision": 0.90,
  "recall": 0.92,
  "created_at": "2026-01-20T15:30:00",
  "created_by": "train_model.py",
  "train_samples": 800000,
  "test_samples": 200000,
  "hyperparameters": {
    "n_estimators": 100,
    "max_depth": 15,
    "random_state": 42
  }
}
```

---

### Phase 4: IntÃ©gration API

#### 4.1 Feature Builder
**Fichier**: [api_pokemon/ml/feature_builder.py](api_pokemon/ml/feature_builder.py)

**RÃ´le**: Construire le vecteur de features depuis les IDs (attacker_id, defender_id, move_id)

```python
def build_features(attacker_id: int, defender_id: int, move_id: int, session) -> dict:
    """
    Query DB and build feature vector.

    Returns:
        dict: Feature vector ready for model prediction
    """
    # Query Pokemon stats and types
    # Query Move properties
    # Calculate type_multiplier, is_stab, stat_ratio, etc.
    # Return dict with all features
```

---

#### 4.2 Model Loader
**Fichier**: [api_pokemon/ml/model_loader.py](api_pokemon/ml/model_loader.py)

**RÃ´le**: Charger le modÃ¨le au dÃ©marrage de l'API

```python
import joblib
from pathlib import Path

def load_model():
    """Load ML model from disk."""
    model_path = Path("models/pokemon_move_model.joblib")
    if not model_path.exists():
        raise FileNotFoundError(f"Model not found: {model_path}")

    model = joblib.load(model_path)
    print(f"âœ… Model loaded: {model_path}")
    return model
```

---

#### 4.3 Predictor
**Fichier**: [api_pokemon/ml/predictor.py](api_pokemon/ml/predictor.py)

**RÃ´le**: Logique de prÃ©diction

```python
class Predictor:
    def __init__(self, model):
        self.model = model

    def predict(self, features: dict) -> dict:
        """
        Make prediction.

        Returns:
            dict: {
                "is_effective": int,
                "probability": float,
                "confidence": str
            }
        """
        # Convert features dict to numpy array
        # Model prediction
        # Calculate probability and confidence
        # Return structured response
```

---

#### 4.4 Predict Route
**Fichier**: [api_pokemon/routes/predict_route.py](api_pokemon/routes/predict_route.py)

**Endpoint**: `POST /predict`

**Request**:
```json
{
  "attacker_id": 1,
  "defender_id": 4,
  "move_id": 33
}
```

**Response**:
```json
{
  "is_effective": 1,
  "probability": 0.87,
  "confidence": "high",
  "type_multiplier": 2.0,
  "move_category": "physique",
  "recommendation": "Super efficace ! Cette capacitÃ© Plante inflige des dÃ©gÃ¢ts doublÃ©s contre ce type Eau.",
  "metadata": {
    "model_version": "1.0.0",
    "prediction_time_ms": 12
  }
}
```

---

#### 4.5 Integration in Main
**Fichier**: [api_pokemon/main.py](api_pokemon/main.py)

**Modifications**:
```python
from api_pokemon.ml.model_loader import load_model
from api_pokemon.routes import predict_route

# Global model instance
ml_model = None

@app.on_event("startup")
async def startup_event():
    global ml_model
    try:
        ml_model = load_model()
        print("âœ… ML Model loaded successfully")
    except Exception as e:
        print(f"âš ï¸  ML Model not loaded: {e}")
        # API can still work without ML

# Include predict router
app.include_router(predict_route.router, prefix="/predict", tags=["ML Prediction"])
```

---

### Phase 5: Tests AutomatisÃ©s (C12)

#### Test 1: Dataset
**Fichier**: [tests/ml/test_dataset_ml.py](tests/ml/test_dataset_ml.py)

**Tests**:
- âœ… Dataset files exist
- âœ… Train/test split ratio (80/20)
- âœ… No missing values in critical features
- âœ… Target distribution (should be close to 50/50 after sampling)
- âœ… Feature types are correct

---

#### Test 2: Model Loading
**Fichier**: [tests/ml/test_model_loading.py](tests/ml/test_model_loading.py)

**Tests**:
- âœ… Model file exists
- âœ… Model loads successfully
- âœ… Metadata file exists and is valid JSON
- âœ… Simple prediction works (sanity check)

---

#### Test 3: Predict Endpoint
**Fichier**: [tests/ml/test_predict_endpoint.py](tests/ml/test_predict_endpoint.py)

**Tests**:
- âœ… Endpoint returns 200 for valid input
- âœ… Response has correct structure
- âœ… Probability is between 0 and 1
- âœ… Invalid IDs return 404
- âœ… Missing fields return 422

---

#### Test 4: Model Performance
**Fichier**: [tests/ml/test_model_performance.py](tests/ml/test_model_performance.py)

**Tests**:
- âœ… Accuracy >= 0.85 on test set
- âœ… F1-score >= 0.80
- âœ… No extreme predictions (all probabilities != 0 or 1)

**Commande**:
```bash
pytest tests/ml/ -v
```

---

### Phase 6: Monitoring (C11)

#### 6.1 Evidently Configuration
**Fichier**: [monitoring/evidently_config.py](monitoring/evidently_config.py)

**Configuration**:
- Data drift detection
- Prediction drift detection
- Report generation

---

#### 6.2 Data Drift Monitor
**Fichier**: [monitoring/monitor_data_drift.py](monitoring/monitor_data_drift.py)

**FonctionnalitÃ©s**:
- Compare reference data (train set) vs current data (new predictions)
- Detect distribution changes in features
- Generate HTML report
- Alert if drift detected

**Commande**:
```bash
python monitoring/monitor_data_drift.py
```

**Output**: `reports/data_drift_report.html`

---

#### 6.3 Prediction Monitor
**Fichier**: [monitoring/monitor_predictions.py](monitoring/monitor_predictions.py)

**MÃ©triques**:
- Total predictions count
- Ratio effective/not-effective (should be stable)
- Prediction latency
- Model load time

---

### Phase 7: Interface Streamlit (C10)

**Fichier**: [interface/pages/3_ðŸ¤–_ML_Predict.py](interface/pages/3_ðŸ¤–_ML_Predict.py)

**FonctionnalitÃ©s**:
1. **SÃ©lection PokÃ©mon Attaquant** (dropdown avec images)
2. **SÃ©lection PokÃ©mon DÃ©fenseur** (dropdown avec images)
3. **SÃ©lection CapacitÃ©** (dropdown avec dÃ©tails)
4. **Bouton "PrÃ©dire l'EfficacitÃ©"**
5. **Affichage RÃ©sultat**:
   - Badge efficace/non efficace (vert/rouge)
   - ProbabilitÃ© avec barre de progression
   - Multiplicateur de type
   - Recommandation textuelle
   - Graphique de confiance (gauge chart)
6. **Historique des prÃ©dictions** (optionnel)

**Interface**:
```python
import streamlit as st
import requests

st.title("ðŸ¤– PrÃ©diction d'EfficacitÃ© ML")

# Fetch Pokemon list from API
pokemon_list = requests.get("http://api:8000/pokemon/").json()

# Dropdowns
attacker = st.selectbox("PokÃ©mon Attaquant", pokemon_list)
defender = st.selectbox("PokÃ©mon DÃ©fenseur", pokemon_list)
move = st.selectbox("CapacitÃ©", ...)

if st.button("PrÃ©dire"):
    response = requests.post("http://api:8000/predict", json={
        "attacker_id": attacker["id"],
        "defender_id": defender["id"],
        "move_id": move["id"]
    })
    result = response.json()

    # Display result
    if result["is_effective"]:
        st.success(f"âœ… Efficace ! (probabilitÃ©: {result['probability']:.1%})")
    else:
        st.error(f"âŒ Pas efficace (probabilitÃ©: {result['probability']:.1%})")

    st.info(result["recommendation"])
```

---

### Phase 8: Documentation Finale

**Fichier**: [E3_RAPPORT.md](E3_RAPPORT.md)

**Contenu**:
- PrÃ©sentation du projet
- ProblÃ¨me ML et justification
- Architecture du dataset
- Choix du modÃ¨le (RandomForest) et justification
- RÃ©sultats (mÃ©triques de performance)
- IntÃ©gration API et Streamlit
- Tests automatisÃ©s
- Monitoring
- ChaÃ®ne MLOps (Docker, CI/CD)
- DÃ©monstration E3 (compÃ©tences C9-C13)
- Conclusion et perspectives

---

## ðŸ“‹ CompÃ©tences E3 - Mapping

| CompÃ©tence | Description | Couverture | Fichiers ClÃ©s |
|------------|-------------|------------|---------------|
| **C9** | DÃ©velopper et exposer un modÃ¨le IA via API | âœ… Endpoint `/predict` | `api_pokemon/routes/predict_route.py`, `api_pokemon/ml/` |
| **C10** | IntÃ©grer le modÃ¨le dans une application | âœ… Page Streamlit | `interface/pages/3_ðŸ¤–_ML_Predict.py` |
| **C11** | Monitorer les performances du modÃ¨le | âœ… Evidently | `monitoring/` |
| **C12** | ImplÃ©menter des tests automatisÃ©s | âœ… pytest | `tests/ml/` |
| **C13** | Mettre en place une chaÃ®ne MLOps | âœ… Docker, scripts reproductibles | `docker-compose.yml`, `machine_learning/train_model.py` |

---

## ðŸš€ Ordre d'ExÃ©cution RecommandÃ©

### Semaine 1: Dataset & Notebooks
1. âœ… [CrÃ©er build_classification_dataset.py](machine_learning/build_classification_dataset.py)
2. â³ ExÃ©cuter et gÃ©nÃ©rer le dataset
3. â³ CrÃ©er notebooks 01, 02, 03
4. â³ ExpÃ©rimenter et valider le modÃ¨le

### Semaine 2: Production & API
5. â³ CrÃ©er train_model.py
6. â³ EntraÃ®ner et exporter le modÃ¨le
7. â³ CrÃ©er les modules API ML (feature_builder, model_loader, predictor)
8. â³ CrÃ©er l'endpoint /predict
9. â³ IntÃ©grer dans main.py

### Semaine 3: Tests & Monitoring
10. â³ CrÃ©er les tests automatisÃ©s (4 fichiers)
11. â³ Configurer Evidently
12. â³ ImplÃ©menter monitoring

### Semaine 4: Interface & Documentation
13. â³ CrÃ©er la page Streamlit ML Predict
14. â³ RÃ©diger E3_RAPPORT.md
15. â³ PrÃ©parer la dÃ©monstration jury

---

## ðŸ’¡ Message ClÃ© pour le Jury

> "Le modÃ¨le de Machine Learning est conÃ§u comme un **service indÃ©pendant**, entraÃ®nÃ© **hors production** via des scripts reproductibles, intÃ©grÃ© dans une **API REST FastAPI**, monitorÃ© avec **Evidently**, testÃ© avec **pytest**, et exposÃ© via une **interface Streamlit**. L'ensemble de la chaÃ®ne MLOps est **dockerisÃ©e** et **automatisÃ©e**, dÃ©montrant une approche **industrielle** et **scalable**."

---

## ðŸ“Š MÃ©triques de SuccÃ¨s

### Dataset
- âœ… 500K-1M lignes
- âœ… Classes Ã©quilibrÃ©es (50/50)
- âœ… 19 features pertinentes

### ModÃ¨le
- âœ… Accuracy >= 85%
- âœ… F1-Score >= 80%
- âœ… Feature importance interprÃ©table

### API
- âœ… Endpoint /predict fonctionnel
- âœ… Latence < 100ms
- âœ… Healthcheck OK

### Tests
- âœ… 15+ tests automatisÃ©s
- âœ… Coverage >= 80%

### Interface
- âœ… Page Streamlit fonctionnelle
- âœ… UX intuitive
- âœ… RÃ©sultats clairs

---

**Statut Actuel**: Phase 1 en cours (Dataset Generation)
**Prochaine Ã‰tape**: ExÃ©cuter `build_classification_dataset.py` via Docker
