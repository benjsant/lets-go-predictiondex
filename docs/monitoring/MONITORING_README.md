# ðŸš€ Monitoring Stack - Guide de DÃ©marrage Rapide

## âœ… Ce qui est implÃ©mentÃ©

### Stack ComplÃ¨te (v1.0)
- âœ… **Prometheus** : Collecte de mÃ©triques (API, ModÃ¨le, SystÃ¨me)
- âœ… **Grafana** : 2 dashboards (API Performance + Model Performance)
- âœ… **MLflow** : Tracking des expÃ©riences ML et registry de modÃ¨les
- âœ… **Production Data Collection** : Collecte automatique des features ML pour future analyse
- âœ… **Node Exporter** : MÃ©triques systÃ¨me (CPU, RAM, etc.)
- âœ… **Alerting** : 8 rÃ¨gles d'alerte configurÃ©es

---

## ðŸŽ¯ Lancement

### Option 1 : Stack ComplÃ¨te
```bash
docker compose up --build
```

### Option 2 : Monitoring Seul (aprÃ¨s DB+API)
```bash
# DÃ©marrer DB + ETL + API d'abord
docker compose up db etl api -d

# Puis le monitoring
docker compose up prometheus grafana node-exporter -d
```

---

## ðŸŒ URLs d'AccÃ¨s

| Service | URL | Credentials |
|---------|-----|-------------|
| **API Swagger** | http://localhost:8000/docs | - |
| **API Metrics** | http://localhost:8000/metrics | - |
| **Prometheus** | http://localhost:9090 | - |
| **Grafana** | http://localhost:3000 | admin / admin |
| **Streamlit UI** | http://localhost:8501 | - |

---

## ðŸ“Š Dashboards Grafana

AprÃ¨s connexion sur http://localhost:3000 (admin/admin) :

### Dashboard 1 : API Performance
- URL: http://localhost:3000/d/api-performance
- **MÃ©triques** : RequÃªtes/s, Latence P95, Taux d'erreurs, Status HTTP

### Dashboard 2 : Model Performance  
- URL: http://localhost:3000/d/model-performance
- **MÃ©triques** : PrÃ©dictions/min, Confiance, Latence modÃ¨le, Distribution win probability

---

## ðŸ§ª Tester le Monitoring

### 1. VÃ©rifier que les mÃ©triques sont exposÃ©es

```bash
curl http://localhost:8000/metrics
```

Vous devriez voir des mÃ©triques Prometheus :
```
# HELP api_requests_total Total API requests
# TYPE api_requests_total counter
api_requests_total{endpoint="/docs",method="GET",status="200"} 5.0
model_predictions_total{model_version="v2"} 42.0
```

### 2. GÃ©nÃ©rer des prÃ©dictions

```bash
curl -X POST http://localhost:8000/predict/best-move \
  -H "Content-Type: application/json" \
  -d '{
    "pokemon_a_id": 1,
    "pokemon_b_id": 25,
    "available_moves": ["Surf", "Ice Beam", "Earthquake"]
  }'
```

### 3. VÃ©rifier Prometheus

1. Ouvrir http://localhost:9090
2. Query : `rate(api_requests_total[1m])`
3. Cliquer sur "Execute" â†’ Graphique des requÃªtes/s

### 4. Ouvrir Grafana

1. http://localhost:3000 (admin / admin)
2. Menu gauche â†’ Dashboards
3. Cliquer sur "API Performance" ou "Model Performance"

---

## ðŸ’¾ Collecte de DonnÃ©es de Production

### Fonctionnement Automatique

Le systÃ¨me collecte automatiquement les features ML de chaque prÃ©diction :
- Buffer : 100 prÃ©dictions max
- RÃ©fÃ©rence : 10k exemples d'entraÃ®nement (X_train.parquet) chargÃ©s au dÃ©marrage
- Output : Fichiers parquet avec 133 features ML

### Localisation des DonnÃ©es

```bash
ls -lh api_pokemon/monitoring/drift_data/
```

Fichiers gÃ©nÃ©rÃ©s :
```
production_data_20260130_124717.parquet  # 100 prÃ©dictions Ã— 133 features
```

### Utilisation des DonnÃ©es

Ces donnÃ©es peuvent Ãªtre utilisÃ©es pour :
- Analyse manuelle de drift des donnÃ©es
- RÃ©entraÃ®nement du modÃ¨le avec donnÃ©es rÃ©elles
- Validation de la qualitÃ© des prÃ©dictions
- Debugging et amÃ©lioration du modÃ¨le

---

## ðŸ“ˆ RequÃªtes Prometheus Utiles

### API Performance

```promql
# RequÃªtes par seconde
rate(api_requests_total[5m])

# Latence P95 globale
histogram_quantile(0.95, rate(api_request_duration_seconds_bucket[5m]))

# Taux d'erreurs
rate(api_errors_total[5m]) / rate(api_requests_total[5m])
```

### Model Performance

```promql
# PrÃ©dictions par minute
rate(model_predictions_total[1m]) * 60

# Latence P95 du modÃ¨le  
histogram_quantile(0.95, rate(model_prediction_duration_seconds_bucket[5m]))

# Confiance moyenne
avg(model_confidence_score)
```

---

## ðŸš¨ Alertes ConfigurÃ©es

### Alertes API (3)
- **HighAPILatency** : Latence > 0.5s pendant 5min
- **HighErrorRate** : Erreurs > 5% pendant 5min  
- **APIDown** : API ne rÃ©pond pas pendant 1min

### Alertes ModÃ¨le (2)
- **HighModelLatency** : Latence > 0.1s pendant 5min
- **LowModelConfidence** : Confiance < 0.6 pendant 10min

### Alertes SystÃ¨me (3)
- **HighCPUUsage** : CPU > 80% pendant 5min
- **HighMemoryUsage** : RAM > 85% pendant 5min
- **LowMemoryAvailable** : RAM disponible < 512MB pendant 2min

Voir les alertes : http://localhost:9090/alerts

---

## ðŸ› ï¸ Troubleshooting

### Prometheus ne collecte pas les mÃ©triques

```bash
# VÃ©rifier que l'API est accessible
curl http://localhost:8000/health

# VÃ©rifier que /metrics rÃ©pond
curl http://localhost:8000/metrics

# VÃ©rifier les logs Prometheus
docker compose logs prometheus

# VÃ©rifier les targets dans Prometheus
# http://localhost:9090/targets
```

### Grafana n'affiche pas de donnÃ©es

```bash
# VÃ©rifier que Prometheus collecte les donnÃ©es
# http://localhost:9090/graph

# VÃ©rifier la datasource Grafana
# http://localhost:3000/datasources

# Recharger les dashboards
docker compose restart grafana
```

### Collecte de donnÃ©es de production

```bash
# VÃ©rifier que X_train.parquet existe (rÃ©fÃ©rence)
ls -lh data/datasets/X_train.parquet

# VÃ©rifier les logs de collecte
docker compose logs -f api | grep -i "production"

# VÃ©rifier les fichiers de donnÃ©es collectÃ©es
ls -lh api_pokemon/monitoring/drift_data/
```

---

## ðŸ“š Documentation ComplÃ¨te

- **Prometheus** : https://prometheus.io/docs/
- **Grafana** : https://grafana.com/docs/
- **MLflow** : https://mlflow.org/docs/latest/index.html

---

## ðŸŽ¯ Prochaines Ã‰tapes (C13 - MLOps)

- [ ] MLflow pour le tracking d'expÃ©riences
- [ ] CI/CD avec GitHub Actions
- [ ] Architecture monitoring modulaire (Redis + Worker)
- [ ] Alerting Slack/Discord
- [ ] Auto-retraining sur drift dÃ©tectÃ©

---

**Version** : 1.1
**Stack** : Prometheus + Grafana + MLflow + Production Data Collection + Node Exporter
**DerniÃ¨re MAJ** : 30 janvier 2026
