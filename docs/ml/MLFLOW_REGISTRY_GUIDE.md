# MLflow Model Registry - Guide d'Utilisation

## üìã Vue d'ensemble

Le **MLflow Model Registry** est maintenant int√©gr√© dans le projet PredictionDex pour :
- ‚úÖ **Centraliser** les mod√®les ML entra√Æn√©s
- ‚úÖ **Versionner** automatiquement chaque mod√®le
- ‚úÖ **Promouvoir** les meilleurs mod√®les en Production
- ‚úÖ **Charger** les mod√®les depuis l'API sans fichiers locaux

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ML Training    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  MLflow Registry ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  API Service    ‚îÇ
‚îÇ  (run_machine_  ‚îÇ      ‚îÇ  (versioning +   ‚îÇ      ‚îÇ  (load from     ‚îÇ
‚îÇ   learning.py,  ‚îÇ      ‚îÇ   promotion)     ‚îÇ      ‚îÇ   registry)     ‚îÇ
‚îÇ   train_model)  ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
                                 ‚îÇ
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ   MLflow UI     ‚îÇ
                         ‚îÇ (http://:5000)  ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Fonctionnalit√©s Impl√©ment√©es

### 1. **Enregistrement Automatique des Mod√®les**
Chaque entra√Ænement enregistre automatiquement le mod√®le dans le registry :

```python
# machine_learning/run_machine_learning.py
version_number = tracker.register_model(
    model_name="battle_winner_predictor",
    description=f"{model_name} - Accuracy: {accuracy:.4f}"
)
```

### 2. **Promotion Automatique en Production**
Les mod√®les avec `accuracy >= 0.85` sont automatiquement promus :

```python
if version_number and metrics['test_accuracy'] >= 0.85:
    tracker.promote_to_production("battle_winner_predictor", version_number)
    print("‚úÖ Model promoted to Production")
```

### 3. **Chargement depuis l'API**
L'API charge automatiquement le mod√®le en Production depuis le registry :

```python
# api_pokemon/services/prediction_service.py
model_bundle = load_model_from_registry(
    model_name="battle_winner_predictor",
    stage="Production"  # or "Staging"
)
```

### 4. **Comparaison des Versions**
Comparer toutes les versions d'un mod√®le :

```python
df = tracker.compare_models("battle_winner_predictor")
print(df)
```

Output example:
```
version  stage       accuracy  f1_score  roc_auc   created_at
3        Production  0.8723    0.8654    0.9234    2025-01-25 14:30
2        Staging     0.8512    0.8401    0.9102    2025-01-25 12:15
1        Archived    0.8203    0.8123    0.8956    2025-01-24 18:45
```

## üì¶ Artifacts Enregistr√©s

Pour chaque mod√®le, les artifacts suivants sont sauvegard√©s :
1. **model/** : Le mod√®le XGBoost ou RandomForest
2. **scalers.pkl** : Les StandardScalers pour la normalisation
3. **metadata.pkl** : Les feature_columns et m√©tadonn√©es

Ces artifacts sont automatiquement t√©l√©charg√©s lors du chargement depuis l'API.

## üõ†Ô∏è Utilisation

### Entra√Æner et Enregistrer un Mod√®le

```bash
# Option 1 : Pipeline complet (run_machine_learning.py)
python machine_learning/run_machine_learning.py \
    --mode all \
    --model xgboost \
    --version v2

# Option 2 : Script standalone (train_model.py)
python machine_learning/train_model.py \
    --use-gridsearch \
    --grid-type fast \
    --version v3
```

**R√©sultat** :
- ‚úÖ Mod√®le entra√Æn√© et export√© localement
- ‚úÖ Mod√®le logg√© dans MLflow avec run metrics
- ‚úÖ Mod√®le enregistr√© dans le Model Registry (version auto-incr√©ment√©e)
- ‚úÖ Promotion automatique en Production si accuracy >= 0.85

### D√©sactiver le Registry (pour tests)

```bash
# run_machine_learning.py : utilise --no-mlflow n'existe pas (toujours activ√©)
# train_model.py : 
python machine_learning/train_model.py --no-mlflow
```

### Charger depuis l'API

L'API charge automatiquement depuis le registry avec variables d'environnement :

```bash
# Dans docker-compose.yml ou .env
USE_MLFLOW_REGISTRY=true          # Enable registry loading (default: true)
MLFLOW_MODEL_NAME=battle_winner_predictor  # Model name (default)
MLFLOW_MODEL_STAGE=Production      # Stage to load (default: Production)
MLFLOW_TRACKING_URI=http://mlflow:5000
```

**Comportement** :
1. Essaie de charger depuis le registry (stage Production)
2. Fallback sur les fichiers locaux si √©chec ou registry d√©sactiv√©
3. Logs clairs pour diagnostiquer

### Interface MLflow UI

Acc√©der √† l'interface web MLflow :

```bash
# URL locale (apr√®s docker compose up)
http://localhost:5000

# Naviguer vers :
# 1. "Experiments" ‚Üí Voir les runs et m√©triques
# 2. "Models" ‚Üí Voir le Model Registry
#    - battle_winner_predictor
#      - Version 1 (Archived)
#      - Version 2 (Staging)
#      - Version 3 (Production) ‚Üê Active
```

**Actions disponibles** :
- üìä Comparer les runs (m√©triques, hyperparam√®tres)
- üè∑Ô∏è Transition manuelle des stages (Staging ‚Üí Production)
- üìù Ajouter des descriptions et tags
- üì• T√©l√©charger les artifacts

## üîÑ Workflow Complet

### Sc√©nario 1 : Entra√Ænement et D√©ploiement Automatique

```bash
# 1. Entra√Æner un nouveau mod√®le
python machine_learning/train_model.py --use-gridsearch --version v4

# Output :
# ‚úÖ Model trained and exported
# ‚úÖ Logged to MLflow (run: train_model_v4_20250125_1430)
# ‚úÖ Registered as version 4 in Model Registry
# üéØ Model meets quality threshold (accuracy >= 0.85)
# ‚úÖ Model promoted to Production stage

# 2. L'API recharge automatiquement le nouveau mod√®le
# (au prochain appel de pr√©diction, load() sera rappel√©)
```

### Sc√©nario 2 : Comparaison et Promotion Manuelle

```python
from machine_learning.mlflow_integration import MLflowTracker

tracker = MLflowTracker(experiment_name="battle_winner_production")
tracker.start_run(run_name="model_comparison")

# Comparer toutes les versions
df = tracker.compare_models("battle_winner_predictor")
print(df)

# Promouvoir manuellement la version 5
tracker.promote_to_production("battle_winner_predictor", version=5)
tracker.end_run()
```

### Sc√©nario 3 : Rollback en cas de Probl√®me

```python
# Si le mod√®le en Production pose probl√®me, revenir √† la version pr√©c√©dente
tracker.promote_to_production("battle_winner_predictor", version=2)

# L'API rechargera automatiquement la version 2 au prochain appel
```

## üß™ Tests

### Test 1 : Enregistrement et Promotion

```bash
# Test avec train_model.py
pytest tests/mlflow/test_model_registry.py::test_register_and_promote -v

# V√©rifie :
# - Enregistrement correct dans le registry
# - Promotion automatique si seuil atteint
# - Artifacts (scalers, metadata) pr√©sents
```

### Test 2 : Chargement depuis l'API

```bash
# Test end-to-end : entra√Ænement ‚Üí registry ‚Üí API load
pytest tests/integration/test_mlflow_to_api.py::test_e2e_mlflow_to_api -v

# V√©rifie :
# 1. Entra√Ænement et enregistrement
# 2. Chargement depuis l'API
# 3. Pr√©diction fonctionnelle
```

### Test 3 : Fallback sur Fichiers Locaux

```bash
# D√©sactiver le registry et v√©rifier fallback
USE_MLFLOW_REGISTRY=false pytest tests/api/test_prediction_service.py -v

# V√©rifie :
# - API charge depuis models/battle_winner_model_v2.pkl
# - Pas d'erreur si MLflow indisponible
```

## üìä M√©triques et Seuils

### Seuils de Promotion Automatique

```python
# Dans run_machine_learning.py et train_model.py
PROMOTION_THRESHOLD = 0.85  # accuracy >= 85%

# Modifier le seuil :
if metrics['test_accuracy'] >= 0.90:  # Seuil plus strict
    tracker.promote_to_production(model_name, version)
```

### M√©triques Logg√©es

Pour chaque mod√®le :
- `train_accuracy` : Pr√©cision sur le jeu d'entra√Ænement
- `test_accuracy` : Pr√©cision sur le jeu de test ‚≠ê (crit√®re de promotion)
- `test_precision` : Pr√©cision (true positives / predicted positives)
- `test_recall` : Rappel (true positives / actual positives)
- `test_f1` : F1-score (harmonic mean of precision and recall)
- `test_roc_auc` : Area Under ROC Curve
- `overfitting` : train_accuracy - test_accuracy

## üêõ Troubleshooting

### Erreur : "No model found in stage 'Production'"

**Cause** : Aucun mod√®le n'a √©t√© promu en Production
**Solution** :
```bash
# Option 1 : Entra√Æner un nouveau mod√®le (auto-promote si accuracy >= 0.85)
python machine_learning/train_model.py --use-gridsearch

# Option 2 : Promouvoir manuellement depuis MLflow UI
# Models ‚Üí battle_winner_predictor ‚Üí Version X ‚Üí Transition to Production

# Option 3 : Utiliser Staging temporairement
export MLFLOW_MODEL_STAGE=Staging
```

### Erreur : "MLflow not available"

**Cause** : MLflow service non d√©marr√© ou inaccessible
**Solution** :
```bash
# V√©rifier que MLflow tourne
docker compose ps mlflow

# V√©rifier la connexion
curl http://localhost:5000/health

# Fallback : API utilise fichiers locaux automatiquement
# (v√©rifier logs API : "‚ö†Ô∏è MLflow not available, using local files")
```

### Mod√®le Non Promu Automatiquement

**Cause** : accuracy < 0.85
**Solution** :
```bash
# Voir les logs d'entra√Ænement :
# "‚ö†Ô∏è Model registered but not promoted (accuracy < 0.85)"

# Option 1 : Am√©liorer le mod√®le (plus de donn√©es, meilleur grid)
python machine_learning/run_machine_learning.py \
    --mode all \
    --tune-hyperparams

# Option 2 : Abaisser le seuil temporairement (dev only)
# Modifier run_machine_learning.py ligne ~1076 :
if metrics['test_accuracy'] >= 0.80:  # Seuil plus bas

# Option 3 : Promotion manuelle
# MLflow UI ‚Üí Models ‚Üí battle_winner_predictor ‚Üí Transition to Production
```

## üåç Variables d'Environnement

### API Service

```bash
# .env ou docker-compose.yml
USE_MLFLOW_REGISTRY=true           # Enable/disable registry loading
MLFLOW_MODEL_NAME=battle_winner_predictor
MLFLOW_MODEL_STAGE=Production      # Production, Staging, Archived
MLFLOW_TRACKING_URI=http://mlflow:5000
```

### ML Training

```bash
# .env
MLFLOW_TRACKING_URI=http://mlflow:5000
MLFLOW_EXPERIMENT_NAME=battle_winner_production
```

## üìö R√©f√©rences

### Fonctions Principales

**mlflow_integration.py** :
- `register_model(model_name, description)` : Enregistre le mod√®le du run actif
- `promote_to_production(model_name, version)` : Promouvoir en Production
- `promote_best_model(model_name, metric, threshold)` : Promotion automatique
- `compare_models(model_name)` : Comparer toutes les versions
- `load_model_from_registry(model_name, stage, version)` : Charger un mod√®le

**prediction_service.py** :
- `PredictionModel.load()` : Charge depuis registry avec fallback local

### Documentation MLflow Officielle

- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)
- [MLflow Python API](https://mlflow.org/docs/latest/python_api/index.html)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)

---

## ‚úÖ R√©sum√©

Le MLflow Model Registry est maintenant int√©gr√© et permet :

1. **Entra√Ænement** ‚Üí Enregistrement automatique avec versioning
2. **Promotion** ‚Üí Automatique si accuracy >= 0.85, sinon manuelle
3. **Chargement API** ‚Üí Depuis registry (Production stage) avec fallback local
4. **Monitoring** ‚Üí MLflow UI pour comparer et g√©rer les versions
5. **Rollback** ‚Üí Revenir √† une version pr√©c√©dente en 1 clic

**Prochaines √©tapes** : Tests complets + docker compose up üöÄ
