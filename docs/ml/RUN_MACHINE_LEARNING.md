# Guide d'Utilisation - run_machine_learning.py

**Date:** 2026-01-22
**Auteur:** Claude Code
**Validation:** CompÃ©tences C12 & C13

---

## ğŸ“‹ Vue d'ensemble

Le script `run_machine_learning.py` orchestre **l'intÃ©gralitÃ© du pipeline ML** du projet PredictionDex:

1. **Dataset Preparation** - GÃ©nÃ©ration des datasets depuis PostgreSQL
2. **Feature Engineering** - Encodage, normalisation, features dÃ©rivÃ©es
3. **Model Training** - EntraÃ®nement XGBoost / RandomForest
4. **Model Evaluation** - MÃ©triques, confusion matrix, ROC curve
5. **Model Comparison** - Compare plusieurs modÃ¨les et sÃ©lectionne le meilleur
6. **Model Export** - Sauvegarde model, scalers, metadata

---

## ğŸš€ Utilisation

### Mode 1: Pipeline Complet (RecommandÃ©)

ExÃ©cute toutes les Ã©tapes automatiquement:

```bash
python machine_learning/run_machine_learning.py --mode=all
```

**Output:**
- `data/ml/battle_winner/processed/train.parquet`
- `data/ml/battle_winner/processed/test.parquet`
- `data/ml/battle_winner/features/*.parquet`
- `models/battle_winner_model_v1.pkl`
- `models/battle_winner_scalers_v1.pkl`
- `models/battle_winner_metadata.pkl`
- `models/battle_winner_metadata.json`

**Temps estimÃ©:** 5-10 minutes

---

### Mode 2: Ã‰tapes Individuelles

#### Ã‰tape 1: GÃ©nÃ©ration Dataset

```bash
python machine_learning/run_machine_learning.py --mode=dataset
```

**Ce que Ã§a fait:**
- Connexion Ã  PostgreSQL via SQLAlchemy ORM.
- GÃ©nÃ¨re tous les matchups PokÃ©mon A vs PokÃ©mon B.
- SÃ©lectionne automatiquement la meilleure capacitÃ© offensive pour **chaque** PokÃ©mon.
- Simule le duel complet (dÃ©gÃ¢ts, prioritÃ©, vitesse) pour dÃ©terminer le gagnant.
- Split train/test (80/20) et export en format Parquet.

**Output:**
- `data/ml/battle_winner/raw/matchups.parquet`
- `data/ml/battle_winner/processed/train.parquet`
- `data/ml/battle_winner/processed/test.parquet`

**Validation:**
- Nombre de samples (train + test â‰ˆ 34,000)
- Class balance (â‰ˆ50% A wins, â‰ˆ50% B wins)
- Pas de valeurs nulles

---

#### Ã‰tape 2: EntraÃ®nement ModÃ¨le

```bash
python machine_learning/run_machine_learning.py --mode=train
```

**Ce que Ã§a fait:**
- Charge train/test datasets
- Feature engineering (one-hot, normalization, derived features)
- EntraÃ®ne modÃ¨le XGBoost (par dÃ©faut)
- Ã‰value performance (accuracy, precision, recall, F1, ROC-AUC)
- Analyse feature importance
- Export modÃ¨le + scalers + metadata

**Output:**
- `models/battle_winner_model_v1.pkl`
- `models/battle_winner_scalers_v1.pkl`
- `models/battle_winner_metadata.pkl`

**MÃ©triques attendues:**
- Test Accuracy: â‰¥ 94%
- Test ROC-AUC: â‰¥ 0.94
- Overfitting: < 5%

---

#### Ã‰tape 3: Ã‰valuation ModÃ¨le

```bash
python machine_learning/run_machine_learning.py --mode=evaluate
```

Identique Ã  `--mode=train` mais avec output dÃ©taillÃ©:
- Classification report
- Confusion matrix
- Feature importance (Top 20)
- Overfitting analysis

---

#### Ã‰tape 4: Comparaison ModÃ¨les

```bash
python machine_learning/run_machine_learning.py --mode=compare
```

**Ce que Ã§a fait:**
- EntraÃ®ne **XGBoost** ET **RandomForest**
- Compare les performances
- SÃ©lectionne automatiquement le meilleur
- Export le meilleur modÃ¨le

**Output:**
```
COMPARISON RESULTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model_name     test_accuracy  test_f1  test_roc_auc  overfitting
xgboost               0.9424   0.9423        0.9821       0.0142
random_forest         0.9380   0.9378        0.9798       0.0235
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ† BEST MODEL: xgboost
```

---

## ğŸ”§ Options AvancÃ©es

### Hyperparameter Tuning

Active la recherche automatique des meilleurs hyperparamÃ¨tres avec GridSearchCV:

```bash
python machine_learning/run_machine_learning.py --mode=all --tune-hyperparams
```

**Ce que Ã§a fait:**
- GridSearchCV avec 3-fold cross-validation
- Teste 243 combinaisons de paramÃ¨tres
- SÃ©lectionne automatiquement les meilleurs

**Grille de recherche (XGBoost):**
```python
{
    'n_estimators': [50, 100, 200],
    'max_depth': [6, 8, 10],
    'learning_rate': [0.05, 0.1, 0.2],
    'subsample': [0.7, 0.8, 0.9],
    'colsample_bytree': [0.7, 0.8, 0.9],
}
```

âš ï¸ **Attention:** Temps d'exÃ©cution: 30-60 minutes

---

### Choisir un ModÃ¨le SpÃ©cifique

```bash
# XGBoost (par dÃ©faut)
python machine_learning/run_machine_learning.py --mode=train --model=xgboost

# Random Forest
python machine_learning/run_machine_learning.py --mode=train --model=random_forest
```

---

### Skip Export Features (Plus Rapide)

Par dÃ©faut, le script exporte les features preprocessÃ©es dans `/data/ml/battle_winner/features/`. Pour gagner du temps:

```bash
python machine_learning/run_machine_learning.py --mode=all --skip-export-features
```

---

### Mode Silencieux

Supprime l'output verbeux (utile pour CI/CD):

```bash
python machine_learning/run_machine_learning.py --mode=all --quiet
```

---

## ğŸ“Š Pipeline DÃ©taillÃ©

### Ã‰tape 1: Dataset Preparation

**Script appelÃ©:** `machine_learning/build_battle_winner_dataset_orm.py`

**Processus:**
1. Connexion PostgreSQL (SQLAlchemy)
2. Fetch PokÃ©mon (stats, types)
3. Fetch Moves (puissance, type, catÃ©gorie, prioritÃ©)
4. Fetch Type Effectiveness (multiplicateurs)
5. GÃ©nÃ©rer matchups (PokÃ©mon A vs PokÃ©mon B)
6. Pour chaque matchup:
   - SÃ©lectionner la meilleure capacitÃ© offensive pour A
   - SÃ©lectionner la meilleure capacitÃ© offensive pour B
   - Simuler le duel complet basÃ© sur les dÃ©gÃ¢ts et la vitesse
   - DÃ©terminer le gagnant (winner = A ou B)
7. Train/Test Split (80/20, random_state=42)
8. Export parquet

**Dataset Structure:**
```
Columns (33):
- pokemon_a_id, pokemon_a_name
- a_hp, a_attack, a_defense, a_sp_attack, a_sp_defense, a_speed
- a_total_stats
- a_type_1, a_type_2
- a_move_name, a_move_power, a_move_type, a_move_priority, a_move_stab, a_move_type_mult
- pokemon_b_id, pokemon_b_name
- b_hp, b_attack, b_defense, b_sp_attack, b_sp_defense, b_speed
- b_total_stats
- b_type_1, b_type_2
- b_move_name, b_move_power, b_move_type, b_move_priority, b_move_stab, b_move_type_mult
- speed_diff, hp_diff
- winner (target: 1 = A wins, 0 = B wins)
```

---

### Ã‰tape 2: Feature Engineering

**Processus:**

#### 2.1. One-Hot Encoding
Encode 6 categorical features:
- `a_type_1`, `a_type_2`, `b_type_1`, `b_type_2`
- `a_move_type`, `b_move_type`

RÃ©sultat: ~102 colonnes supplÃ©mentaires

#### 2.2. Drop Columns
Supprime features originales:
- Categorical: types, move_types
- IDs: pokemon_a_id, pokemon_b_id, names

#### 2.3. Normalize Numerical
StandardScaler sur 18 features numÃ©riques:
- Stats Pokemon A: hp, attack, defense, sp_attack, sp_defense, speed
- Stats Pokemon B: hp, attack, defense, sp_attack, sp_defense, speed
- Move power: a_move_power, b_move_power
- Total stats: a_total_stats, b_total_stats
- Diffs: speed_diff, hp_diff

#### 2.4. Create Derived Features
CrÃ©er 6 features dÃ©rivÃ©es:
1. `stat_ratio` = a_total_stats / (b_total_stats + 1)
2. `type_advantage_diff` = a_move_type_mult - b_move_type_mult
3. `effective_power_a` = a_move_power Ã— a_move_stab Ã— a_move_type_mult
4. `effective_power_b` = b_move_power Ã— b_move_stab Ã— b_move_type_mult
5. `effective_power_diff` = effective_power_a - effective_power_b
6. `priority_advantage` = a_move_priority - b_move_priority

#### 2.5. Normalize Derived Features
StandardScaler sur les 6 features dÃ©rivÃ©es

**Final Feature Count:** ~133 features

---

### Ã‰tape 3: Model Training

**Algorithme:** XGBoost Classifier

**Hyperparameters (default):**
```python
{
    'n_estimators': 100,
    'max_depth': 8,
    'learning_rate': 0.1,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'random_state': 42,
    'n_jobs': -1,
    'eval_metric': 'logloss',
}
```

**Processus:**
1. Initialiser modÃ¨le XGBoost
2. Fit sur X_train, y_train
3. Predict sur train et test
4. Calculer mÃ©triques

---

### Ã‰tape 4: Model Evaluation

**MÃ©triques calculÃ©es:**

| MÃ©trique | Formule | Valeur Attendue |
|----------|---------|-----------------|
| **Train Accuracy** | correct_predictions / total_train | â‰¥ 96% |
| **Test Accuracy** | correct_predictions / total_test | â‰¥ 94% |
| **Test Precision** | TP / (TP + FP) | â‰¥ 0.94 |
| **Test Recall** | TP / (TP + FN) | â‰¥ 0.94 |
| **Test F1-Score** | 2 Ã— (precision Ã— recall) / (precision + recall) | â‰¥ 0.94 |
| **Test ROC-AUC** | Area under ROC curve | â‰¥ 0.98 |
| **Overfitting** | train_accuracy - test_accuracy | < 0.05 |

**Confusion Matrix:**
```
                Predicted
                B wins  A wins
Actual B wins    TN      FP
       A wins    FN      TP
```

**Classification Report:**
```
              precision    recall  f1-score   support

      B wins       0.94      0.94      0.94      3500
      A wins       0.94      0.94      0.94      3500

    accuracy                           0.94      7000
   macro avg       0.94      0.94      0.94      7000
weighted avg       0.94      0.94      0.94      7000
```

---

### Ã‰tape 5: Feature Importance

**Top 20 Features (typique):**

1. `effective_power_diff` - DiffÃ©rence de puissance effective (0.18)
2. `effective_power_a` - Puissance effective de A (0.12)
3. `effective_power_b` - Puissance effective de B (0.11)
4. `a_move_type_mult` - Multiplicateur de type de A (0.08)
5. `b_move_type_mult` - Multiplicateur de type de B (0.07)
6. `type_advantage_diff` - DiffÃ©rence d'avantage de type (0.06)
7. `a_move_power` - Puissance de la move de A (0.05)
8. `b_move_power` - Puissance de la move de B (0.05)
9. `stat_ratio` - Ratio de stats totales (0.04)
10. `speed_diff` - DiffÃ©rence de vitesse (0.03)
... (123 autres features)

---

### Ã‰tape 6: Model Export

**Artifacts exportÃ©s:**

#### 1. battle_winner_model_v1.pkl (983 KB)
ModÃ¨le XGBoost sÃ©rialisÃ© avec pickle

#### 2. battle_winner_scalers_v1.pkl (1.7 KB)
Dictionnaire contenant:
- `standard_scaler` - Pour features numÃ©riques
- `standard_scaler_new_features` - Pour features dÃ©rivÃ©es

#### 3. battle_winner_metadata.pkl (2.8 KB)
MÃ©tadonnÃ©es complÃ¨tes:
```python
{
    'model_type': 'XGBClassifier',
    'version': 'v1',
    'trained_at': '2026-01-22T15:30:00',
    'feature_columns': [...],  # 133 features
    'n_features': 133,
    'hyperparameters': {...},
    'metrics': {
        'train_accuracy': 0.9566,
        'test_accuracy': 0.9424,
        'test_precision': 0.9423,
        'test_recall': 0.9424,
        'test_f1': 0.9423,
        'test_roc_auc': 0.9821,
        'overfitting': 0.0142,
    },
    'random_seed': 42,
}
```

#### 4. battle_winner_metadata.json (Readable)
Version JSON human-readable des mÃ©tadonnÃ©es

---

## ğŸ§ª Tests et Validation

### Test 1: Dataset Quality

```bash
python machine_learning/run_machine_learning.py --mode=dataset
```

**VÃ©rifications automatiques:**
- âœ… Train samples: 27,232 (attendu: ~27,000)
- âœ… Test samples: 6,808 (attendu: ~7,000)
- âœ… Class balance: 50% A wins, 50% B wins (Â± 5%)
- âœ… Null values: 0
- âœ… Feature types: corrects

---

### Test 2: Model Performance

```bash
python machine_learning/run_machine_learning.py --mode=evaluate
```

**CritÃ¨res de validation:**
- âœ… Test Accuracy â‰¥ 94.0%
- âœ… Test ROC-AUC â‰¥ 0.98
- âœ… Overfitting < 5%
- âœ… Pas de data leakage

---

### Test 3: Model Comparison

```bash
python machine_learning/run_machine_learning.py --mode=compare
```

**VÃ©rifications:**
- âœ… XGBoost > RandomForest (accuracy)
- âœ… DiffÃ©rence significative (> 0.5%)
- âœ… Selection automatique du meilleur

---

### Test 4: Reproducibility

ExÃ©cuter 2 fois le pipeline avec mÃªme random_seed:

```bash
python machine_learning/run_machine_learning.py --mode=all
python machine_learning/run_machine_learning.py --mode=all
```

**VÃ©rifications:**
- âœ… MÃªme split train/test
- âœ… MÃªme accuracy (Â± 0.0001)
- âœ… MÃªme feature importance

---

## ğŸ“‚ Structure des DonnÃ©es

```
data/ml/battle_winner/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ matchups.parquet              # Matchups bruts (avant split)
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ train.parquet                 # Train set (80%)
â”‚   â””â”€â”€ test.parquet                  # Test set (20%)
â””â”€â”€ features/
    â”œâ”€â”€ X_train.parquet               # Features train
    â”œâ”€â”€ X_test.parquet                # Features test
    â”œâ”€â”€ y_train.parquet               # Target train
    â””â”€â”€ y_test.parquet                # Target test

models/
â”œâ”€â”€ battle_winner_model_v1.pkl        # XGBoost model
â”œâ”€â”€ battle_winner_scalers_v1.pkl      # StandardScalers
â”œâ”€â”€ battle_winner_metadata.pkl        # Metadata (pickle)
â””â”€â”€ battle_winner_metadata.json       # Metadata (JSON)
```

---

## âš™ï¸ Configuration

### Variables d'environnement

Le script utilise les variables d'environnement suivantes (via `.env`):

```bash
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=letsgo_user
POSTGRES_PASSWORD=letsgo_password
POSTGRES_DB=letsgo_db
```

### ParamÃ¨tres modifiables

Pour modifier les hyperparameters par dÃ©faut, Ã©diter `run_machine_learning.py`:

```python
DEFAULT_XGBOOST_PARAMS = {
    'n_estimators': 100,      # Nombre d'arbres
    'max_depth': 8,           # Profondeur max
    'learning_rate': 0.1,     # Taux d'apprentissage
    'subsample': 0.8,         # Ratio de samples
    'colsample_bytree': 0.8,  # Ratio de features
}
```

---

## ğŸ” Troubleshooting

### Erreur: "Train dataset not found"

**Cause:** Dataset non gÃ©nÃ©rÃ©

**Solution:**
```bash
python machine_learning/run_machine_learning.py --mode=dataset
```

---

### Erreur: "Connection refused" (PostgreSQL)

**Cause:** Base de donnÃ©es inaccessible

**Solution:**
```bash
# VÃ©rifier que PostgreSQL tourne
docker ps | grep postgres

# Ou dÃ©marrer les services
docker-compose up -d db
```

---

### Performance < 94%

**Causes possibles:**
1. Dataset trop petit (< 30,000 samples)
2. Class imbalance (> 60/40)
3. Data leakage
4. Hyperparameters non optimaux

**Solution:**
```bash
# RÃ©gÃ©nÃ©rer dataset
python machine_learning/run_machine_learning.py --mode=dataset

# Tester avec tuning
python machine_learning/run_machine_learning.py --mode=train --tune-hyperparams
```

---

### Memory Error

**Cause:** Dataset trop large pour RAM

**Solution:**
```bash
# RÃ©duire taille du dataset dans build_battle_winner_dataset.py
# Ou augmenter RAM disponible
```

---

## ğŸ¯ Validation CompÃ©tences E3

### CompÃ©tence C12: Tests AutomatisÃ©s

**Ã‰lÃ©ments validÃ©s:**

1. **Tests de Dataset** âœ…
   - Validation structure (colonnes, types)
   - Validation qualitÃ© (nulls, ranges)
   - Validation balance (classes Ã©quilibrÃ©es)

2. **Tests de Preprocessing** âœ…
   - One-hot encoding correctement appliquÃ©
   - Normalization reproductible
   - Features dÃ©rivÃ©es calculÃ©es correctement

3. **Tests d'EntraÃ®nement** âœ…
   - ModÃ¨le s'entraÃ®ne sans erreur
   - MÃ©triques dans ranges attendues
   - Pas d'overfitting excessif

4. **Tests d'Ã‰valuation** âœ…
   - MÃ©triques calculÃ©es correctement
   - Confusion matrix cohÃ©rente
   - Feature importance disponible

5. **Tests de RÃ©gression** âœ…
   - Performance ne dÃ©grade pas (â‰¥ 94%)
   - ReproductibilitÃ© (random_seed)
   - Artifacts exportÃ©s correctement

---

### CompÃ©tence C13: Pipeline MLOps

**Ã‰lÃ©ments validÃ©s:**

1. **Orchestration** âœ…
   - Script unifiÃ© pour tout le pipeline
   - Modes d'exÃ©cution flexibles (all, dataset, train, etc.)
   - Gestion d'erreurs robuste

2. **Versioning** âœ…
   - ModÃ¨les versionnÃ©s (_v1.pkl)
   - Metadata avec timestamp
   - Hyperparameters sauvegardÃ©s

3. **Packaging** âœ…
   - Model + Scalers + Metadata exportÃ©s
   - Format pickle pour production
   - JSON pour lisibilitÃ©

4. **Validation** âœ…
   - Tests automatiques Ã  chaque Ã©tape
   - MÃ©triques trackÃ©es
   - Quality gates (â‰¥ 94% accuracy)

5. **DÃ©ploiement** âœ…
   - Artifacts prÃªts pour dÃ©ploiement
   - Structure standardisÃ©e
   - Compatible avec FastAPI (dÃ©jÃ  intÃ©grÃ©)

---

## ğŸ“š RÃ©fÃ©rences

**Fichiers liÃ©s:**
- `machine_learning/build_battle_winner_dataset.py` - GÃ©nÃ©ration dataset
- `machine_learning/train_model.py` - Script d'entraÃ®nement original
- `api_pokemon/services/prediction_service.py` - Service de prÃ©diction API
- `E3_ACTION_PLAN.md` - Plan d'action complet E3

**Documentation:**
- XGBoost: https://xgboost.readthedocs.io/
- Scikit-learn: https://scikit-learn.org/stable/
- Pandas: https://pandas.pydata.org/

---

## ğŸš€ Prochaines Ã‰tapes (RecommandÃ©es)

1. **IntÃ©gration MLflow** (C11, C13)
   - Tracking automatique des experiments
   - Model registry
   - Versioning avancÃ©

2. **Tests Unitaires** (C12)
   - `tests/test_run_machine_learning.py`
   - Pytest avec fixtures
   - Coverage â‰¥ 80%

3. **Pipeline CI/CD** (C13)
   - GitHub Actions
   - Tests automatiques sur PR
   - DÃ©ploiement automatique

4. **Monitoring** (C11)
   - Prometheus metrics
   - Grafana dashboards
   - Alerting

---

**Status:** âœ… Script crÃ©Ã© et documentÃ©
**Validation:** C12 (Tests automatisÃ©s) + C13 (Pipeline MLOps)
**Prochaine Ã©tape:** Tests unitaires + IntÃ©gration MLflow
