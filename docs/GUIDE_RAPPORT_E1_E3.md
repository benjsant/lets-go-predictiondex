# üìù Guide de R√©daction du Rapport Projet E1 + E3

> **Certification RNCP37827 "D√©veloppeur en Intelligence Artificielle"**  
> Projet : **PredictionDex - Pr√©dicteur de Combats Pok√©mon Let's Go**

---

## üìå Exigences Officielles (R√®glement Simplon)

### Structure des √©valuations

| √âvaluation | Bloc | Comp√©tences | Dur√©e soutenance |
|------------|------|-------------|------------------|
| **E1** | Bloc 1 (RNCP37827BC01) | C1-C5 | 15 min pr√©sentation + 10 min Q/R |
| E2 | Bloc 2 (RNCP37827BC02) | C6-C8 | 15 min |
| **E3** | Bloc 2 (RNCP37827BC02) | C9-C13 | 20 min + d√©monstration |
| E4 | Bloc 3 (RNCP37827BC03) | C14-C19 | 20 min + d√©mo |
| E5 | Bloc 3 (RNCP37827BC03) | C20-C21 | 10 min |

> üí° **Point important** : *"Un projet unique peut √™tre pr√©sent√© pour les √©valuations E1, E3 et E4, agr√©geant ces modalit√©s."* ‚Äî C'est exactement ce que permet PredictionDex !

### Ce que le jury attend

**Pour E1 (Mise en situation 1)** :
- Pr√©senter le **flux automatis√© de collecte** depuis diff√©rentes sources
- Pr√©senter les **requ√™tes de nettoyage et mise en forme**
- Pr√©senter la **cr√©ation de la base de donn√©es**
- Pr√©senter l'**exposition des donn√©es via API**

**Pour E3 (Mise en situation 2)** :
- Pr√©senter le d√©veloppement d'une **API encapsulant un mod√®le d'IA**
- Pr√©senter les **√©tapes d'int√©gration** dans l'application
- Pr√©senter le **monitorage et les tests** du mod√®le
- Pr√©senter la **cha√Æne de livraison continue**
- **Effectuer une d√©monstration** des diff√©rents composants

---

## üìã Structure Recommand√©e du Rapport Combin√©

Le rapport combin√© E1+E3 doit d√©montrer la ma√Ætrise de l'ensemble des comp√©tences des deux blocs tout en pr√©sentant un projet coh√©rent de bout en bout.

---

## üéØ Page de Garde

```
RAPPORT DE PROJET
Certification RNCP Concepteur D√©veloppeur en Intelligence Artificielle

Blocs de comp√©tences : E1 (API & Base de donn√©es) + E3 (Mise √† disposition de l'IA)

Projet : PredictionDex
Pr√©dicteur de r√©sultats de combats Pok√©mon Let's Go

Candidat : [Votre nom]
Date : [Date de rendu]
Organisme de formation : Simplon
```

---

## üìñ Table des Mati√®res Sugg√©r√©e

```
1. Introduction et Contexte du Projet
   1.1 Pr√©sentation du projet
   1.2 Objectifs m√©tier
   1.3 P√©rim√®tre technique
   1.4 Planning et m√©thodologie

2. BLOC E1 : Collecte et Gestion des Donn√©es
   2.1 Architecture des donn√©es (C1)
   2.2 Pipeline ETL et collecte (C2)
   2.3 Mod√©lisation de la base de donn√©es (C3)
   2.4 D√©veloppement de l'API REST (C4)
   2.5 Int√©gration et d√©ploiement (C5)

3. BLOC E3 : Mise √† Disposition de l'IA
   3.1 Exposition des mod√®les ML via API (C9)
   3.2 Int√©gration dans l'application (C10)
   3.3 Monitoring et d√©tection de d√©rives (C11)
   3.4 Tests et validation (C12)
   3.5 Pipeline CI/CD (C13)

4. Synth√®se et Perspectives
   4.1 Bilan technique
   4.2 Difficult√©s rencontr√©es et solutions
   4.3 Axes d'am√©lioration
   4.4 Conclusion

Annexes
```

---

## üìÑ D√©tail des Sections

### 1. Introduction et Contexte du Projet (2-3 pages)

#### 1.1 Pr√©sentation du projet
**Contenu pour PredictionDex :**
- Contexte : Pr√©diction de r√©sultats de combats Pok√©mon Let's Go Pikachu/Evoli
- Probl√©matique : Comment pr√©dire le vainqueur d'un combat bas√© sur les statistiques des Pok√©mon ?
- Solution : Plateforme MLOps compl√®te int√©grant collecte de donn√©es, ML et interface utilisateur

#### 1.2 Objectifs m√©tier
- Permettre aux joueurs de simuler des combats
- Analyser les forces/faiblesses des Pok√©mon
- Fournir des recommandations de strat√©gie

#### 1.3 P√©rim√®tre technique
**Stack technologique :**
| Composant | Technologies |
|-----------|-------------|
| Backend | Python 3.11, FastAPI 0.109 |
| Base de donn√©es | PostgreSQL 15, SQLAlchemy 2.0 |
| Machine Learning | XGBoost 2.0, scikit-learn 1.4 |
| MLOps | MLflow 2.18, Prometheus, Grafana |
| Frontend | Streamlit 1.39 |
| DevOps | Docker Compose, GitHub Actions |

#### 1.4 Planning et m√©thodologie
- M√©thodologie agile
- Sprints de d√©veloppement
- Revue de code et tests continus

---

### 2. BLOC E1 : Collecte et Gestion des Donn√©es (8-10 pages)

#### 2.1 Architecture des donn√©es (C1 - Recueillir les besoins)

**√Ä d√©montrer :**
- Analyse du besoin m√©tier
- Identification des sources de donn√©es
- Volum√©trie estim√©e

**Contenu PredictionDex :**
```
Sources de donn√©es identifi√©es :
‚îú‚îÄ‚îÄ API Pok√©API (donn√©es officielles Pok√©mon)
‚îú‚îÄ‚îÄ Fichiers CSV (datasets de combats)
‚îî‚îÄ‚îÄ Scraping Pokepedia (donn√©es fran√ßaises)

Volume : ~150 Pok√©mon, ~165 attaques, milliers de combats simul√©s
```

**Livrables √† inclure :**
- Sch√©ma des flux de donn√©es
- Matrice des sources vs besoins
- Screenshot de l'analyse des donn√©es brutes

---

#### 2.2 Pipeline ETL et collecte (C2 - Collecter les donn√©es)

**√Ä d√©montrer :**
- Scripts de collecte automatis√©s
- Transformation des donn√©es
- Qualit√© et validation

**Contenu PredictionDex :**

```python
# Exemple de code ETL √† inclure (simplifi√©)
# etl_pokemon/pipeline.py

class ETLPipeline:
    """Pipeline complet d'extraction, transformation, chargement"""
    
    def extract_from_pokeapi(self) -> List[dict]:
        """Extraction depuis Pok√©API"""
        ...
    
    def transform_pokemon_data(self, raw_data: dict) -> Pokemon:
        """Transformation et normalisation"""
        ...
    
    def load_to_database(self, pokemon: Pokemon) -> None:
        """Chargement en base PostgreSQL"""
        ...
```

**Livrables √† inclure :**
- Diagramme du pipeline ETL
- Captures d'√©cran du scraper
- Logs d'ex√©cution
- M√©triques de qualit√© des donn√©es

---

#### 2.3 Mod√©lisation de la base de donn√©es (C3 - Mod√©liser les donn√©es)

**√Ä d√©montrer :**
- Mod√®le Conceptuel de Donn√©es (MCD)
- Mod√®le Physique de Donn√©es (MPD)
- Scripts de cr√©ation

**Contenu PredictionDex :**

```
Tables principales (11 tables) :
‚îú‚îÄ‚îÄ pokemons (id, name, hp, attack, defense, ...)
‚îú‚îÄ‚îÄ moves (id, name, power, accuracy, type_id, ...)
‚îú‚îÄ‚îÄ types (id, name)
‚îú‚îÄ‚îÄ pokemon_moves (pokemon_id, move_id)
‚îú‚îÄ‚îÄ pokemon_types (pokemon_id, type_id)
‚îú‚îÄ‚îÄ type_effectiveness (attacking_type_id, defending_type_id, multiplier)
‚îú‚îÄ‚îÄ evolutions (pokemon_id, evolves_to_id, method)
‚îú‚îÄ‚îÄ battles (id, pokemon1_id, pokemon2_id, winner_id, scenario)
‚îú‚îÄ‚îÄ ml_predictions (id, battle_id, predicted_winner, confidence)
‚îú‚îÄ‚îÄ ml_models (id, name, version, accuracy, created_at)
‚îî‚îÄ‚îÄ monitoring_metrics (id, timestamp, metric_name, value)
```

**Livrables √† inclure :**
- Diagramme MCD (outil : dbdiagram.io, draw.io)
- Diagramme MPD avec relations
- Script SQL de cr√©ation des tables
- Screenshot pgAdmin/DBeaver

---

#### 2.4 D√©veloppement de l'API REST (C4 - D√©velopper une API)

**√Ä d√©montrer :**
- Architecture de l'API
- Endpoints CRUD
- Documentation OpenAPI

**Contenu PredictionDex :**

```yaml
# Endpoints principaux
/api/v1/pokemon:
  GET: Liste des Pok√©mon
  GET /{id}: D√©tail d'un Pok√©mon
  POST: Cr√©ation (admin)
  PUT /{id}: Mise √† jour (admin)
  DELETE /{id}: Suppression (admin)

/api/v1/moves:
  GET: Liste des attaques
  GET /{id}: D√©tail d'une attaque

/api/v1/types:
  GET: Liste des types
  GET /effectiveness: Matrice d'efficacit√©

/api/v1/battle/predict:
  POST: Pr√©diction de combat (appel ML)
```

**Livrables √† inclure :**
- Capture Swagger UI (/docs)
- Exemples de requ√™tes/r√©ponses (Postman/curl)
- Code des routes principales
- Tests unitaires des endpoints

---

#### 2.5 Int√©gration et d√©ploiement (C5 - Int√©grer une solution)

**√Ä d√©montrer :**
- Conteneurisation
- Orchestration
- Configuration

**Contenu PredictionDex :**

```yaml
# docker-compose.yml - Services E1
services:
  postgres:
    image: postgres:15
    volumes:
      - postgres_data:/var/lib/postgresql/data
    
  api:
    build: 
      context: .
      dockerfile: docker/Dockerfile.api
    ports:
      - "8000:8000"
    depends_on:
      - postgres
    
  pgadmin:
    image: dpage/pgadmin4
    ports:
      - "5050:80"
```

**Livrables √† inclure :**
- Architecture Docker (sch√©ma)
- Dockerfile comment√©
- Captures des services en ex√©cution
- Logs de d√©ploiement

---

### 3. BLOC E3 : Mise √† Disposition de l'IA (8-10 pages)

#### 3.1 Exposition des mod√®les ML via API (C9 - D√©velopper une API ML)

**√Ä d√©montrer :**
- Endpoints de pr√©diction
- S√©rialisation du mod√®le
- Gestion des versions

**Contenu PredictionDex :**

```python
# api_pokemon/routes/prediction_route.py

@router.post("/predict")
async def predict_battle(
    battle: BattleRequest,
    model_version: str = "v2"
) -> PredictionResponse:
    """
    Pr√©dit le vainqueur d'un combat Pok√©mon.
    
    - Charge le mod√®le XGBoost depuis MLflow
    - Applique le feature engineering
    - Retourne la pr√©diction avec confiance
    """
    model = load_model(f"battle_winner_{model_version}")
    features = extract_features(battle)
    prediction = model.predict(features)
    probability = model.predict_proba(features)
    
    return PredictionResponse(
        winner=prediction,
        confidence=probability.max(),
        model_version=model_version
    )
```

**M√©triques du mod√®le v2 :**
| M√©trique | Valeur |
|----------|--------|
| Accuracy | 88.23% |
| Precision | 87.8% |
| Recall | 88.5% |
| F1-Score | 88.1% |

**Livrables √† inclure :**
- Code de l'endpoint de pr√©diction
- Format des requ√™tes/r√©ponses
- Screenshot MLflow (mod√®les versionn√©s)
- Comparaison des versions de mod√®les

---

#### 3.2 Int√©gration dans l'application (C10 - Int√©grer l'IA)

**√Ä d√©montrer :**
- Interface utilisateur
- Appels API depuis le frontend
- Exp√©rience utilisateur

**Contenu PredictionDex :**

```python
# interface/pages/battle_predictor.py

def display_battle_predictor():
    """Page Streamlit de pr√©diction de combat"""
    
    col1, col2 = st.columns(2)
    
    with col1:
        pokemon1 = st.selectbox("Pok√©mon 1", pokemon_list)
        moves1 = st.multiselect("Attaques", get_moves(pokemon1))
    
    with col2:
        pokemon2 = st.selectbox("Pok√©mon 2", pokemon_list)
        moves2 = st.multiselect("Attaques", get_moves(pokemon2))
    
    if st.button("Pr√©dire le vainqueur"):
        result = call_prediction_api(pokemon1, pokemon2, moves1, moves2)
        display_result_with_animation(result)
```

**Livrables √† inclure :**
- Captures d'√©cran de l'interface Streamlit
- Diagramme de s√©quence (User ‚Üí Streamlit ‚Üí API ‚Üí ML)
- Code d'int√©gration
- D√©monstration (vid√©o ou GIF)

---

#### 3.3 Monitoring et d√©tection de d√©rives (C11 - Surveiller l'IA)

**√Ä d√©montrer :**
- M√©triques collect√©es
- Dashboards de monitoring
- Alertes configur√©es

**Contenu PredictionDex :**

```python
# api_pokemon/monitoring/drift_detection.py

class DriftDetector:
    """D√©tection de d√©rive des donn√©es et du mod√®le"""
    
    def detect_data_drift(self, current_data: pd.DataFrame) -> DriftReport:
        """D√©tecte les d√©rives statistiques des features"""
        reference = self.load_reference_distribution()
        
        drift_results = {}
        for feature in MONITORED_FEATURES:
            ks_stat, p_value = ks_2samp(
                reference[feature], 
                current_data[feature]
            )
            drift_results[feature] = {
                "is_drifted": p_value < 0.05,
                "ks_statistic": ks_stat,
                "p_value": p_value
            }
        
        return DriftReport(results=drift_results)
    
    def detect_prediction_drift(self) -> bool:
        """D√©tecte les changements dans la distribution des pr√©dictions"""
        ...
```

**Stack de monitoring :**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Prometheus ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Grafana ‚îÇ
‚îÇ  (m√©triques)‚îÇ     ‚îÇ  (stockage)‚îÇ     ‚îÇ (visu)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Livrables √† inclure :**
- Captures dashboards Grafana
- Configuration Prometheus
- Code de d√©tection de drift
- Exemple d'alerte d√©clench√©e

---

#### 3.4 Tests et validation (C12 - Tester la solution)

**√Ä d√©montrer :**
- Strat√©gie de tests
- Couverture de code
- Tests ML sp√©cifiques

**Contenu PredictionDex :**

```
Structure des tests (252 tests, 82% couverture) :
tests/
‚îú‚îÄ‚îÄ api/           # Tests endpoints FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ test_pokemon_route.py
‚îÇ   ‚îú‚îÄ‚îÄ test_prediction_route.py
‚îÇ   ‚îî‚îÄ‚îÄ test_moves_route.py
‚îú‚îÄ‚îÄ ml/            # Tests mod√®les ML
‚îÇ   ‚îú‚îÄ‚îÄ test_model_training.py
‚îÇ   ‚îú‚îÄ‚îÄ test_feature_engineering.py
‚îÇ   ‚îî‚îÄ‚îÄ test_predictions.py
‚îú‚îÄ‚îÄ integration/   # Tests bout-en-bout
‚îÇ   ‚îú‚îÄ‚îÄ test_full_pipeline.py
‚îÇ   ‚îî‚îÄ‚îÄ test_api_to_ml.py
‚îú‚îÄ‚îÄ monitoring/    # Tests monitoring
‚îÇ   ‚îî‚îÄ‚îÄ test_drift_detection.py
‚îî‚îÄ‚îÄ conftest.py    # Fixtures partag√©es
```

**Exemple de test ML :**
```python
# tests/ml/test_predictions.py

def test_model_prediction_accuracy():
    """V√©rifie que le mod√®le maintient une accuracy > 85%"""
    model = load_production_model()
    X_test, y_test = load_test_dataset()
    
    accuracy = model.score(X_test, y_test)
    
    assert accuracy >= 0.85, f"Accuracy {accuracy} < seuil 85%"

def test_prediction_consistency():
    """V√©rifie la coh√©rence des pr√©dictions"""
    # M√™me entr√©e = m√™me sortie
    result1 = predict(pokemon1_id=25, pokemon2_id=6)
    result2 = predict(pokemon1_id=25, pokemon2_id=6)
    
    assert result1.winner == result2.winner
```

**Livrables √† inclure :**
- Rapport pytest avec couverture
- Captures GitHub Actions (tests CI)
- Code des tests cl√©s
- Matrice de tests (unitaires, int√©gration, E2E)

---

#### 3.5 Pipeline CI/CD (C13 - D√©ployer en continu)

**√Ä d√©montrer :**
- Workflows automatis√©s
- D√©ploiement continu
- Gestion des environnements

**Contenu PredictionDex :**

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: pytest --cov=. --cov-report=xml
      - name: Upload coverage
        uses: codecov/codecov-action@v4

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Build Docker images
        run: docker-compose build
      - name: Push to registry
        run: docker-compose push

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to production
        run: ./scripts/deploy.sh
```

**Workflows GitHub Actions :**
| Workflow | D√©clencheur | Actions |
|----------|-------------|---------|
| CI Tests | Push/PR | Tests + Couverture |
| Build | Merge main | Build Docker |
| Security | Quotidien | Scan vuln√©rabilit√©s |
| MLflow | Push ML/ | Versioning mod√®les |
| Docs | Push docs/ | MkDocs deploy |
| Release | Tag | Publication GitHub |

**Livrables √† inclure :**
- Captures GitHub Actions (runs r√©ussis)
- Fichiers YAML des workflows
- Sch√©ma du pipeline CI/CD
- Logs de d√©ploiement

---

### 4. Synth√®se et Perspectives (2-3 pages)

#### 4.1 Bilan technique
**Points forts du projet :**
- Architecture microservices compl√®te
- Pipeline ML reproductible avec MLflow
- Monitoring temps r√©el
- Couverture de tests √©lev√©e (82%)

#### 4.2 Difficult√©s rencontr√©es et solutions

| Probl√®me | Solution |
|----------|----------|
| Donn√©es manquantes Pok√©API | Ajout scraping Pokepedia |
| Performance mod√®le v1 | Feature engineering am√©lior√© v2 |
| Temps de r√©ponse API | Cache Redis + optimisation requ√™tes |
| D√©rive donn√©es | Syst√®me de monitoring automatique |

#### 4.3 Axes d'am√©lioration
- Ajouter plus de sc√©narios de combat
- Impl√©menter un syst√®me de A/B testing
- D√©ployer sur Kubernetes
- Ajouter l'explication des pr√©dictions (SHAP)

#### 4.4 Conclusion
Synth√®se des comp√©tences d√©montr√©es et perspectives professionnelles.

---

## üìé Annexes Recommand√©es

> Les annexes sont essentielles pour appuyer ton rapport avec des preuves concr√®tes. Voici les annexes √† inclure, class√©es par priorit√©.

### Annexes E1 ‚Äî Gestion des Donn√©es

| # | Annexe | Contenu | Priorit√© |
|---|--------|---------|----------|
| A1 | **Sch√©mas BDD (MCD/MPD)** | Diagrammes entit√©-relation des tables PostgreSQL (pokemon, types, moves, battles) | ‚≠ê‚≠ê‚≠ê ESSENTIEL |
| A2 | **Pipeline ETL** | Sch√©ma visuel du flux : Sources ‚Üí Scraping/API ‚Üí Nettoyage ‚Üí PostgreSQL | ‚≠ê‚≠ê‚≠ê ESSENTIEL |
| A3 | **Documentation API Swagger** | Capture compl√®te de `/docs` (OpenAPI) avec tous les endpoints | ‚≠ê‚≠ê‚≠ê ESSENTIEL |
| A4 | **Requ√™tes SQL cl√©s** | 3-5 requ√™tes importantes comment√©es (jointures, agr√©gations) | ‚≠ê‚≠ê RECOMMAND√â |
| A5 | **Captures pgAdmin** | Vues des tables peupl√©es avec donn√©es | ‚≠ê‚≠ê RECOMMAND√â |
| A6 | **R√©tro-planning** | Gantt ou timeline des phases du projet | ‚≠ê OPTIONNEL |

### Annexes E3 ‚Äî Mise √† Disposition de l'IA

| # | Annexe | Contenu | Priorit√© |
|---|--------|---------|----------|
| B1 | **Architecture technique** | Sch√©ma des 9 services Docker avec flux de donn√©es | ‚≠ê‚≠ê‚≠ê ESSENTIEL |
| B2 | **M√©triques du mod√®le** | Matrice de confusion, courbe ROC, accuracy 88.23% | ‚≠ê‚≠ê‚≠ê ESSENTIEL |
| B3 | **Dashboard monitoring** | Captures Grafana + m√©triques Prometheus | ‚≠ê‚≠ê‚≠ê ESSENTIEL |
| B4 | **Pipelines CI/CD** | Sch√©ma des 6 workflows GitHub Actions | ‚≠ê‚≠ê‚≠ê ESSENTIEL |
| B5 | **MLflow tracking** | Captures des exp√©riences et du model registry | ‚≠ê‚≠ê RECOMMAND√â |
| B6 | **Rapport de tests** | R√©sum√© pytest (252 tests, 82% coverage) | ‚≠ê‚≠ê RECOMMAND√â |
| B7 | **Interface Streamlit** | Captures de l'application utilisateur en action | ‚≠ê‚≠ê RECOMMAND√â |
| B8 | **D√©tection de drift** | Graphiques KS-test, PSI, alertes configur√©es | ‚≠ê‚≠ê RECOMMAND√â |

### Annexes Communes

| # | Annexe | Contenu |
|---|--------|----------|
| C1 | **Glossaire technique** | D√©finitions : ETL, MLOps, CI/CD, Drift, XGBoost, FastAPI, etc. |
| C2 | **R√©f√©rences bibliographiques** | Documentation officielle, articles, tutoriels utilis√©s |
| C3 | **Lien GitHub** | URL du repository avec instructions de lancement |

### Glossaire type (Annexe C1)

| Terme | D√©finition |
|-------|------------|
| **ETL** | Extract, Transform, Load ‚Äî Pipeline de collecte et transformation de donn√©es |
| **MLOps** | Machine Learning Operations ‚Äî Pratiques DevOps appliqu√©es au ML |
| **CI/CD** | Continuous Integration / Continuous Deployment |
| **Drift** | D√©rive des donn√©es ou du mod√®le dans le temps |
| **XGBoost** | Algorithme de gradient boosting pour la classification/r√©gression |
| **FastAPI** | Framework Python moderne pour cr√©er des APIs REST |
| **MLflow** | Plateforme open-source pour le cycle de vie ML |
| **Prometheus** | Syst√®me de monitoring et d'alerting open-source |
| **Grafana** | Outil de visualisation de m√©triques |
| **Docker Compose** | Outil d'orchestration de conteneurs multi-services |

---

## ‚úÖ Checklist de Validation

### Bloc E1 - API & Base de donn√©es
- [ ] C1 : Sch√©ma des besoins et flux de donn√©es
- [ ] C2 : Pipeline ETL document√© avec code
- [ ] C3 : MCD/MPD + Scripts SQL
- [ ] C4 : API REST avec Swagger + tests
- [ ] C5 : Docker-compose fonctionnel

### Bloc E3 - Mise √† disposition de l'IA
- [ ] C9 : Endpoint `/predict` document√©
- [ ] C10 : Interface Streamlit avec captures
- [ ] C11 : Dashboards monitoring + code drift
- [ ] C12 : 252 tests, 82% couverture
- [ ] C13 : 6 workflows GitHub Actions

---

## üìè Conseils de R√©daction

### Format et longueur
1. **Longueur recommand√©e** : 20-30 pages (hors annexes)
2. **Format** : PDF, num√©rot√©, avec table des mati√®res cliquable
3. **Police** : Arial ou Calibri, 11-12pt, interligne 1.15-1.5
4. **Marges** : 2.5 cm minimum

### Contenu
5. **Illustrations** : Privil√©gier les diagrammes et captures d'√©cran annot√©es
6. **Code** : Extraits pertinents et comment√©s (pas de copier-coller massif)
7. **R√©f√©rences** : Citer tes sources (documentation, articles)
8. **Coh√©rence** : Pr√©senter E1 et E3 comme un projet unique et fluide

### Erreurs √† √©viter
- ‚ùå Trop de code sans explication
- ‚ùå Captures d'√©cran illisibles ou non annot√©es
- ‚ùå Oublier de mentionner le RGPD (m√™me si pas de donn√©es personnelles)
- ‚ùå Ne pas lier les comp√©tences aux r√©alisations concr√®tes
- ‚ùå Rapport trop long (le jury doit pouvoir le lire en 30 min)

---

## üé§ Pr√©paration √† la Soutenance

### Dur√©es officielles (r√®glement Simplon)

| Bloc | Pr√©sentation | Questions jury | Total |
|------|--------------|----------------|-------|
| **E1** (Bloc 1) | 15 min | 10 min max | **25 min** |
| **E3** (Bloc 2) | 20 min + d√©mo | 10 min max | **30 min** |

> Si rapport combin√© E1+E3 : pr√©voir ~35-45 min de pr√©sentation totale

### D√©roulement sugg√©r√©

**E1 ‚Äî Gestion des donn√©es (15 min)**
1. Contexte et probl√©matique (2 min)
2. Pipeline ETL et sources de donn√©es (4 min)
3. Base de donn√©es et mod√©lisation (4 min)
4. API REST de donn√©es (4 min)
5. Transition vers E3 (1 min)

**E3 ‚Äî Mise √† disposition de l'IA (20 min)**
1. API du mod√®le ML (4 min)
2. Int√©gration Streamlit (3 min)
3. **D√©monstration live** (5 min) ‚ö°
4. Monitoring et d√©tection de drift (4 min)
5. Tests et CI/CD (3 min)
6. Conclusion et perspectives (1 min)

### D√©monstration live (obligatoire pour E3)

**Sc√©nario de d√©mo sugg√©r√© :**
```
1. Ouvrir l'interface Streamlit
2. S√©lectionner deux Pok√©mon (ex: Pikachu vs Dracaufeu)
3. Lancer une pr√©diction
4. Montrer le r√©sultat avec probabilit√©s
5. Ouvrir Grafana et montrer les m√©triques temps r√©el
6. (Optionnel) Montrer MLflow avec les exp√©riences
```

### Questions types du jury

**E1 ‚Äî Donn√©es :**
- "Comment avez-vous g√©r√© les donn√©es manquantes ?"
- "Pourquoi PostgreSQL plut√¥t qu'une autre BDD ?"
- "Comment s√©curisez-vous l'API de donn√©es ?"
- "Quelle est votre politique RGPD ?"

**E3 ‚Äî IA :**
- "Comment d√©tectez-vous les d√©rives du mod√®le ?"
- "Pourquoi avoir choisi XGBoost ?"
- "Comment testez-vous le pipeline ML ?"
- "Quelle est votre strat√©gie de versioning des mod√®les ?"
- "Que se passe-t-il si le mod√®le d√©rive ?"
- "Comment g√©rez-vous le rollback d'un mod√®le ?"

### Points diff√©renciants √† mettre en avant
- ‚úÖ Architecture MLOps compl√®te (rare pour un projet de certification)
- ‚úÖ D√©tection de drift automatis√©e avec alertes
- ‚úÖ 9 services Docker orchestr√©s
- ‚úÖ CI/CD avec 6 workflows GitHub Actions
- ‚úÖ 252 tests, 82% de couverture
- ‚úÖ Deux versions de mod√®le compar√©es (v1 vs v2)

---

*Guide cr√©√© le 31 janvier 2026 pour le projet PredictionDex*
