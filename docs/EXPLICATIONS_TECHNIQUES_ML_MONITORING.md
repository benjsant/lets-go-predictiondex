# ðŸ§  Explications Techniques DÃ©taillÃ©es - ML & Monitoring

**Date:** 27 janvier 2026
**Objectif:** Comprendre en profondeur le fonctionnement du ML, Grafana, Evidently et leur intÃ©gration

---

## ðŸ“‹ Table des MatiÃ¨res

1. [Pipeline Machine Learning Complet](#1-pipeline-machine-learning-complet)
2. [Monitoring Prometheus](#2-monitoring-prometheus)
3. [Visualisation Grafana](#3-visualisation-grafana)
4. [Drift Detection Evidently](#4-drift-detection-evidently)
5. [IntÃ©gration ComplÃ¨te](#5-intÃ©gration-complÃ¨te)

---

## 1. Pipeline Machine Learning Complet

### ðŸŽ¯ Vue d'Ensemble du Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PIPELINE ML COMPLET                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰tape 1: GÃ©nÃ©ration Dataset
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PostgreSQL (188 PokÃ©mon Ã— 226 Moves)
         â†“
    Simulation Combats
    (3 scÃ©narios Ã— 898,472 combats)
         â†“
    battles_dataset_v2.parquet (220 MB)


Ã‰tape 2: Feature Engineering
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
38 features brutes
         â†“
    One-Hot Encoding (types)
    + Normalisation (StandardScaler)
    + Features dÃ©rivÃ©es (ratios, diffs)
         â†“
    133 features engineered


Ã‰tape 3: Training
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
XGBoost Classifier
    â”œâ”€ n_estimators: 100
    â”œâ”€ max_depth: 6
    â”œâ”€ learning_rate: 0.1
    â”œâ”€ tree_method: 'hist' (CPU optimisÃ©)
    â””â”€ n_jobs: -1 (tous les cores)
         â†“
    Model trained (8 minutes)


Ã‰tape 4: Ã‰valuation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Test Set (20% = 179,694 combats)
         â†“
    MÃ©triques calculÃ©es:
    â”œâ”€ Accuracy: 88.23%
    â”œâ”€ Precision: 87.91%
    â”œâ”€ Recall: 88.57%
    â”œâ”€ F1-Score: 88.24%
    â””â”€ ROC-AUC: 0.940


Ã‰tape 5: Export & Registry
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Compression Joblib (zlib level 3)
         â†“
    Fichiers locaux:
    â”œâ”€ battle_winner_model_v2.pkl (39.8 MB)
    â”œâ”€ battle_winner_scalers_v2.pkl (12 KB)
    â””â”€ battle_winner_metadata_v2.pkl (8 KB)
         â†“
    MLflow Model Registry
    â”œâ”€ Model enregistrÃ© (version 1)
    â”œâ”€ Artifacts uploadÃ©s
    â””â”€ Auto-promotion si accuracy >= 85%


Ã‰tape 6: Serving
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API FastAPI
    â”œâ”€ Load model depuis MLflow (prioritÃ© 1)
    â”œâ”€ Fallback fichiers locaux (prioritÃ© 2)
    â””â”€ PrÃ©load au startup (Ã©vite timeout)
         â†“
    Endpoint /predict/best-move
    â”œâ”€ Input: Pokemon A, Pokemon B, Moves disponibles
    â”œâ”€ Processing: Feature engineering + XGBoost predict
    â””â”€ Output: Meilleur coup + probabilitÃ© victoire
```

---

### ðŸ“Š Ã‰tape 1: GÃ©nÃ©ration Dataset - DÃ©tails

**Fichier:** `machine_learning/build_battle_winner_dataset_v2.py`

**Principe:**

Nous simulons **898,472 combats** entre tous les PokÃ©mon avec diffÃ©rents movesets pour crÃ©er un dataset d'entraÃ®nement rÃ©aliste.

**3 ScÃ©narios de Combat:**

#### ScÃ©nario 1: Best Move vs Best Move (299,491 combats)

```python
def generate_scenario_1_battles(db: Session):
    """
    ScÃ©nario rÃ©aliste: chaque PokÃ©mon utilise son meilleur coup offensif.

    Pour chaque paire (Pokemon A, Pokemon B):
    1. SÃ©lectionner meilleur coup offensif de A contre B
    2. SÃ©lectionner meilleur coup offensif de B contre A
    3. Calculer features combat (stats, types, STAB, effectiveness)
    4. Simuler combat simplifiÃ© (qui frappe en premier, damage estimÃ©)
    5. DÃ©terminer vainqueur
    """
    type_effectiveness = load_type_chart(db)
    all_pokemon = db.query(Pokemon).all()  # 188 PokÃ©mon

    battles = []

    for poke_a in all_pokemon:
        for poke_b in all_pokemon:
            if poke_a.id == poke_b.id:
                continue  # Pas de combat contre soi-mÃªme

            # Meilleur coup A
            best_move_a = select_best_offensive_move(
                poke_a, poke_b, type_effectiveness
            )

            # Meilleur coup B
            best_move_b = select_best_offensive_move(
                poke_b, poke_a, type_effectiveness
            )

            # Calculer features
            features = compute_battle_features(
                poke_a, poke_b,
                best_move_a, best_move_b
            )

            # Simuler combat
            winner = simulate_battle(
                poke_a, poke_b,
                best_move_a, best_move_b,
                type_effectiveness
            )

            battles.append({
                **features,
                'winner': 1 if winner == 'A' else 0
            })

    return battles

# Nombre combats: 188 Ã— 187 = 35,156 matchups
# Mais avec movesets variÃ©s: ~299,491 combats
```

**Logique `simulate_battle()`:**

```python
def simulate_battle(poke_a, poke_b, move_a, move_b, type_eff):
    """
    Simulation simplifiÃ©e combat PokÃ©mon.

    RÃ¨gles:
    1. PrioritÃ© des moves (ex: Vive-Attaque = +1 priority)
    2. Si mÃªme prioritÃ© â†’ Vitesse la plus Ã©levÃ©e frappe en premier
    3. Damage = (Power Ã— STAB Ã— Type Multiplier Ã— Attack/Defense ratio)
    4. HP diminuent jusqu'Ã  KO
    5. Vainqueur = dernier debout
    """
    # DÃ©terminer ordre attaque
    if move_a.priority > move_b.priority:
        first_attacker = 'A'
    elif move_a.priority < move_b.priority:
        first_attacker = 'B'
    else:
        first_attacker = 'A' if poke_a.speed > poke_b.speed else 'B'

    # HP initiaux
    hp_a = poke_a.stats.hp
    hp_b = poke_b.stats.hp

    # Combat tour par tour
    while hp_a > 0 and hp_b > 0:
        if first_attacker == 'A':
            # A attaque B
            damage = calculate_damage(poke_a, poke_b, move_a, type_eff)
            hp_b -= damage

            if hp_b <= 0:
                return 'A'  # A gagne

            # B contre-attaque
            damage = calculate_damage(poke_b, poke_a, move_b, type_eff)
            hp_a -= damage

            if hp_a <= 0:
                return 'B'  # B gagne

        else:
            # B attaque A (mÃªme logique inversÃ©e)
            ...

    return 'A' if hp_a > hp_b else 'B'
```

**Calcul Damage:**

```python
def calculate_damage(attacker, defender, move, type_eff):
    """
    Formule damage PokÃ©mon simplifiÃ©e.

    BasÃ©e sur la vraie formule PokÃ©mon mais simplifiÃ©e pour ML:
    Damage = (Power Ã— STAB Ã— Effectiveness Ã— Stat Ratio) / 10
    """
    # Power brute
    power = move.power or 50

    # STAB (Same Type Attack Bonus = Ã—1.5)
    stab = 1.5 if move.type_id in [t.type_id for t in attacker.types] else 1.0

    # Type effectiveness (0, 0.25, 0.5, 1, 2, 4)
    effectiveness = get_type_multiplier(
        move.type_id,
        [t.type_id for t in defender.types],
        type_eff
    )

    # Stat ratio (Attack/Defense ou Sp.Attack/Sp.Defense)
    if move.category == 'physique':
        stat_ratio = attacker.stats.attack / (defender.stats.defense + 1)
    else:  # spÃ©cial
        stat_ratio = attacker.stats.sp_attack / (defender.stats.sp_defense + 1)

    # Damage final
    damage = (power * stab * effectiveness * stat_ratio) / 10

    # Variation alÃ©atoire Â±10%
    import random
    damage *= random.uniform(0.9, 1.1)

    return max(1, int(damage))  # Minimum 1 HP
```

---

#### ScÃ©nario 2: Random Moves (299,491 combats)

```python
def generate_scenario_2_battles(db: Session):
    """
    ScÃ©nario alÃ©atoire: movesets random pour plus de diversitÃ©.

    Pour chaque paire (Pokemon A, Pokemon B):
    1. SÃ©lectionner 1 coup random parmi tous les coups appris
    2. RÃ©pÃ©ter plusieurs fois avec diffÃ©rents coups
    3. MÃªme simulation que scÃ©nario 1
    """
    for poke_a in all_pokemon:
        for poke_b in all_pokemon:
            # Obtenir tous les coups appris
            moves_a = [pm.move for pm in poke_a.moves if pm.move.power]
            moves_b = [pm.move for pm in poke_b.moves if pm.move.power]

            # GÃ©nÃ©rer 5 combats random
            for _ in range(5):
                move_a = random.choice(moves_a)
                move_b = random.choice(moves_b)

                # MÃªme logique simulation
                features = compute_battle_features(...)
                winner = simulate_battle(...)
                battles.append({**features, 'winner': winner})

    return battles
```

---

#### ScÃ©nario 3: Type Advantage Focus (299,490 combats)

```python
def generate_scenario_3_battles(db: Session):
    """
    ScÃ©nario avantage type: focus sur matchups stratÃ©giques.

    Pour chaque paire (Pokemon A, Pokemon B):
    1. SÃ©lectionner coup super efficace de A si existe (Ã—2 ou Ã—4)
    2. Sinon coup neutre
    3. MÃªme logique pour B
    4. Simulation combat
    """
    for poke_a in all_pokemon:
        for poke_b in all_pokemon:
            # Chercher coup super efficace
            super_effective_move_a = find_super_effective_move(
                poke_a, poke_b, type_effectiveness
            )

            if super_effective_move_a:
                move_a = super_effective_move_a
            else:
                move_a = select_best_offensive_move(poke_a, poke_b)

            # MÃªme logique pour B
            move_b = ...

            # Simulation
            features = compute_battle_features(...)
            winner = simulate_battle(...)
            battles.append({**features, 'winner': winner})

    return battles
```

---

### ðŸ§® Ã‰tape 2: Feature Engineering - DÃ©tails

**Fichier:** `machine_learning/run_machine_learning.py` (fonction `engineer_features()`)

**Input:** 38 features brutes
**Output:** 133 features engineered

#### 38 Features Brutes

```python
raw_features = {
    # Pokemon A (14 features)
    'a_hp': int,                # Points de Vie
    'a_attack': int,            # Attaque
    'a_defense': int,           # DÃ©fense
    'a_sp_attack': int,         # Attaque SpÃ©ciale
    'a_sp_defense': int,        # DÃ©fense SpÃ©ciale
    'a_speed': int,             # Vitesse
    'a_total_stats': int,       # Somme stats (calculÃ©)
    'a_type_1': str,            # Type primaire (ex: "Ã©lectrik")
    'a_type_2': str,            # Type secondaire (ex: "vol", ou "none")
    'a_move_power': float,      # Puissance coup
    'a_move_type': str,         # Type coup (ex: "Ã©lectrik")
    'a_move_priority': int,     # PrioritÃ© coup (-6 Ã  +5)
    'a_move_stab': float,       # STAB (1.0 ou 1.5)
    'a_move_type_mult': float,  # Multiplicateur type (0, 0.25, 0.5, 1, 2, 4)

    # Pokemon B (14 features) - mÃªmes colonnes prÃ©fixÃ©es 'b_'
    'b_hp': int,
    'b_attack': int,
    # ... (14 features identiques)

    # Features dÃ©rivÃ©es de base (4 features)
    'speed_diff': int,          # a_speed - b_speed
    'hp_diff': int,             # a_hp - b_hp
    'a_moves_first': int,       # 1 si A frappe en premier, 0 sinon

    # Target
    'winner': int               # 1 si A gagne, 0 si B gagne
}
```

---

#### Transformation en 133 Features

**Ã‰tape 2.1: One-Hot Encoding des Types**

```python
def engineer_features(df_raw):
    """
    Transform 38 raw features â†’ 133 engineered features.
    """
    # Types uniques dans le jeu (18 types)
    unique_types = [
        'plante', 'poison', 'feu', 'vol', 'eau', 'insecte',
        'combat', 'normal', 'sol', 'spectre', 'psy', 'acier',
        'tÃ©nÃ¨bres', 'glace', 'fÃ©e', 'Ã©lectrik', 'dragon', 'roche',
        'none'  # Pour PokÃ©mon mono-type
    ]

    # One-hot encoding pour 6 colonnes catÃ©gorielles
    categorical_cols = [
        'a_type_1',      # â†’ 19 colonnes (a_type_1_plante, a_type_1_feu, ...)
        'a_type_2',      # â†’ 19 colonnes
        'b_type_1',      # â†’ 19 colonnes
        'b_type_2',      # â†’ 19 colonnes
        'a_move_type',   # â†’ 19 colonnes
        'b_move_type'    # â†’ 19 colonnes
    ]

    X = df_raw.copy()

    for col in categorical_cols:
        dummies = pd.get_dummies(X[col], prefix=col, drop_first=False)
        X = pd.concat([X, dummies], axis=1)

    # Supprimer colonnes catÃ©gorielles originales
    X = X.drop(columns=categorical_cols)

    # RÃ©sultat: 32 features numÃ©riques + 6Ã—19 = 146 colonnes
    # Mais certains types n'apparaissent jamais (ex: a_type_2_dragon trÃ¨s rare)
    # Donc ~133 colonnes after cleanup
```

---

**Ã‰tape 2.2: Normalisation Features NumÃ©riques**

```python
    # Features Ã  normaliser (StandardScaler)
    numeric_features = [
        'a_hp', 'a_attack', 'a_defense', 'a_sp_attack', 'a_sp_defense', 'a_speed',
        'b_hp', 'b_attack', 'b_defense', 'b_sp_attack', 'b_sp_defense', 'b_speed',
        'a_move_power', 'b_move_power',
        'a_total_stats', 'b_total_stats',
        'speed_diff', 'hp_diff'
    ]

    # StandardScaler: (X - mean) / std
    scaler = StandardScaler()
    X[numeric_features] = scaler.fit_transform(X[numeric_features])

    # Exemple transformation:
    # a_hp = 300 â†’ (300 - mean_hp) / std_hp â†’ 1.34 (z-score)
    # a_attack = 50 â†’ (50 - mean_attack) / std_attack â†’ -0.87
```

---

**Ã‰tape 2.3: Features DÃ©rivÃ©es**

```python
    # CrÃ©er 6 nouvelles features intelligentes

    # 1. Ratio stats totales (qui est globalement plus fort ?)
    X['stat_ratio'] = df_raw['a_total_stats'] / (df_raw['b_total_stats'] + 1)
    # Exemple: 500 / 400 = 1.25 (A 25% plus fort)

    # 2. DiffÃ©rence avantage type
    X['type_advantage_diff'] = df_raw['a_move_type_mult'] - df_raw['b_move_type_mult']
    # Exemple: 2.0 - 0.5 = 1.5 (A super efficace, B peu efficace)

    # 3. Puissance effective A (avec STAB + type)
    X['effective_power_a'] = (
        df_raw['a_move_power'] *
        df_raw['a_move_stab'] *
        df_raw['a_move_type_mult']
    )
    # Exemple: 90 Ã— 1.5 (STAB) Ã— 2.0 (super efficace) = 270

    # 4. Puissance effective B
    X['effective_power_b'] = (
        df_raw['b_move_power'] *
        df_raw['b_move_stab'] *
        df_raw['b_move_type_mult']
    )

    # 5. DiffÃ©rence puissance effective
    X['effective_power_diff'] = X['effective_power_a'] - X['effective_power_b']
    # Exemple: 270 - 120 = 150 (A beaucoup plus dangereux)

    # 6. Avantage prioritÃ© (qui frappe en premier ?)
    X['priority_advantage'] = df_raw['a_move_priority'] - df_raw['b_move_priority']
    # Exemple: +1 (Vive-Attaque) - 0 (move normal) = 1

    # Normaliser les nouvelles features
    scaler_new = StandardScaler()
    new_features = [
        'stat_ratio', 'type_advantage_diff',
        'effective_power_a', 'effective_power_b',
        'effective_power_diff', 'priority_advantage'
    ]
    X[new_features] = scaler_new.fit_transform(X[new_features])

    return X  # Shape: (898472, 133)
```

---

### ðŸ¤– Ã‰tape 3: Training XGBoost - DÃ©tails

**Fichier:** `machine_learning/run_machine_learning.py` (fonction `train_model()`)

**HyperparamÃ¨tres XGBoost:**

```python
DEFAULT_XGBOOST_PARAMS = {
    # Nombre d'arbres de dÃ©cision
    'n_estimators': 100,
    # 100 arbres Ã©quilibrÃ©s: pas d'overfitting, bon accuracy

    # Profondeur maximale arbres
    'max_depth': 6,
    # 6 niveaux: capture patterns complexes sans overfitting

    # Taux d'apprentissage
    'learning_rate': 0.1,
    # 0.1 = Ã©quilibre vitesse/accuracy

    # MÃ©thode construction arbres
    'tree_method': 'hist',
    # 'hist' = Histogramme-based algorithm (3-5Ã— plus rapide que 'exact')

    # ParallÃ©lisation CPU
    'n_jobs': -1,
    # -1 = utiliser tous les cores CPU disponibles

    # Random seed (reproductibilitÃ©)
    'random_state': 42,

    # Objective function
    'objective': 'binary:logistic',
    # Classification binaire (A gagne=1, B gagne=0)

    # MÃ©triques Ã©valuation
    'eval_metric': 'logloss',
    # Log loss = mesure qualitÃ© probabilitÃ©s prÃ©dites
}
```

**Code training:**

```python
def train_model(X_train, y_train, X_test, y_test, hyperparams):
    """
    EntraÃ®nement XGBoost Classifier.

    Args:
        X_train: (718,778 samples, 133 features)
        y_train: (718,778 labels)
        X_test: (179,694 samples, 133 features)
        y_test: (179,694 labels)

    Returns:
        model: XGBoost model trained
        metrics: dict avec accuracy, precision, recall, F1, ROC-AUC
    """
    import xgboost as xgb
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

    # CrÃ©er modÃ¨le
    model = xgb.XGBClassifier(**hyperparams)

    # Training (8 minutes sur CPU 8 cores)
    print("ðŸš€ Training XGBoost...")
    start_time = time.time()

    model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        verbose=10  # Afficher progression tous les 10 arbres
    )

    training_time = time.time() - start_time
    print(f"âœ… Training completed in {training_time:.1f}s")

    # PrÃ©dictions test set
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]  # ProbabilitÃ©s classe 1

    # Calcul mÃ©triques
    metrics = {
        'test_accuracy': accuracy_score(y_test, y_pred),
        # 88.23% - PrÃ©dit le bon gagnant 88 fois sur 100

        'test_precision': precision_score(y_test, y_pred),
        # 87.91% - Quand prÃ©dit "A gagne", c'est vrai 88% du temps

        'test_recall': recall_score(y_test, y_pred),
        # 88.57% - DÃ©tecte 88.57% des vrais "A gagne"

        'test_f1': f1_score(y_test, y_pred),
        # 88.24% - Moyenne harmonique prÃ©cision/recall

        'test_roc_auc': roc_auc_score(y_test, y_pred_proba),
        # 0.940 - Excellente discrimination (0.5=random, 1.0=parfait)

        'training_time_seconds': training_time,
        # ~480s (8 minutes)

        'n_features': X_train.shape[1],
        # 133 features

        'n_samples_train': len(X_train),
        # 718,778 combats

        'n_samples_test': len(X_test)
        # 179,694 combats
    }

    return model, metrics
```

**Output training (exemple):**

```
[0]     validation-logloss:0.61234
[10]    validation-logloss:0.42156
[20]    validation-logloss:0.36789
[30]    validation-logloss:0.33456
...
[90]    validation-logloss:0.28912
[100]   validation-logloss:0.28901  â† Convergence

âœ… Training completed in 478.3s

Metrics:
  test_accuracy: 0.8823 (88.23%)
  test_precision: 0.8791
  test_recall: 0.8857
  test_f1: 0.8824
  test_roc_auc: 0.9403
```

---

### ðŸ’¾ Ã‰tape 4: Export & Compression - DÃ©tails

**Fichier:** `machine_learning/run_machine_learning.py` (fonction `export_model()`)

**Compression Joblib:**

```python
def export_model(model, scalers, metadata, version='v2'):
    """
    Export modÃ¨le + scalers + metadata avec compression.

    Compression zlib level 3:
    - Sans compression: 401 MB (RandomForest) ou 120 MB (XGBoost)
    - Avec compression: 39.8 MB (XGBoost zlib-3) â†’ -67% taille
    """
    import joblib
    from pathlib import Path

    models_dir = Path('models')
    models_dir.mkdir(exist_ok=True)

    # Export modÃ¨le (compression zlib niveau 3)
    model_path = models_dir / f'battle_winner_model_{version}.pkl'
    joblib.dump(model, model_path, compress=('zlib', 3))
    print(f"âœ… Model saved: {model_path} ({model_path.stat().st_size / 1e6:.1f} MB)")

    # Export scalers (compression zlib niveau 9 car petit fichier)
    scalers_path = models_dir / f'battle_winner_scalers_{version}.pkl'
    joblib.dump(scalers, scalers_path, compress=('zlib', 9))
    print(f"âœ… Scalers saved: {scalers_path} ({scalers_path.stat().st_size / 1e3:.1f} KB)")

    # Export metadata (JSON pour lisibilitÃ©)
    metadata_path = models_dir / f'battle_winner_metadata_{version}.json'
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2)
    print(f"âœ… Metadata saved: {metadata_path}")

# Output:
# âœ… Model saved: models/battle_winner_model_v2.pkl (39.8 MB)
# âœ… Scalers saved: models/battle_winner_scalers_v2.pkl (12.3 KB)
# âœ… Metadata saved: models/battle_winner_metadata_v2.json (8.1 KB)
```

**Contenu metadata.json:**

```json
{
  "model_type": "XGBClassifier",
  "version": "v2",
  "trained_at": "2026-01-27T14:32:15",
  "dataset_version": "v2",
  "n_features": 133,
  "n_samples_train": 718778,
  "n_samples_test": 179694,
  "hyperparameters": {
    "n_estimators": 100,
    "max_depth": 6,
    "learning_rate": 0.1,
    "tree_method": "hist",
    "n_jobs": -1
  },
  "metrics": {
    "test_accuracy": 0.8823,
    "test_precision": 0.8791,
    "test_recall": 0.8857,
    "test_f1": 0.8824,
    "test_roc_auc": 0.9403,
    "train_accuracy": 0.9821,
    "train_roc_auc": 0.9987
  },
  "training_time_seconds": 478.3,
  "features": [
    "a_hp", "a_attack", "a_defense", ...,
    "a_type_1_Ã©lectrik", "a_type_1_feu", ...,
    "stat_ratio", "type_advantage_diff", ...
  ]
}
```

---

## 2. Monitoring Prometheus

### ðŸŽ¯ Architecture Prometheus

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROMETHEUS MONITORING                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

API FastAPI (port 8080)
    â”‚
    â”œâ”€ PrometheusMiddleware (api_pokemon/monitoring/metrics.py)
    â”‚  â”œâ”€ Intercept toutes les requÃªtes
    â”‚  â”œâ”€ Mesure latence (start â†’ end)
    â”‚  â”œâ”€ Track status codes (200, 404, 500)
    â”‚  â””â”€ Update mÃ©triques Prometheus
    â”‚
    â”œâ”€ /metrics endpoint (exposition mÃ©triques)
    â”‚  â””â”€ Format: Prometheus text exposition format
    â”‚
    â””â”€ track_prediction() dans routes
       â””â”€ Log mÃ©triques ML spÃ©cifiques

         â†“ Scrape HTTP GET /metrics

Prometheus Server (port 9091)
    â”‚
    â”œâ”€ Scrape config (docker/prometheus/prometheus.yml)
    â”‚  â”œâ”€ job 'api' â†’ scrape_interval: 10s
    â”‚  â”œâ”€ job 'prometheus' â†’ self-monitoring
    â”‚  â””â”€ job 'node' â†’ node-exporter (mÃ©triques systÃ¨me)
    â”‚
    â”œâ”€ TSDB (Time Series Database)
    â”‚  â””â”€ Stockage mÃ©triques par timestamp
    â”‚
    â””â”€ Alert Manager (rules: docker/prometheus/alerts.yml)
       â”œâ”€ HighAPILatency (P95 > 500ms pendant 2min)
       â”œâ”€ HighErrorRate (errors/s > 0.05 pendant 2min)
       â”œâ”€ HighModelLatency (P95 > 100ms pendant 2min)
       â””â”€ HighCPUUsage (> 80% pendant 5min)

         â†“ Query PromQL

Grafana (port 3001)
    â”‚
    â”œâ”€ Datasource: Prometheus
    â”œâ”€ Dashboard API Performance
    â””â”€ Dashboard Model Performance

         â†“ Visualisation

Utilisateur (Jury Soutenance)
```

---

### ðŸ“Š MÃ©triques CollectÃ©es - DÃ©tail

**Fichier:** `api_pokemon/monitoring/metrics.py`

#### MÃ©triques API

```python
from prometheus_client import Counter, Histogram, Gauge

# 1. Compteur requÃªtes totales
api_requests_total = Counter(
    'api_requests_total',
    'Total number of API requests',
    ['method', 'endpoint', 'status']  # Labels pour segmentation
)

# Exemple utilisation:
# api_requests_total.labels(method='POST', endpoint='/predict/best-move', status='200').inc()
# â†’ IncrÃ©mente compteur

# RequÃªtes PromQL:
# api_requests_total                                    â†’ Toutes requÃªtes
# api_requests_total{endpoint="/predict/best-move"}    â†’ Seulement prÃ©dictions
# rate(api_requests_total[5m])                         â†’ RequÃªtes/seconde (5min window)
```

```python
# 2. Histogramme latence requÃªtes
api_request_duration_seconds = Histogram(
    'api_request_duration_seconds',
    'API request duration in seconds',
    ['method', 'endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]  # Buckets latence
)

# Exemple utilisation:
# start = time.time()
# response = await call_next(request)
# duration = time.time() - start
# api_request_duration_seconds.labels(method='POST', endpoint='/predict/best-move').observe(duration)
# â†’ Enregistre durÃ©e dans histogramme

# RequÃªtes PromQL:
# histogram_quantile(0.50, rate(api_request_duration_seconds_bucket[5m]))  â†’ P50 (mÃ©diane)
# histogram_quantile(0.95, rate(api_request_duration_seconds_bucket[5m]))  â†’ P95
# histogram_quantile(0.99, rate(api_request_duration_seconds_bucket[5m]))  â†’ P99
```

---

#### MÃ©triques ML

```python
# 3. Compteur prÃ©dictions modÃ¨le
model_predictions_total = Counter(
    'model_predictions_total',
    'Total number of model predictions',
    ['model_version']  # Label version modÃ¨le
)

# Exemple:
# model_predictions_total.labels(model_version='v2').inc()

# RequÃªtes PromQL:
# rate(model_predictions_total[5m])  â†’ PrÃ©dictions/seconde
# sum(model_predictions_total)       â†’ Total prÃ©dictions depuis dÃ©marrage
```

```python
# 4. Histogramme latence prÃ©diction ML
model_prediction_duration_seconds = Histogram(
    'model_prediction_duration_seconds',
    'Model prediction duration in seconds',
    ['model_version'],
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]  # Latence ML (plus rapide qu'API)
)

# Exemple:
# start = time.time()
# prediction = model.predict(features)
# duration = time.time() - start
# model_prediction_duration_seconds.labels(model_version='v2').observe(duration)

# RequÃªtes PromQL:
# histogram_quantile(0.95, rate(model_prediction_duration_seconds_bucket[5m]))  â†’ P95 latence ML
```

```python
# 5. Gauge confiance modÃ¨le
model_confidence_score = Gauge(
    'model_confidence_score',
    'Model prediction confidence score (0-1)',
    ['model_version']
)

# Exemple:
# probability = model.predict_proba(features)[0]
# confidence = max(probability)  # Max des 2 probabilitÃ©s (classe 0, classe 1)
# model_confidence_score.labels(model_version='v2').set(confidence)

# RequÃªtes PromQL:
# model_confidence_score        â†’ DerniÃ¨re valeur confiance
# avg_over_time(model_confidence_score[1h])  â†’ Moyenne confiance derniÃ¨re heure
```

```python
# 6. Histogramme distribution probabilitÃ©s victoire
model_win_probability = Histogram(
    'model_win_probability',
    'Distribution of win probabilities',
    ['model_version'],
    buckets=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]  # 11 buckets
)

# Exemple:
# win_prob = model.predict_proba(features)[0][1]  # ProbabilitÃ© classe "A gagne"
# model_win_probability.labels(model_version='v2').observe(win_prob)

# RequÃªtes PromQL:
# histogram_quantile(0.50, rate(model_win_probability_bucket[1h]))  â†’ MÃ©diane probabilitÃ©
# sum(rate(model_win_probability_bucket{le="0.6"}[1h]))  â†’ % prÃ©dictions incertaines (<60%)
```

---

### ðŸ” Middleware Prometheus - Code DÃ©taillÃ©

**Fichier:** `api_pokemon/monitoring/metrics.py:154-213`

```python
class PrometheusMiddleware(BaseHTTPMiddleware):
    """
    Middleware FastAPI pour tracking automatique mÃ©triques Prometheus.

    Intercept toutes les requÃªtes HTTP et log:
    - Nombre requÃªtes (par mÃ©thode/endpoint/status)
    - Latence requÃªte
    - Erreurs
    - MÃ©triques systÃ¨me (CPU, RAM)
    """

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        """
        Process request and track metrics.

        Flow:
        1. Request arrive
        2. Start timer
        3. Call next handler (route API)
        4. Response gÃ©nÃ©rÃ©e
        5. Stop timer
        6. Update mÃ©triques Prometheus
        7. Return response
        """
        # Skip /metrics endpoint (Ã©viter boucle infinie)
        if request.url.path == "/metrics":
            return await call_next(request)

        # Start timer
        start_time = time.time()

        try:
            # Call API handler (ex: predict_best_move())
            response = await call_next(request)

            # Stop timer
            duration = time.time() - start_time

            # Track successful request
            track_request(
                method=request.method,        # 'POST'
                endpoint=request.url.path,    # '/predict/best-move'
                status=response.status_code,  # 200
                duration=duration             # 0.327 seconds
            )

            # Update system metrics (CPU, RAM)
            update_system_metrics()

            return response

        except Exception as e:
            # Track error
            duration = time.time() - start_time

            track_error(
                method=request.method,
                endpoint=request.url.path,
                error_type=type(e).__name__  # 'ValueError', 'DatabaseError'
            )

            # Also track as failed request (status 500)
            track_request(
                method=request.method,
                endpoint=request.url.path,
                status=500,
                duration=duration
            )

            # Re-raise exception
            raise
```

**Fonction tracking:**

```python
def track_request(method: str, endpoint: str, status: int, duration: float):
    """
    Track une requÃªte API.

    Updates:
    - api_requests_total (Counter)
    - api_request_duration_seconds (Histogram)
    """
    # Increment counter
    api_requests_total.labels(
        method=method,
        endpoint=endpoint,
        status=status
    ).inc()

    # Record duration
    api_request_duration_seconds.labels(
        method=method,
        endpoint=endpoint
    ).observe(duration)
```

---

### ðŸ“ˆ Queries PromQL Utiles

**Dans Prometheus UI (http://localhost:9091):**

```promql
# 1. Request Rate (requÃªtes/seconde)
rate(api_requests_total[5m])

# 2. Request Rate par endpoint
sum(rate(api_requests_total[5m])) by (endpoint)

# 3. Latence P95 API
histogram_quantile(0.95, rate(api_request_duration_seconds_bucket[5m]))

# 4. Error Rate
rate(api_errors_total[5m])

# 5. Success Rate (%)
sum(rate(api_requests_total{status=~"2.."}[5m])) /
sum(rate(api_requests_total[5m])) * 100

# 6. PrÃ©dictions ML par seconde
rate(model_predictions_total[5m])

# 7. Latence P95 modÃ¨le ML
histogram_quantile(0.95, rate(model_prediction_duration_seconds_bucket[5m]))

# 8. CPU usage
system_cpu_usage_percent

# 9. Memory usage (%)
(system_memory_usage_bytes / (system_memory_usage_bytes + system_memory_available_bytes)) * 100

# 10. Top 5 endpoints les plus lents
topk(5, histogram_quantile(0.95, rate(api_request_duration_seconds_bucket[5m])))
```

---

## 3. Visualisation Grafana

### ðŸ“Š Dashboards Grafana - Architecture

```
Grafana (http://localhost:3001)
    â”‚
    â”œâ”€ Datasource Configuration
    â”‚  â””â”€ Prometheus: http://prometheus:9090
    â”‚
    â”œâ”€ Dashboard 1: API Performance
    â”‚  â”‚  (docker/grafana/dashboards/api_performance.json)
    â”‚  â”‚
    â”‚  â”œâ”€ Panel 1: Request Rate
    â”‚  â”‚  â””â”€ Query: rate(api_requests_total[5m])
    â”‚  â”‚
    â”‚  â”œâ”€ Panel 2: Latency P50/P95/P99
    â”‚  â”‚  â””â”€ Query: histogram_quantile(0.95, rate(...))
    â”‚  â”‚
    â”‚  â”œâ”€ Panel 3: Error Rate
    â”‚  â”‚  â””â”€ Query: rate(api_errors_total[5m])
    â”‚  â”‚
    â”‚  â”œâ”€ Panel 4: Status Codes Distribution
    â”‚  â”‚  â””â”€ Query: sum(rate(...)) by (status)
    â”‚  â”‚
    â”‚  â””â”€ Panel 5: Response Time Heatmap
    â”‚     â””â”€ Query: histogram buckets
    â”‚
    â””â”€ Dashboard 2: Model Performance
       â”‚  (docker/grafana/dashboards/model_performance.json)
       â”‚
       â”œâ”€ Panel 1: Predictions per Second
       â”‚  â””â”€ Query: rate(model_predictions_total[5m])
       â”‚
       â”œâ”€ Panel 2: Model Latency P95
       â”‚  â””â”€ Query: histogram_quantile(0.95, rate(model_prediction_duration_seconds_bucket[5m]))
       â”‚
       â”œâ”€ Panel 3: Confidence Score Over Time
       â”‚  â””â”€ Query: model_confidence_score
       â”‚
       â””â”€ Panel 4: Win Probability Distribution
          â””â”€ Query: rate(model_win_probability_bucket[1h])
```

---

### ðŸŽ¨ CrÃ©er un Panel Grafana (Exemple)

**Panel: Latence P95 PrÃ©dictions ML**

1. **Ouvrir Grafana:** http://localhost:3001 (admin/admin)
2. **Create â†’ Dashboard â†’ Add Panel**
3. **Configuration:**

```
Title: Model Prediction Latency (P95)

Query:
  histogram_quantile(0.95,
    rate(model_prediction_duration_seconds_bucket{model_version="v2"}[5m])
  )

Visualization: Time series (line chart)

Y-axis:
  - Unit: seconds (s)
  - Min: 0
  - Max: auto

Thresholds:
  - Green: 0 - 0.05s (< 50ms)
  - Yellow: 0.05 - 0.1s (50-100ms)
  - Red: > 0.1s (> 100ms)

Legend:
  - Show: Yes
  - Values: Last, Min, Max, Avg
```

4. **Apply**

**RÃ©sultat:** Graph montrant latence P95 du modÃ¨le ML en temps rÃ©el.

---

## 4. Drift Detection Evidently

### ðŸ” Fonctionnement Evidently AI

**Fichier:** `api_pokemon/monitoring/drift_detection.py`

#### Architecture Drift Detection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            EVIDENTLY DRIFT DETECTION                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Training (one-time)
    â”‚
    â”œâ”€ X_train.parquet (718,778 samples)
    â”‚  â””â”€ Sample 10,000 random samples
    â”‚     â†’ Reference Dataset (baseline)
    â”‚
    â””â”€ Save reference data
       â””â”€ data/datasets/X_train_reference.parquet


Production (continuous)
    â”‚
    â”œâ”€ API Prediction /predict/best-move
    â”‚  â””â”€ drift_detector.add_prediction(features, prediction, probability)
    â”‚
    â”œâ”€ Production Buffer (in-memory)
    â”‚  â”œâ”€ Max size: 1,000 predictions
    â”‚  â””â”€ Auto-save every 1,000 predictions
    â”‚
    â”œâ”€ Trigger Report (2 conditions)
    â”‚  â”œâ”€ Buffer full (1,000 predictions)
    â”‚  â””â”€ OU 1 hour elapsed
    â”‚
    â””â”€ Generate Drift Report
       â”‚
       â”œâ”€ Create Production Dataset from buffer
       â”‚  â””â”€ Convert buffer â†’ pandas DataFrame
       â”‚
       â”œâ”€ Evidently Report
       â”‚  â”œâ”€ DataDriftPreset (auto-configure tests)
       â”‚  â””â”€ Compare Production vs Reference
       â”‚
       â”œâ”€ Calculate Drift Metrics
       â”‚  â”œâ”€ Dataset Drift: True/False
       â”‚  â”œâ”€ Number of drifted features: 5/133
       â”‚  â””â”€ Share of drifted features: 3.7%
       â”‚
       â”œâ”€ Save Outputs
       â”‚  â”œâ”€ HTML Dashboard (interactive)
       â”‚  â”œâ”€ JSON Report (metrics)
       â”‚  â””â”€ Production Data (parquet for retraining)
       â”‚
       â””â”€ Clear Buffer (reset to 0)
```

---

#### Code Drift Detection - DÃ©tails

```python
class DriftDetector:
    """
    Singleton drift detection avec Evidently AI 0.7.

    Design Pattern: Singleton (1 seule instance dans l'app)
    """

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, '_initialized'):
            return  # DÃ©jÃ  initialisÃ©

        self._initialized = True

        # 1. Load reference data (training set)
        self._load_reference_data()
        # â†’ Charge X_train.parquet, sample 10k lignes, crÃ©e Evidently Dataset

        # 2. Production buffer
        self.production_buffer = []  # List[Dict]
        self.max_buffer_size = 1000

        # 3. Auto-report config
        self.report_frequency = timedelta(hours=1)
        self.last_report_time = datetime.now()

    def _load_reference_data(self):
        """
        Load reference data from training set.

        Steps:
        1. Read X_train.parquet (718,778 samples, 133 features)
        2. Sample 10,000 random rows (reproductible avec random_state=42)
        3. Convert to Evidently Dataset
        """
        try:
            # Try local path
            ref_file = Path("data/datasets/X_train.parquet")
            if not ref_file.exists():
                # Try Docker mount
                ref_file = Path("/app/data/datasets/X_train.parquet")

            if not ref_file.exists():
                self.logger.warning("Reference data not found. Drift detection disabled.")
                self.reference_data = None
                return

            # Load & sample
            reference_df = pd.read_parquet(ref_file)
            sampled_df = reference_df.sample(n=min(10000, len(reference_df)), random_state=42)

            # Create Evidently Dataset
            from evidently import Dataset, DataDefinition
            self.data_definition = DataDefinition()
            self.reference_data = Dataset.from_pandas(
                sampled_df,
                data_definition=self.data_definition
            )

            self.logger.info(f"âœ… Reference data loaded: {sampled_df.shape}")

        except Exception as e:
            self.logger.error(f"Failed to load reference data: {e}")
            self.reference_data = None
```

---

#### Ajout PrÃ©diction au Buffer

```python
    def add_prediction(self, features: Dict, prediction: int, probability: float):
        """
        Add prediction to production buffer.

        Called by API after each prediction:
        api_pokemon/routes/prediction_route.py:88-96

        Args:
            features: Dict avec features input (ex: pokemon_a_id, pokemon_b_id, move_name)
            prediction: 0 (B gagne) ou 1 (A gagne)
            probability: ProbabilitÃ© victoire (0.0 Ã  1.0)
        """
        if self.reference_data is None:
            return  # Drift detection disabled

        # Add to buffer with timestamp
        prediction_data = {
            **features,  # Unpack features dict
            'predicted_winner': prediction,
            'win_probability': probability,
            'timestamp': datetime.now().isoformat()
        }

        self.production_buffer.append(prediction_data)

        # Check if buffer is full (trigger auto-report)
        if len(self.production_buffer) >= self.max_buffer_size:
            self.logger.info(f"Buffer full ({self.max_buffer_size}). Generating drift report.")
            self.generate_drift_report()
            self.production_buffer = []  # Clear buffer

        # Check if it's time to generate report (1 hour elapsed)
        if datetime.now() - self.last_report_time >= self.report_frequency:
            if len(self.production_buffer) > 0:
                self.generate_drift_report()
                self.production_buffer = []
```

---

#### GÃ©nÃ©ration Rapport Drift

```python
    def generate_drift_report(self) -> Dict:
        """
        Generate drift report using Evidently AI 0.7.

        Steps:
        1. Convert buffer â†’ pandas DataFrame
        2. Create Evidently Dataset (production)
        3. Create Evidently Report with DataDriftPreset
        4. Run report (compare production vs reference)
        5. Save HTML dashboard + JSON metrics
        6. Return drift summary
        """
        if self.reference_data is None:
            return {}

        if len(self.production_buffer) == 0:
            return {}

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        try:
            # 1. Create DataFrame from buffer
            production_df = pd.DataFrame(self.production_buffer)

            # 2. Create Evidently Dataset
            production_dataset = Dataset.from_pandas(
                production_df,
                data_definition=self.data_definition
            )

            # 3. Create Evidently Report with DataDriftPreset
            from evidently import Report
            from evidently.presets import DataDriftPreset

            report = Report([DataDriftPreset()])

            # 4. Run report (compare production vs reference)
            report.run(
                current_data=production_dataset,
                reference_data=self.reference_data
            )

            # 5. Save JSON
            report_file = self.drift_reports_dir / f"drift_report_{timestamp}.json"
            with open(report_file, 'w') as f:
                f.write(report.json())

            # 6. Save HTML dashboard
            dashboard_file = self.drift_reports_dir / f"drift_dashboard_{timestamp}.html"
            report.save_html(str(dashboard_file))

            self.logger.info(f"âœ… Drift report generated: {dashboard_file}")

            # 7. Extract drift summary from report
            drift_dict = report.as_dict()
            metrics_data = drift_dict.get('metrics', [])

            # Find DatasetDriftMetric in metrics list
            drift_result = {}
            for metric in metrics_data:
                if 'DatasetDriftMetric' in str(type(metric)):
                    drift_result = metric.get('result', {})
                    break

            drift_summary = {
                'timestamp': timestamp,
                'n_features': drift_result.get('number_of_columns', 0),
                'n_drifted_features': drift_result.get('number_of_drifted_columns', 0),
                'share_drifted_features': drift_result.get('share_of_drifted_columns', 0),
                'dataset_drift': drift_result.get('dataset_drift', False),
            }

            # Save summary JSON
            summary_file = self.drift_reports_dir / f"drift_summary_{timestamp}.json"
            with open(summary_file, 'w') as f:
                json.dump(drift_summary, f, indent=2)

            # Update last report time
            self.last_report_time = datetime.now()

            self.logger.info(
                f"Drift detected: {drift_summary['n_drifted_features']}/{drift_summary['n_features']} features "
                f"({drift_summary['share_drifted_features']:.1%})"
            )

            return drift_summary

        except Exception as e:
            self.logger.error(f"Failed to generate drift report: {e}", exc_info=True)
            return {}
```

---

#### InterprÃ©tation Rapport Evidently

**Fichier HTML:** `drift_dashboard_20260127_143052.html`

**Sections du rapport:**

1. **Dataset Summary**
   - Reference dataset: 10,000 samples, 133 features
   - Production dataset: 1,000 samples, 133 features

2. **Dataset Drift**
   - Drift detected: **True** ou **False**
   - Share of drifted features: **3.7%** (5/133 features)

3. **Feature Drift Details**
   - Liste des 5 features driftÃ©es:
     - `a_hp`: drift score 0.234 (distribution changÃ©e)
     - `b_attack`: drift score 0.189
     - `effective_power_a`: drift score 0.156
     - `stat_ratio`: drift score 0.145
     - `a_move_type_mult`: drift score 0.123

4. **Distribution Plots**
   - Histogrammes reference (bleu) vs production (orange)
   - Permet de voir visuellement le shift de distribution

**Que faire si drift dÃ©tectÃ© ?**

1. **Analyser les causes:**
   - Nouvelles combinaisons PokÃ©mon utilisÃ©es ?
   - Meta-game a changÃ© (nouveaux mouvements populaires) ?
   - DonnÃ©es production != donnÃ©es training ?

2. **Actions:**
   - **Si drift minime (< 10%):** Continuer monitoring
   - **Si drift modÃ©rÃ© (10-30%):** Retraining modÃ¨le recommandÃ©
   - **Si drift sÃ©vÃ¨re (> 30%):** Retraining urgent + investigation

3. **Retraining:**
   ```bash
   # RÃ©cupÃ©rer production data sauvegardÃ©e
   # api_pokemon/monitoring/drift_data/production_data_*.parquet

   # Fusionner avec training set
   # Retrainer modÃ¨le avec nouvelles donnÃ©es
   python machine_learning/run_machine_learning.py --mode=retrain --production-data=...

   # Auto-promotion via MLflow si accuracy > 85%
   ```

---

## 5. IntÃ©gration ComplÃ¨te

### ðŸ”— Flow Complet: PrÃ©diction â†’ Monitoring â†’ Drift Detection

```
USER REQUEST
    â”‚
    â”‚  POST /predict/best-move
    â”‚  {
    â”‚    "pokemon_a_id": 25,
    â”‚    "pokemon_b_id": 1,
    â”‚    "available_moves": ["Fatal-Foudre"]
    â”‚  }
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. PrometheusMiddleware                    â”‚
â”‚     - Start timer                           â”‚
â”‚     - Track request START                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. API Route /predict/best-move            â”‚
â”‚     - Validate input (Pydantic)             â”‚
â”‚     - Load model from MLflow Registry       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. prediction_service.predict_best_move()  â”‚
â”‚     - Query Pokemon A & B from PostgreSQL   â”‚
â”‚     - Select best move B (opponent)         â”‚
â”‚     - Prepare features (38 raw features)    â”‚
â”‚     - Feature engineering (133 features)    â”‚
â”‚     - XGBoost predict                       â”‚
â”‚     - Return result                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚  result = {
                  â”‚    "recommended_move": "Fatal-Foudre",
                  â”‚    "win_probability": 0.8734,
                  â”‚    "all_moves": [...]
                  â”‚  }
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Track Prediction Metrics (Prometheus)   â”‚
â”‚     - track_prediction(                     â”‚
â”‚         model_version="v2",                 â”‚
â”‚         duration=0.327s,                    â”‚
â”‚         confidence=0.8734,                  â”‚
â”‚         win_prob=0.8734                     â”‚
â”‚       )                                     â”‚
â”‚     - Update Prometheus metrics:            â”‚
â”‚       â€¢ model_predictions_total += 1        â”‚
â”‚       â€¢ model_prediction_duration += 0.327s â”‚
â”‚       â€¢ model_confidence_score = 0.8734     â”‚
â”‚       â€¢ model_win_probability += 0.8734     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Drift Detection (Evidently)             â”‚
â”‚     - drift_detector.add_prediction(        â”‚
â”‚         features={...},                     â”‚
â”‚         prediction=1,                       â”‚
â”‚         probability=0.8734                  â”‚
â”‚       )                                     â”‚
â”‚     - Add to buffer (now: 543/1000)         â”‚
â”‚     - If buffer full â†’ generate_report()    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. PrometheusMiddleware (END)              â”‚
â”‚     - Stop timer (duration: 0.327s)         â”‚
â”‚     - Track request SUCCESS                 â”‚
â”‚     - api_requests_total += 1               â”‚
â”‚     - api_request_duration += 0.327s        â”‚
â”‚     - Update system metrics (CPU, RAM)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. Return JSON Response                    â”‚
â”‚     {                                       â”‚
â”‚       "recommended_move": "Fatal-Foudre",   â”‚
â”‚       "win_probability": 0.8734,            â”‚
â”‚       ...                                   â”‚
â”‚     }                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
              USER


BACKGROUND (Continuous)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Prometheus (every 10s)
    â”‚
    â”œâ”€ Scrape /metrics endpoint
    â”‚  â””â”€ Get latest metric values
    â”‚
    â”œâ”€ Store in TSDB (Time Series Database)
    â”‚  â””â”€ Timeseries data with timestamps
    â”‚
    â””â”€ Evaluate Alert Rules
       â”œâ”€ If P95 latency > 500ms for 2min â†’ Alert
       â””â”€ If error rate > 5% for 2min â†’ Alert


Grafana (real-time)
    â”‚
    â”œâ”€ Query Prometheus every 5s
    â”‚  â””â”€ Refresh dashboards
    â”‚
    â””â”€ Display visualizations
       â”œâ”€ Request rate graph
       â”œâ”€ Latency heatmap
       â””â”€ Model performance charts


Evidently (every 1000 predictions OR 1 hour)
    â”‚
    â”œâ”€ Buffer reaches 1000 predictions
    â”‚  â””â”€ Trigger drift report generation
    â”‚
    â”œâ”€ Compare production vs reference
    â”‚  â””â”€ Statistical tests (KS test, Chi-square, etc.)
    â”‚
    â”œâ”€ Generate HTML + JSON reports
    â”‚  â””â”€ Save to api_pokemon/monitoring/drift_reports/
    â”‚
    â””â”€ Clear buffer (reset to 0)
```

---

**VoilÃ  ! Vous avez maintenant une comprÃ©hension complÃ¨te du ML et du Monitoring.**

**CrÃ©Ã© le:** 27 janvier 2026
**Pour:** Certification RNCP E1/E3
**Niveau:** Explications dÃ©taillÃ©es production-ready
