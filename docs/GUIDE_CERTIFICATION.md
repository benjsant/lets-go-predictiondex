# Guide de Certification E1/E3 - Let's Go PredictionDex

## üéØ Vue d'ensemble

Ce document r√©capitule **tous les outils et scripts** disponibles pour pr√©parer et r√©ussir ta certification.

---

## üìÇ Structure des Scripts d'Orchestration

### **Scripts Principaux**

| Script | Taille | Usage | Comp√©tence |
|--------|--------|-------|------------|
| **demo_certification.py** | 13 KB | üéØ **D√©mo compl√®te certification** | E1 + E3 |
| **quick_start_docker.py** | 11 KB | üöÄ D√©marrage interactif stack | Setup |
| **validate_docker_stack.py** | 9.5 KB | ‚úÖ Validation services | V√©rification |
| **generate_monitoring_data.py** | 13 KB | üìä G√©n√©ration m√©triques Grafana | C11 |
| **populate_monitoring_v2.py** | 11 KB | üìà Remplir dashboards | C11 |
| **test_certification_workflow.py** | 13 KB | üß™ Test workflow CI/CD | C13 |
| **run_all_tests.py** | 11 KB | üß™ Ex√©cution tests complets | C12 |
| **generate_report_figures.py** | 31 KB | üìä G√©n√©ration figures rapport | Documentation |

### **Scripts MLflow**

| Script | Usage |
|--------|-------|
| **mlflow/check_mlflow_status.py** | ‚úÖ V√©rifier √©tat MLflow |
| **mlflow/enable_mlflow.py** | üîÑ Activer MLflow tracking |
| **mlflow/register_existing_model.py** | üì¶ Enregistrer mod√®le dans Registry |

---

## üöÄ Workflow de Pr√©paration (30 min)

### **1. D√©marrer la Stack Docker** (5 min)

```bash
# D√©marrage guid√© interactif
python scripts/quick_start_docker.py

# OU d√©marrage automatique
python scripts/quick_start_docker.py --auto
```

**Services d√©marr√©s :**
- PostgreSQL (port 5432)
- API FastAPI (port 8080)
- Streamlit (port 8502)
- Prometheus (port 9091)
- Grafana (port 3001)
- MLflow (port 5001)

---

### **2. Valider la Stack** (3 min)

```bash
# Validation compl√®te avec d√©tails
python scripts/validate_docker_stack.py --verbose
```

**V√©rifications effectu√©es :**
- ‚úÖ Tous les containers UP
- ‚úÖ Healthchecks OK
- ‚úÖ Endpoints accessibles
- ‚úÖ Base de donn√©es connect√©e

---

### **3. G√©n√©rer des M√©triques pour Grafana** (10 min)

```bash
# G√©n√©ration 10 minutes de m√©triques r√©alistes
python scripts/generate_monitoring_data.py --mode realistic --duration 10

# OU g√©n√©ration rapide (burst)
python scripts/generate_monitoring_data.py --mode burst --duration 5
```

**M√©triques g√©n√©r√©es :**
- Pr√©dictions ML (200-500 requ√™tes)
- Latence API (50-200ms)
- Taux d'erreurs (< 1%)
- Confiance mod√®le (0.85-0.95)
- CPU/Memory usage

---

### **4. V√©rifier MLflow** (2 min)

```bash
# V√©rifier √©tat MLflow
python scripts/mlflow/check_mlflow_status.py

# Si mod√®le non enregistr√©, l'enregistrer
python scripts/mlflow/register_existing_model.py
```

**R√©sultat attendu :**
- ‚úÖ Serveur MLflow UP
- ‚úÖ 3 exp√©rimentations
- ‚úÖ 1 mod√®le en Production (battle_winner_predictor v1)
- ‚úÖ M√©triques : 96.26% accuracy, 99.54% ROC-AUC

---

### **5. Lancer la D√©mo Certification** (10 min)

```bash
# D√©mo compl√®te automatique
python scripts/demo_certification.py

# Ouvrir seulement les interfaces web
python scripts/demo_certification.py --web-only

# Avec g√©n√©ration de m√©triques
python scripts/demo_certification.py --generate-metrics
```

**Ce script ouvre automatiquement :**
- Streamlit ‚Üí http://localhost:8502
- Swagger API ‚Üí http://localhost:8080/docs
- Grafana ‚Üí http://localhost:3001
- Prometheus ‚Üí http://localhost:9091
- MLflow ‚Üí http://localhost:5001

---

## üéØ Plan de D√©monstration (30 min)

### **Phase 1 : Interfaces Web Interactives** (12 min)

#### **1. Streamlit** (4 min) - **C10**
**URL :** http://localhost:8502

**√Ä montrer :**
- ‚úÖ **Page "Combat et Pr√©diction"** : Pr√©diction en temps r√©el
- ‚úÖ S√©lection Pok√©mon A vs Pok√©mon B
- ‚úÖ API call + r√©sultat (meilleur move + win probability)
- ‚úÖ Interface responsive et accessible
- ‚úÖ 8 pages au total

**Script √† dire :**
> "Voici l'interface Streamlit qui int√®gre l'API ML. L'utilisateur s√©lectionne deux Pok√©mon, l'application appelle mon API de pr√©diction, et affiche le meilleur move avec la probabilit√© de victoire. L'interface est responsive et accessible (WCAG 2.1 AA)."

---

#### **2. Swagger API** (3 min) - **C9**
**URL :** http://localhost:8080/docs

**√Ä montrer :**
- ‚úÖ **Endpoint POST /predict/best-move** : Tester avec JSON
- ‚úÖ Request body : `{"pokemon_a_id": 1, "pokemon_b_id": 4, "available_moves": [1, 2, 3]}`
- ‚úÖ Response : `{"recommended_move": {...}, "win_probability": 0.87}`
- ‚úÖ Documentation auto-g√©n√©r√©e
- ‚úÖ Authentification API Key (X-API-Key header)

**JSON exemple :**
```json
{
  "pokemon_a_id": 1,
  "pokemon_b_id": 4,
  "available_moves": [33, 45, 99]
}
```

**Script √† dire :**
> "L'API REST expose le mod√®le XGBoost avec 96.26% accuracy. Elle prend en entr√©e deux Pok√©mon et les moves disponibles, et retourne le meilleur move avec la probabilit√© de victoire. L'API est s√©curis√©e avec API Key et document√©e avec Swagger."

---

#### **3. Grafana** (3 min) - **C11**
**URL :** http://localhost:3001 (admin/admin)

**√Ä montrer :**
- ‚úÖ **Dashboard "Model Performance"** :
  - Predictions per Minute
  - Model Confidence Score (gauge)
  - Win Probability distribution
- ‚úÖ **Dashboard "API Performance"** :
  - API Status (UP/DOWN)
  - Request Duration (latency)
  - Error Rate
  - CPU/Memory Usage

**Script √† dire :**
> "Pour le monitoring en production, j'utilise Grafana qui affiche les m√©triques en temps r√©el. On voit ici le nombre de pr√©dictions par minute, la confiance du mod√®le, et les performances de l'API. Les dashboards sont accessibles (navigation clavier, WCAG 2.1 AA)."

---

#### **4. Prometheus** (1 min) - **C11**
**URL :** http://localhost:9091

**√Ä montrer :**
- ‚úÖ **Onglet "Targets"** : Tous les targets UP (vert)
- ‚úÖ API scrape toutes les 15s
- ‚úÖ 9 m√©triques collect√©es

**Script √† dire :**
> "Prometheus collecte les m√©triques toutes les 15 secondes. On voit ici que tous les targets sont UP, et les donn√©es sont stock√©es avec 15 jours de r√©tention."

---

#### **5. MLflow** (2 min) - **C13**
**URL :** http://localhost:5001

**√Ä montrer :**
- ‚úÖ **Onglet "Experiments"** : 3 exp√©rimentations
  - pokemon_battle_winner
  - demo_monitoring
  - Default
- ‚úÖ **Onglet "Models"** : battle_winner_predictor v1 (Production)
- ‚úÖ **M√©triques** : 96.26% accuracy, 99.54% ROC-AUC

**Script √† dire :**
> "MLflow g√®re le Model Registry et l'experiment tracking. Ici on voit mon mod√®le battle_winner_predictor en version 1, promu en Production car l'accuracy d√©passe 95%. Les m√©triques et artifacts sont versionn√©s."

---

### **Phase 2 : Composants Backend** (10 min)

#### **6. PostgreSQL** (3 min) - **E1.3**
**Via Swagger API :**
- GET /pokemon ‚Üí Liste 151 Pok√©mon
- GET /types ‚Üí 18 types
- GET /moves ‚Üí 600+ moves

**√Ä montrer dans Swagger :**
```bash
# Via terminal (alternatif)
docker exec letsgo_db psql -U letsgo_user -d letsgo_db -c "\dt"
```

**Tables (11) :**
- pokemon_species, pokemon, form
- type, pokemon_type, type_effectiveness
- move, move_category, pokemon_move, learn_method
- pokemon_stat

**Script √† dire :**
> "La base de donn√©es PostgreSQL contient 11 tables normalis√©es 3NF avec contraintes d'int√©grit√© r√©f√©rentielle. Les donn√©es proviennent de 3 sources : Pok√©API, CSV, et scraping Pok√©p√©dia."

---

#### **7. ETL Pipeline** (3 min) - **E1.1, E1.2**

```bash
# Voir logs format√©s
docker logs letsgo_etl --tail 100
```

**√âtapes ETL (5) :**
1. **Init DB** : Cr√©ation sch√©ma + tables
2. **Load CSV** : 3 fichiers (Pokemon, Moves, Types)
3. **Enrich Pok√©API** : Stats + sprites (threading 10 workers)
4. **Scraping** : Pokepedia moves (Scrapy)
5. **Post-processing** : H√©ritage moves + √©volutions

**Script √† dire :**
> "Le pipeline ETL automatise la collecte depuis 3 sources : fichiers CSV, API REST (Pok√©API), et web scraping (Pokepedia). Les donn√©es sont nettoy√©es, normalis√©es et agr√©g√©es dans PostgreSQL. Le pipeline est idempotent et versioned dans Git."

---

#### **8. ML Training** (4 min) - **C12**

```bash
# Voir logs entra√Ænement
docker logs letsgo_ml --tail 100

# Ouvrir notebook
code notebooks/03_training_evaluation.ipynb
```

**Pipeline ML :**
1. Dataset : 718,889 combats (3 sc√©narios)
2. Features : 133 features engineered
3. Model : XGBoost Classifier
4. Training : GridSearchCV (8 combos)
5. Evaluation : 96.26% accuracy, 99.54% ROC-AUC

**Script √† dire :**
> "Le pipeline ML g√©n√®re 718k combats depuis la base de donn√©es, calcule 133 features (stats, types, STAB, effectiveness), entra√Æne un XGBoost avec GridSearchCV, et √©value sur un test set. L'accuracy finale est 96.26%."

---

### **Phase 3 : Technique Avanc√©** (8 min)

#### **9. Drift Detection** (2 min) - **C11**

```bash
# Lister fichiers drift
ls -lh api_pokemon/monitoring/drift_data/

# Lire un fichier parquet
python -c "import pandas as pd; df = pd.read_parquet('api_pokemon/monitoring/drift_data/production_data_20260201_163846.parquet'); print(df.describe())"
```

**√Ä montrer :**
- ‚úÖ Fichiers parquet dat√©s (93 KB chacun)
- ‚úÖ 100 pr√©dictions par fichier
- ‚úÖ Features collect√©es pour analyse future

**Script √† dire :**
> "Le DriftDetector collecte automatiquement les features de chaque pr√©diction en production et les sauvegarde en parquet. Ces donn√©es permettent de d√©tecter des d√©rives de distribution et de d√©clencher un retraining si n√©cessaire."

---

#### **10. GitHub Actions** (3 min) - **C13**

**URL :** https://github.com/USERNAME/lets-go-predictiondex/actions

**Workflows (7) :**
1. **certification-e1-e3.yml** : Workflow complet certification
2. **1-lint-and-format.yml** : Lint + format
3. **2-tests-unit.yml** : Tests unitaires
4. **3-docker-build.yml** : Build images Docker
5. **4-integration-tests.yml** : Tests int√©gration
6. **monitoring-validation.yml** : Tests monitoring
7. **(autres workflows...)**

**√Ä montrer :**
- ‚úÖ **D√©clencheurs** : push, PR, workflow_dispatch
- ‚úÖ **Jobs** : E1 data validation, E3 API/monitoring/MLOps
- ‚úÖ **Artifacts** : Coverage reports, test results

**Script √† dire :**
> "La cha√Æne CI/CD GitHub Actions comprend 7 workflows qui testent automatiquement le code, buildent les images Docker, et valident les comp√©tences E1 et E3. Les workflows sont d√©clench√©s sur chaque push et pull request."

---

#### **11. Documentation** (3 min) - **E1.5**

```bash
# Lister documentation
ls -lh docs/
tree docs/ -L 2
```

**Documents (20+) :**
- **README.md** : Guide complet projet
- **docs/ARCHITECTURE.md** : Architecture technique
- **docs/MONITORING.md** : Guide monitoring complet
- **docs/ACCESSIBILITE_MONITORING.md** : Tests accessibilit√©
- **docs/figures/** : Diagrammes MCD, architecture
- **machine_learning/README.md** : Guide ML
- **api_pokemon/README.md** : Guide API

**Script √† dire :**
> "La documentation est compl√®te et accessible (markdown, WCAG 2.1 AA). Elle couvre l'architecture, le monitoring, l'accessibilit√©, et tous les composants du projet. Les diagrammes MCD et d'architecture sont inclus."

---

## üéì Mapping Comp√©tences ‚Üí Composants

### **BLOC E1 - DONN√âES**

| Comp√©tence | Composant | Preuve |
|------------|-----------|--------|
| **C1** - Collecte donn√©es | ETL Pipeline | [etl_pokemon/pipeline.py](../etl_pokemon/pipeline.py) |
| **C2** - Requ√™tes SQL | SQLAlchemy ORM | [core/db/guards/](../core/db/guards/) |
| **C3** - Nettoyage donn√©es | Normalizers | [etl_pokemon/utils/normalizers.py](../etl_pokemon/utils/normalizers.py) |
| **C4** - Structurer BDD | PostgreSQL 11 tables | [core/models/](../core/models/) |
| **C5** - API donn√©es | FastAPI REST | [api_pokemon/routes/](../api_pokemon/routes/) |

### **BLOC E3 - IA PRODUCTION**

| Comp√©tence | Composant | Preuve |
|------------|-----------|--------|
| **C9** - API REST + IA | FastAPI + XGBoost | [api_pokemon/routes/prediction_route.py](../api_pokemon/routes/prediction_route.py) |
| **C10** - Int√©gration app | Streamlit 8 pages | [interface/app.py](../interface/app.py) |
| **C11** - Monitoring IA | Prometheus + Grafana + MLflow | [api_pokemon/monitoring/](../api_pokemon/monitoring/) |
| **C12** - Tests ML | Pytest 407 tests | [tests/ml/](../tests/ml/) |
| **C13** - MLOps CI/CD | GitHub Actions + MLflow | [.github/workflows/](../.github/workflows/) |

---

## üìä M√©triques du Projet

| M√©trique | Valeur |
|----------|--------|
| **Python Files** | 150+ |
| **Test Files** | 23 |
| **Test Functions** | 407 |
| **Code Coverage** | 82%+ |
| **Database Tables** | 11 |
| **API Endpoints** | 15+ |
| **GitHub Workflows** | 7 |
| **Docker Services** | 10 |
| **ML Features** | 133+ |
| **Model Accuracy** | 96.26% |
| **Model ROC-AUC** | 99.54% |
| **Training Dataset** | 718,889 combats |
| **Documentation Files** | 20+ |

---

## üîß Commandes Utiles

### **Logs**
```bash
# ETL Pipeline
docker logs letsgo_etl --tail 200

# ML Training
docker logs letsgo_ml --tail 200

# API FastAPI
docker logs letsgo_api --tail 200

# Tous les logs
docker compose logs -f
```

### **Base de Donn√©es**
```bash
# Connexion PostgreSQL
docker exec -it letsgo_db psql -U letsgo_user -d letsgo_db

# Lister tables
docker exec letsgo_db psql -U letsgo_user -d letsgo_db -c "\dt"

# Compter Pok√©mon
docker exec letsgo_db psql -U letsgo_user -d letsgo_db -c "SELECT COUNT(*) FROM pokemon;"
```

### **Tests**
```bash
# Tous les tests
python scripts/run_all_tests.py

# Tests ML seulement
pytest tests/ml/ -v

# Tests monitoring
pytest tests/monitoring/ -v

# Coverage
pytest --cov=api_pokemon --cov=machine_learning --cov-report=html
```

### **Docker**
```bash
# √âtat des services
docker compose ps

# Red√©marrer un service
docker compose restart api

# Voir ressources
docker stats

# Nettoyer
docker compose down -v
docker system prune -a
```

---

## ‚úÖ Checklist Pr√©-Certification

### **1 Semaine Avant**
- [ ] Tester le workflow complet (`python scripts/demo_certification.py`)
- [ ] V√©rifier tous les services UP (`python scripts/validate_docker_stack.py`)
- [ ] G√©n√©rer captures d'√©cran (Grafana, MLflow, Streamlit)
- [ ] Relire documentation (README.md, MONITORING.md)
- [ ] Tester en condition r√©elle (30 min chrono)

### **La Veille**
- [ ] Activer MLflow (`python scripts/mlflow/register_existing_model.py`)
- [ ] G√©n√©rer m√©triques Grafana (`python scripts/generate_monitoring_data.py --duration 10`)
- [ ] V√©rifier MLflow status (`python scripts/mlflow/check_mlflow_status.py`)
- [ ] Tester tous les endpoints API
- [ ] Pr√©parer notes de pr√©sentation

### **Le Jour J**
- [ ] D√©marrer stack Docker (`python scripts/quick_start_docker.py`)
- [ ] Valider services (`python scripts/validate_docker_stack.py --verbose`)
- [ ] Ouvrir tous les onglets (`python scripts/demo_certification.py --web-only`)
- [ ] Respirer profond√©ment üòä
- [ ] Pr√©senter avec confiance !

---

## üö® Troubleshooting

### **Probl√®me : Services ne d√©marrent pas**
```bash
# V√©rifier Docker
docker ps

# V√©rifier logs
docker compose logs

# Red√©marrer
docker compose down
docker compose up -d
```

### **Probl√®me : Ports d√©j√† utilis√©s**
```bash
# Identifier processus
lsof -i :8080
lsof -i :5432

# Tuer processus
kill -9 <PID>
```

### **Probl√®me : Base de donn√©es vide**
```bash
# Relancer ETL
docker compose up -d db
python etl_pokemon/pipeline.py --force
```

### **Probl√®me : MLflow ne d√©marre pas**
```bash
# Logs MLflow
docker logs letsgo_mlflow

# Red√©marrer MLflow
docker compose restart mlflow

# V√©rifier health
curl http://localhost:5001/health
```

---

## üìû Support

- **Documentation** : [README.md](../README.md)
- **Architecture** : [docs/ARCHITECTURE.md](ARCHITECTURE.md)
- **Monitoring** : [docs/MONITORING.md](MONITORING.md)
- **Accessibilit√©** : [docs/ACCESSIBILITE_MONITORING.md](ACCESSIBILITE_MONITORING.md)

---

## üéâ Conclusion

**Tu as tous les outils pour r√©ussir ta certification !**

**Score attendu :**
- **E1** : 100% (5/5 comp√©tences)
- **E3** : 98% (5/5 comp√©tences)

**Points forts √† mettre en avant :**
- Architecture compl√®te et professionnelle
- Pipeline ML performant (96.26% accuracy)
- Monitoring production-ready (Prometheus + Grafana + MLflow)
- Tests exhaustifs (407 tests, 82% coverage)
- CI/CD automatis√©e (7 workflows GitHub Actions)
- Documentation accessible et compl√®te

**Bonne chance ! üçÄ**

---

**Version** : 2.0
**Derni√®re mise √† jour** : 2 f√©vrier 2026
**Auteur** : Let's Go PredictionDex Team
