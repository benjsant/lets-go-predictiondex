# Comprendre le Pipeline Machine Learning

Ce document explique comment est structur√© le projet Machine Learning de PredictionDex, de l'exp√©rimentation (Notebooks) √† la production (Scripts Python).

## üó∫Ô∏è Vue d'Ensemble

Le projet suit une structure standard en Data Science : **R&D** ‚Üí **Industrialisation** ‚Üí **Production**.

```mermaid
graph TD
    subgraph "1. R&D (Experimentation)"
        N1[01_exploration.ipynb] --> N2[02_feature_engineering.ipynb]
        N2 --> N3[03_training_evaluation.ipynb]
    end

    subgraph "2. Industrialisation (Code Python)"
        S1[build_dataset.py] --> S2[train_model.py]
        S2 --> S3[run_machine_learning.py]
    end

    subgraph "3. Artifacts (R√©sultats)"
        D1[data/ml/raw] --> D2[data/ml/processed]
        D2 --> M[models/*.pkl]
    end

    N3 -.-> |Validation| S2
    S3 --> M
```

---

## üìÇ 1. Recherche & D√©veloppement (`notebooks/`)

C'est votre **laboratoire**. Ici, le code peut √™tre "sale", on teste des id√©es, on visualise des graphiques. Le but est de comprendre les donn√©es.

| Notebook | But | Description |
|----------|-----|-------------|
| **01_exploration.ipynb** | **Comprendre** | On charge les donn√©es brutes. On regarde s'il y a des valeurs manquantes, on trace des histogrammes pour voir la distribution des stats (HP, Attaque...). |
| **02_feature_engineering.ipynb** | **Transformer** | On teste des transformations math√©matiques. *Exemple : Transformer le type "Feu" en colonnes num√©riques (One-Hot Encoding).* |
| **03_training_evaluation.ipynb** | **Comparer** | On entra√Æne plusieurs mod√®les (Random Forest, XGBoost, Regression Logistique) et on compare leurs scores pour choisir le meilleur. |

**üëâ Comment jouer avec ?**
Lancez Jupyter (`jupyter notebook`) et modifiez les cellules. Si vous trouvez une nouvelle feature g√©niale, notez-la !

---

## üè≠ 2. Pipeline de Production (`machine_learning/`)

C'est votre **usine**. Une fois qu'une id√©e est valid√©e dans les notebooks, on la copie ici dans des scripts Python propres et robustes.

### `build_battle_winner_dataset.py` (Le G√©n√©rateur)
Ce script cr√©e les donn√©es d'entra√Ænement.
1. Il se connecte √† la base de donn√©es.
2. Il simule 34 000+ combats (tous les Pok√©mon contre tous les Pok√©mon).
3. Pour chaque combat, il d√©termine qui gagne math√©matiquement.
4. Il sauvegarde le tout dans `data/ml/raw/matchups.parquet`.

### `train_model.py` (L'Entra√Æneur)
Ce script entra√Æne le mod√®le officiel.
1. Il charge les donn√©es g√©n√©r√©es.
2. Il applique les transformations valid√©es (Feature Engineering).
3. Il entra√Æne le mod√®le (XGBoost).
4. Il sauvegarde le cerveau du mod√®le dans un fichier `.pkl` (Pickle).

### `run_machine_learning.py` (Le Chef d'Orchestre)
C'est le script "bouton magique". Il lance le G√©n√©rateur puis l'Entra√Æneur √† la suite.
```bash
python machine_learning/run_machine_learning.py --mode=all
```

---

## üì¶ 3. Les Donn√©es (`data/`)

C'est votre **entrep√¥t**.

- **`data/ml/raw/`** : Les donn√©es brutes sorties du simulateur.
- **`data/ml/processed/`** : Les donn√©es nettoy√©es et s√©par√©es en deux :
  - **Train (80%)** : Pour que le mod√®le apprenne.
  - **Test (20%)** : Pour v√©rifier si le mod√®le a bien appris (examen final).

---

## üöÄ Workflow Typique (Cycle de Vie)

Voici comment travailler efficacement :

1.  **Hypoth√®se** : "Je pense que si j'ajoute la diff√©rence de Vitesse entre les deux Pok√©mon, le mod√®le sera meilleur."
2.  **Test (Notebook)** : 
    - Ouvrir `02_feature_engineering.ipynb`.
    - Cr√©er la variable `speed_diff = speed_A - speed_B`.
    - Relancer l'entra√Ænement dans le notebook.
    - R√©sultat : L'accuracy passe de 92% √† 94% ! üéâ
3.  **Migration (Script)** : 
    - Copier la logique de `speed_diff` dans le script `machine_learning/train_model.py`.
4.  **Production (Docker)** :
    - Lancer `docker compose up --build`.
    - Le conteneur va r√©-entra√Æner le mod√®le avec votre nouvelle feature.
    - Le nouveau mod√®le est maintenant actif dans l'API !

---

## üõ†Ô∏è Commandes Utiles

**Lancer tout le pipeline (G√©n√©ration + Entra√Ænement) :**
```bash
python machine_learning/run_machine_learning.py --mode=all
```

**Juste r√©-entra√Æner le mod√®le (si on a chang√© les hyperparam√®tres) :**
```bash
python machine_learning/run_machine_learning.py --mode=train
```

**Voir la performance du mod√®le actuel :**
```bash
python machine_learning/run_machine_learning.py --mode=evaluate
```
