# Changelog - MLflow Model Registry Integration

**Date** : 25 janvier 2025  
**Version** : Phase 2 - MLflow Model Registry  
**Objectif** : Centraliser la gestion des mod√®les ML avec versioning et promotion automatique

---

## üéØ Objectif de cette Session

Apr√®s avoir optimis√© les performances CPU du ML (Phase 1), cette session impl√©mente le **MLflow Model Registry** pour :
- ‚úÖ Centraliser les mod√®les entra√Æn√©s dans un registry versionn√©
- ‚úÖ Promouvoir automatiquement les meilleurs mod√®les en Production
- ‚úÖ Charger les mod√®les depuis l'API sans d√©pendance aux fichiers locaux
- ‚úÖ Simplifier le rollback et la comparaison des versions

---

## üì¶ Fichiers Modifi√©s

### 1. **machine_learning/mlflow_integration.py**
**Changements** : Ajout de 5 nouvelles fonctions pour le Model Registry

```python
# Nouvelles fonctions
def register_model(model_name, description) -> str
def promote_to_production(model_name, version) -> bool
def promote_best_model(model_name, metric, minimum_metric_value) -> bool
def compare_models(model_name) -> pd.DataFrame
def load_model_from_registry(model_name, stage, version) -> Dict

# Am√©lioration de log_model()
def log_model(model, scalers=None, metadata=None)
    # Loggue maintenant aussi scalers.pkl et metadata.pkl comme artifacts
```

**Fonctionnalit√©s** :
- ‚úÖ `register_model()` : Enregistre le mod√®le du run actif dans le registry
- ‚úÖ `promote_to_production()` : Transition vers Production, archive l'ancienne version
- ‚úÖ `promote_best_model()` : Promotion automatique si m√©trique >= seuil
- ‚úÖ `compare_models()` : Retourne DataFrame comparant toutes les versions
- ‚úÖ `load_model_from_registry()` : Charge mod√®le + scalers + metadata depuis le registry
- ‚úÖ `log_model()` : Loggue maintenant scalers et metadata comme artifacts suppl√©mentaires

---

### 2. **machine_learning/run_machine_learning.py**
**Changements** : Int√©gration du registry dans les 3 modes (train/evaluate, compare, all)

```python
# Apr√®s chaque export_model() et tracker.log_model()
version_number = tracker.register_model(
    model_name="battle_winner_predictor",
    description=f"{model_name} - Accuracy: {accuracy:.4f}"
)

# Promotion automatique si accuracy >= 0.85
if version_number and metrics['test_accuracy'] >= 0.85:
    tracker.promote_to_production("battle_winner_predictor", version_number)
    print("üéØ Model meets quality threshold (accuracy >= 0.85)")
    print("‚úÖ Model promoted to Production stage")
else:
    print("‚ö†Ô∏è  Model registered but not promoted (accuracy < 0.85)")
```

**Impact** :
- ‚úÖ **3 emplacements modifi√©s** : modes 'train/evaluate', 'compare', 'all'
- ‚úÖ **Enregistrement automatique** apr√®s chaque entra√Ænement
- ‚úÖ **Promotion automatique** si accuracy >= 85%
- ‚úÖ **Scalers et metadata** logg√©s comme artifacts pour chargement complet

---

### 3. **machine_learning/train_model.py**
**Changements** : Ajout de l'int√©gration MLflow Registry dans le script standalone

```python
# Nouvel import
try:
    from machine_learning.mlflow_integration import MLflowTracker
    MLFLOW_AVAILABLE = True
except ImportError:
    MLFLOW_AVAILABLE = False

# Apr√®s export_model()
if MLFLOW_AVAILABLE and model_path and not args.no_mlflow:
    tracker = MLflowTracker(experiment_name=f"battle_winner_{args.version}")
    tracker.start_run(run_name=f"train_model_{args.version}_{timestamp}")
    
    tracker.log_params({...})
    tracker.log_metrics(metrics)
    tracker.log_model(model, scalers=scalers, metadata={'feature_columns': feature_columns})
    
    # Register + auto-promote
    version_number = tracker.register_model("battle_winner_predictor", description)
    if version_number and metrics['test_accuracy'] >= 0.85:
        tracker.promote_to_production("battle_winner_predictor", version_number)
    
    tracker.end_run()
```

**Nouvelle option** :
```bash
python machine_learning/train_model.py --no-mlflow  # D√©sactiver le registry
```

**Impact** :
- ‚úÖ **Script standalone** maintenant compatible avec le registry
- ‚úÖ **Enregistrement automatique** apr√®s entra√Ænement
- ‚úÖ **Option --no-mlflow** pour tests sans MLflow
- ‚úÖ **Scalers et metadata** logg√©s pour chargement complet

---

### 4. **api_pokemon/services/prediction_service.py**
**Changements** : Chargement depuis MLflow Registry avec fallback local

```python
# Nouveaux imports
try:
    from machine_learning.mlflow_integration import load_model_from_registry
    MLFLOW_AVAILABLE = True
except ImportError:
    MLFLOW_AVAILABLE = False

# Nouvelle m√©thode load()
def load(self):
    use_mlflow = os.getenv('USE_MLFLOW_REGISTRY', 'true').lower() == 'true'
    
    # 1. Try MLflow Registry (Production stage)
    if use_mlflow and MLFLOW_AVAILABLE:
        model_bundle = load_model_from_registry(
            model_name="battle_winner_predictor",
            stage="Production"
        )
        if model_bundle:
            self._model = model_bundle['model']
            self._scalers = model_bundle['scalers']
            self._metadata = model_bundle['metadata']
            print("‚úÖ Model loaded from MLflow Registry")
            return
    
    # 2. Fallback: Load from local files
    print("‚ö†Ô∏è Falling back to local files...")
    self._model = joblib.load("models/battle_winner_model_v2.pkl")
    ...
```

**Variables d'environnement** :
```bash
USE_MLFLOW_REGISTRY=true           # Enable/disable registry (default: true)
MLFLOW_MODEL_NAME=battle_winner_predictor
MLFLOW_MODEL_STAGE=Production      # Production, Staging, Archived
MLFLOW_TRACKING_URI=http://mlflow:5000
```

**Impact** :
- ‚úÖ **Chargement automatique** depuis Production stage
- ‚úÖ **Fallback robuste** sur fichiers locaux si √©chec
- ‚úÖ **Logs clairs** pour diagnostiquer la source du mod√®le
- ‚úÖ **Compatible** avec environnements sans MLflow

---

## üîÑ Workflow Complet

### Avant (sans Model Registry)

```
1. Entra√Ænement ‚Üí models/battle_winner_model_v2.pkl
2. API ‚Üí Charge depuis fichiers locaux
3. Rollback ‚Üí Remplacer manuellement les fichiers .pkl
4. Comparaison ‚Üí Impossible sans garder tous les .pkl
```

### Apr√®s (avec Model Registry)

```
1. Entra√Ænement ‚Üí models/*.pkl + MLflow Registry (versioning)
2. Promotion automatique ‚Üí Production stage si accuracy >= 0.85
3. API ‚Üí Charge depuis Production stage (avec fallback local)
4. Comparaison ‚Üí MLflow UI ou compare_models()
5. Rollback ‚Üí Promouvoir une version pr√©c√©dente en 1 clic
```

---

## üìä Exemple d'Utilisation

### Sc√©nario 1 : Entra√Ænement et D√©ploiement Automatique

```bash
# 1. Entra√Æner un mod√®le
$ python machine_learning/train_model.py --use-gridsearch --version v4

Output:
‚úÖ Model trained and exported
‚úÖ Logged to MLflow (run: train_model_v4_20250125_1430)
‚úÖ Registered as version 4 in Model Registry
üéØ Model meets quality threshold (accuracy >= 0.85)
‚úÖ Model promoted to Production stage

# 2. L'API recharge automatiquement
# Au prochain appel de pr√©diction :
üîç Loading ML model...
   Trying MLflow Model Registry (battle_winner_predictor @ Production)...
‚úÖ Model loaded from MLflow Registry
   Version: 4
```

### Sc√©nario 2 : Comparaison et Rollback

```python
from machine_learning.mlflow_integration import MLflowTracker

tracker = MLflowTracker()
tracker.start_run()

# Comparer toutes les versions
df = tracker.compare_models("battle_winner_predictor")
print(df)
"""
version  stage       accuracy  f1_score  roc_auc   created_at
4        Production  0.8723    0.8654    0.9234    2025-01-25 14:30
3        Staging     0.8512    0.8401    0.9102    2025-01-25 12:15
2        Archived    0.8203    0.8123    0.8956    2025-01-24 18:45
"""

# Rollback √† la version 3 si probl√®me
tracker.promote_to_production("battle_winner_predictor", version=3)
# ‚úÖ Version 3 transitioned to Production
# ‚úÖ Previous Production version archived
```

---

## üß™ Tests Pr√©vus

### Tests Unitaires

```bash
# Test 1 : Enregistrement et promotion
tests/mlflow/test_model_registry.py
- test_register_model()
- test_promote_to_production()
- test_promote_best_model()
- test_compare_models()
- test_load_model_from_registry()

# Test 2 : Int√©gration API
tests/integration/test_mlflow_to_api.py
- test_e2e_mlflow_to_api()
- test_api_fallback_to_local()
```

### Tests Manuels

```bash
# 1. Entra√Æner et v√©rifier registry
python machine_learning/train_model.py --use-gridsearch
# ‚Üí V√©rifier MLflow UI : Models ‚Üí battle_winner_predictor

# 2. Tester chargement API
docker compose up api
curl http://localhost:8000/api/v1/pokemon/1/predict-against/4
# ‚Üí Logs API : "‚úÖ Model loaded from MLflow Registry"

# 3. Tester fallback
USE_MLFLOW_REGISTRY=false docker compose up api
# ‚Üí Logs API : "‚ö†Ô∏è Falling back to local files..."
```

---

## üìà M√©triques et Seuils

### Seuil de Promotion Automatique

```python
PROMOTION_THRESHOLD = 0.85  # accuracy >= 85%

# Modifiable dans :
# - machine_learning/run_machine_learning.py (lignes ~1076, ~1113, ~1174)
# - machine_learning/train_model.py (ligne ~644)
```

### M√©triques Logg√©es

```python
{
    'train_accuracy': 0.8956,
    'test_accuracy': 0.8723,   # ‚≠ê Crit√®re de promotion
    'test_precision': 0.8654,
    'test_recall': 0.8598,
    'test_f1': 0.8626,
    'test_roc_auc': 0.9234,
    'overfitting': 0.0233
}
```

---

## üêõ Probl√®mes R√©solus

### Probl√®me 1 : Scalers et Metadata Non Disponibles

**Avant** : `load_model_from_registry()` retournait seulement le mod√®le

**Solution** : 
- Modifier `log_model()` pour logger `scalers.pkl` et `metadata.pkl` comme artifacts
- Modifier `load_model_from_registry()` pour t√©l√©charger et charger ces artifacts
- Retourner un dict `{'model': ..., 'scalers': ..., 'metadata': ..., 'version': ...}`

### Probl√®me 2 : Import Circulaire dans l'API

**Avant** : `from machine_learning.mlflow_integration import load_model_from_registry` causait des erreurs

**Solution** :
- Wrap l'import dans un try/except
- D√©finir `MLFLOW_AVAILABLE = False` si √©chec
- L'API fonctionne avec ou sans MLflow

### Probl√®me 3 : Promotion Non Automatique

**Avant** : Fallait promouvoir manuellement depuis MLflow UI

**Solution** :
- Ajouter `promote_best_model()` qui v√©rifie le seuil automatiquement
- Int√©grer dans run_machine_learning.py et train_model.py
- Logs clairs : "üéØ Model meets threshold" ou "‚ö†Ô∏è Not promoted"

---

## üìö Documentation Cr√©√©e

1. **MLFLOW_REGISTRY_GUIDE.md** (ce fichier)
   - Architecture et workflow
   - Utilisation compl√®te (train, load, compare, rollback)
   - Troubleshooting
   - Variables d'environnement

2. **CHANGELOG_MLFLOW_REGISTRY.md** (fichier actuel)
   - Modifications d√©taill√©es par fichier
   - Exemples d'utilisation
   - Tests pr√©vus

---

## ‚úÖ R√©sum√© des Changements

| Fichier | Fonctionnalit√©s Ajout√©es | Impact |
|---------|-------------------------|--------|
| `mlflow_integration.py` | 5 fonctions registry + am√©lioration log_model | ‚≠ê‚≠ê‚≠ê Core registry |
| `run_machine_learning.py` | Register + promote dans 3 modes | ‚≠ê‚≠ê‚≠ê Enregistrement auto |
| `train_model.py` | Int√©gration registry + option --no-mlflow | ‚≠ê‚≠ê Script standalone |
| `prediction_service.py` | Load from registry + fallback local | ‚≠ê‚≠ê‚≠ê API sans fichiers |

---

## üöÄ Prochaines √âtapes

### Phase 3 : Tests Complets

1. ‚úÖ √âcrire tests unitaires pour le Model Registry
2. ‚úÖ √âcrire tests d'int√©gration ML ‚Üí API
3. ‚úÖ Tester fallback sur fichiers locaux
4. ‚úÖ Valider promotion automatique

### Phase 4 : Validation Docker

1. ‚úÖ `docker compose up --build`
2. ‚úÖ V√©rifier MLflow service d√©marre
3. ‚úÖ V√©rifier ml_builder enregistre mod√®le
4. ‚úÖ V√©rifier API charge depuis registry
5. ‚úÖ Tester pr√©dictions end-to-end

---

**Statut** : ‚úÖ MLflow Model Registry int√©gr√© et document√©  
**Prochain** : Tests complets ‚Üí docker compose up üöÄ
