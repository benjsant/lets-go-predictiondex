#!/usr/bin/env python3
"""
Test rapide de l'intÃ©gration MLflow
===================================

CrÃ©e un run MLflow de test pour valider l'infrastructure.

Usage:
    python scripts/test_mlflow_integration.py
"""

import sys
import os
import time
from pathlib import Path

# Ajouter le projet au path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import mlflow
    import mlflow.sklearn
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.datasets import make_classification
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, f1_score
except ImportError as e:
    print(f"âŒ DÃ©pendance manquante: {e}")
    print("ğŸ’¡ Installez les dÃ©pendances: pip install mlflow scikit-learn")
    sys.exit(1)


def test_mlflow_connection():
    """Teste la connexion Ã  MLflow."""
    print("ğŸ”Œ Test de connexion MLflow...")
    
    # Configurer l'URI de tracking
    mlflow_uri = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
    mlflow.set_tracking_uri(mlflow_uri)
    
    try:
        # Tenter de crÃ©er un experiment
        experiment_name = "test_integration"
        
        # Supprimer l'experiment s'il existe dÃ©jÃ 
        try:
            exp = mlflow.get_experiment_by_name(experiment_name)
            if exp:
                print(f"   â„¹ï¸  Experiment '{experiment_name}' existe dÃ©jÃ  (ID: {exp.experiment_id})")
        except:
            pass
        
        # CrÃ©er ou rÃ©cupÃ©rer l'experiment
        experiment_id = mlflow.create_experiment(experiment_name) if not mlflow.get_experiment_by_name(experiment_name) else mlflow.get_experiment_by_name(experiment_name).experiment_id
        
        print(f"   âœ… ConnectÃ© Ã  MLflow: {mlflow_uri}")
        print(f"   âœ… Experiment: {experiment_name} (ID: {experiment_id})")
        
        return True, experiment_name
    
    except Exception as e:
        print(f"   âŒ Erreur de connexion: {e}")
        print(f"\nğŸ’¡ Assurez-vous que MLflow est dÃ©marrÃ©:")
        print(f"   docker-compose up -d mlflow")
        print(f"   # ou")
        print(f"   mlflow server --host 0.0.0.0 --port 5000")
        return False, None


def train_test_model():
    """EntraÃ®ne un modÃ¨le de test et log dans MLflow."""
    print("\nğŸ¤– EntraÃ®nement d'un modÃ¨le de test...")
    
    # GÃ©nÃ©rer des donnÃ©es synthÃ©tiques
    X, y = make_classification(
        n_samples=1000,
        n_features=20,
        n_informative=15,
        n_redundant=5,
        random_state=42
    )
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"   ğŸ“Š Dataset: {len(X_train)} train, {len(X_test)} test")
    
    # EntraÃ®ner un modÃ¨le simple
    model = RandomForestClassifier(
        n_estimators=50,
        max_depth=5,
        random_state=42
    )
    
    start = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start
    
    # Ã‰valuer
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    print(f"   â±ï¸  Temps d'entraÃ®nement: {training_time:.2f}s")
    print(f"   ğŸ“ˆ Accuracy: {accuracy:.3f}")
    print(f"   ğŸ“ˆ F1-Score: {f1:.3f}")
    
    return model, {
        "accuracy": accuracy,
        "f1_score": f1,
        "training_time": training_time,
        "n_train": len(X_train),
        "n_test": len(X_test)
    }


def log_to_mlflow(experiment_name: str, model, metrics: dict):
    """Log le modÃ¨le et les mÃ©triques dans MLflow."""
    print("\nğŸ“ Logging dans MLflow...")
    
    mlflow.set_experiment(experiment_name)
    
    with mlflow.start_run(run_name=f"test_run_{int(time.time())}"):
        # Log des paramÃ¨tres
        mlflow.log_param("model_type", "RandomForest")
        mlflow.log_param("n_estimators", 50)
        mlflow.log_param("max_depth", 5)
        mlflow.log_param("test_mode", True)
        
        print(f"   âœ… ParamÃ¨tres loggÃ©s")
        
        # Log des mÃ©triques
        mlflow.log_metrics({
            "accuracy": metrics["accuracy"],
            "f1_score": metrics["f1_score"],
            "training_time": metrics["training_time"]
        })
        
        print(f"   âœ… MÃ©triques loggÃ©es")
        
        # Log du modÃ¨le
        mlflow.sklearn.log_model(
            model,
            "model",
            registered_model_name="TestModel"
        )
        
        print(f"   âœ… ModÃ¨le loggÃ©")
        
        # RÃ©cupÃ©rer l'ID du run
        run = mlflow.active_run()
        run_id = run.info.run_id
        
        print(f"\n   ğŸ¯ Run ID: {run_id}")
        
        return run_id


def verify_mlflow_data(experiment_name: str):
    """VÃ©rifie que les donnÃ©es sont bien dans MLflow."""
    print("\nğŸ” VÃ©rification des donnÃ©es MLflow...")
    
    try:
        # RÃ©cupÃ©rer l'experiment
        experiment = mlflow.get_experiment_by_name(experiment_name)
        
        if not experiment:
            print(f"   âŒ Experiment '{experiment_name}' non trouvÃ©")
            return False
        
        # RÃ©cupÃ©rer les runs
        runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])
        
        print(f"   âœ… Experiment ID: {experiment.experiment_id}")
        print(f"   âœ… Nombre de runs: {len(runs)}")
        
        if len(runs) > 0:
            latest_run = runs.iloc[0]
            print(f"\n   ğŸ“Š Dernier run:")
            print(f"      Run ID: {latest_run['run_id']}")
            print(f"      Accuracy: {latest_run['metrics.accuracy']:.3f}")
            print(f"      F1-Score: {latest_run['metrics.f1_score']:.3f}")
            print(f"      Status: {latest_run['status']}")
        
        return True
    
    except Exception as e:
        print(f"   âŒ Erreur lors de la vÃ©rification: {e}")
        return False


def main():
    """Point d'entrÃ©e principal."""
    print("\n" + "=" * 70)
    print("ğŸ§ª Test d'intÃ©gration MLflow")
    print("=" * 70)
    
    # 1. Tester la connexion
    connected, experiment_name = test_mlflow_connection()
    
    if not connected:
        sys.exit(1)
    
    # 2. EntraÃ®ner un modÃ¨le de test
    try:
        model, metrics = train_test_model()
    except Exception as e:
        print(f"\nâŒ Erreur lors de l'entraÃ®nement: {e}")
        sys.exit(1)
    
    # 3. Logger dans MLflow
    try:
        run_id = log_to_mlflow(experiment_name, model, metrics)
    except Exception as e:
        print(f"\nâŒ Erreur lors du logging MLflow: {e}")
        print(f"\nğŸ’¡ VÃ©rifiez que MLflow est accessible:")
        print(f"   curl http://localhost:5000/health")
        sys.exit(1)
    
    # 4. VÃ©rifier les donnÃ©es
    if verify_mlflow_data(experiment_name):
        print("\n" + "=" * 70)
        print("âœ… Test d'intÃ©gration MLflow rÃ©ussi!")
        print("=" * 70)
        print(f"\nğŸ’¡ Consultez MLflow UI: http://localhost:5000")
        print(f"ğŸ’¡ Experiment: {experiment_name}")
        print(f"ğŸ’¡ Run ID: {run_id}")
        
        return 0
    else:
        print("\nâŒ Ã‰chec de la vÃ©rification des donnÃ©es")
        return 1


if __name__ == "__main__":
    sys.exit(main())
