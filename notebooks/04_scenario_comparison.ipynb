{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4b9de4",
   "metadata": {},
   "source": [
    "# 04 - Comparaison des Mod√®les v1 vs v2 par Sc√©nario\n",
    "\n",
    "**Objectif**: Comparer les performances des mod√®les entra√Æn√©s sur v1 (best_move uniquement) vs v2 (multi-sc√©narios) sur diff√©rents types de combats.\n",
    "\n",
    "**Input**: \n",
    "- Mod√®les v1 et v2 dans `models/`\n",
    "- Datasets de test v2 avec sc√©narios dans `data/ml/battle_winner_v2/features/`\n",
    "\n",
    "**Output**: Analyse comparative et recommandations d'utilisation\n",
    "\n",
    "**Date**: 2026-01-24\n",
    "\n",
    "---\n",
    "\n",
    "## Table des Mati√®res\n",
    "\n",
    "1. [Chargement des Mod√®les et Donn√©es](#1-chargement-des-mod√®les-et-donn√©es)\n",
    "2. [√âvaluation par Sc√©nario](#2-√©valuation-par-sc√©nario)\n",
    "3. [Comparaison Globale](#3-comparaison-globale)\n",
    "4. [Analyse D√©taill√©e par Sc√©nario](#4-analyse-d√©taill√©e-par-sc√©nario)\n",
    "5. [Analyse des Erreurs](#5-analyse-des-erreurs)\n",
    "6. [Recommandations](#6-recommandations)\n",
    "7. [Conclusion](#7-conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb9260",
   "metadata": {},
   "source": [
    "## 1. Chargement des Mod√®les et Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17012a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Biblioth√®ques charg√©es\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Chemins\n",
    "BASE_DIR_V1 = Path('../data/ml/battle_winner')\n",
    "BASE_DIR_V2 = Path('../data/ml/battle_winner_v2')\n",
    "MODELS_DIR = Path('../models')\n",
    "\n",
    "print(\"üì¶ Biblioth√®ques charg√©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f37441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîç V√âRIFICATION DES MOD√àLES DISPONIBLES\n",
      "================================================================================\n",
      "‚ùå Mod√®le v1 non trouv√©: ../models/battle_winner_model_v1.pkl\n",
      "‚úÖ Mod√®le v2 trouv√©: ../models/battle_winner_model_v2.pkl\n",
      "\n",
      "‚úÖ Mod√®les charg√©s avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier l'existence des mod√®les\n",
    "print(\"=\" * 80)\n",
    "print(\"üîç V√âRIFICATION DES MOD√àLES DISPONIBLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model_v1_path = MODELS_DIR / 'battle_winner_model_v1.pkl'\n",
    "model_v2_path = MODELS_DIR / 'battle_winner_model_v2.pkl'\n",
    "\n",
    "if model_v1_path.exists():\n",
    "    print(f\"‚úÖ Mod√®le v1 trouv√©: {model_v1_path}\")\n",
    "    model_v1 = joblib.load(model_v1_path)\n",
    "    HAS_V1 = True\n",
    "else:\n",
    "    print(f\"‚ùå Mod√®le v1 non trouv√©: {model_v1_path}\")\n",
    "    model_v1 = None\n",
    "    HAS_V1 = False\n",
    "\n",
    "if model_v2_path.exists():\n",
    "    print(f\"‚úÖ Mod√®le v2 trouv√©: {model_v2_path}\")\n",
    "    model_v2 = joblib.load(model_v2_path)\n",
    "    HAS_V2 = True\n",
    "else:\n",
    "    print(f\"‚ùå Mod√®le v2 non trouv√©: {model_v2_path}\")\n",
    "    model_v2 = None\n",
    "    HAS_V2 = False\n",
    "\n",
    "if not HAS_V1 and not HAS_V2:\n",
    "    print(\"\\n‚ö†Ô∏è Aucun mod√®le trouv√©. Veuillez d'abord entra√Æner les mod√®les avec notebook 03.\")\n",
    "elif not HAS_V2:\n",
    "    print(\"\\n‚ö†Ô∏è Mod√®le v2 non trouv√©. Ce notebook n√©cessite les deux mod√®les pour la comparaison.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Mod√®les charg√©s avec succ√®s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e90494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìÇ CHARGEMENT DES DONN√âES DE TEST V2\n",
      "================================================================================\n",
      "‚úÖ Donn√©es de test v2 charg√©es: (179695, 133)\n",
      "‚úÖ Sc√©narios d√©tect√©s\n",
      "\n",
      "üìä Distribution des sc√©narios:\n",
      "scenario_type\n",
      "all_combinations    137956\n",
      "random_move          34782\n",
      "best_move             6957\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Charger les donn√©es de test v2 (avec sc√©narios)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìÇ CHARGEMENT DES DONN√âES DE TEST V2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "FEATURES_DIR_V2 = BASE_DIR_V2 / 'features'\n",
    "\n",
    "if FEATURES_DIR_V2.exists():\n",
    "    X_test_v2 = pd.read_parquet(FEATURES_DIR_V2 / 'X_test.parquet')\n",
    "    y_test_v2 = pd.read_parquet(FEATURES_DIR_V2 / 'y_test.parquet')['winner']\n",
    "    \n",
    "    # V√©rifier si scenario_type existe\n",
    "    if 'scenario_type' in X_test_v2.columns:\n",
    "        scenario_test = X_test_v2['scenario_type'].copy()\n",
    "        X_test_v2_ml = X_test_v2.drop(columns=['scenario_type'])\n",
    "        HAS_SCENARIOS = True\n",
    "        print(f\"‚úÖ Donn√©es de test v2 charg√©es: {X_test_v2_ml.shape}\")\n",
    "        print(f\"‚úÖ Sc√©narios d√©tect√©s\")\n",
    "        print(f\"\\nüìä Distribution des sc√©narios:\")\n",
    "        print(scenario_test.value_counts())\n",
    "    else:\n",
    "        X_test_v2_ml = X_test_v2\n",
    "        scenario_test = None\n",
    "        HAS_SCENARIOS = False\n",
    "        print(f\"‚ö†Ô∏è Pas de colonne scenario_type dans les donn√©es v2\")\n",
    "else:\n",
    "    print(f\"‚ùå R√©pertoire des features v2 non trouv√©: {FEATURES_DIR_V2}\")\n",
    "    X_test_v2_ml = None\n",
    "    y_test_v2 = None\n",
    "    scenario_test = None\n",
    "    HAS_SCENARIOS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd730e",
   "metadata": {},
   "source": [
    "## 2. √âvaluation par Sc√©nario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde70594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Impossible d'effectuer la comparaison - mod√®les ou donn√©es manquants\n"
     ]
    }
   ],
   "source": [
    "if HAS_V1 and HAS_V2 and HAS_SCENARIOS:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üéØ √âVALUATION DES MOD√àLES PAR SC√âNARIO\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Pr√©dictions des deux mod√®les\n",
    "    y_pred_v1 = model_v1.predict(X_test_v2_ml)\n",
    "    y_pred_v2 = model_v2.predict(X_test_v2_ml)\n",
    "    \n",
    "    y_proba_v1 = model_v1.predict_proba(X_test_v2_ml)[:, 1] if hasattr(model_v1, 'predict_proba') else None\n",
    "    y_proba_v2 = model_v2.predict_proba(X_test_v2_ml)[:, 1] if hasattr(model_v2, 'predict_proba') else None\n",
    "    \n",
    "    # Analyser par sc√©nario\n",
    "    scenarios = scenario_test.unique()\n",
    "    comparison_results = []\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        mask = scenario_test == scenario\n",
    "        y_true = y_test_v2[mask]\n",
    "        y_pred_v1_scenario = y_pred_v1[mask]\n",
    "        y_pred_v2_scenario = y_pred_v2[mask]\n",
    "        \n",
    "        # M√©triques v1\n",
    "        acc_v1 = accuracy_score(y_true, y_pred_v1_scenario)\n",
    "        prec_v1 = precision_score(y_true, y_pred_v1_scenario)\n",
    "        rec_v1 = recall_score(y_true, y_pred_v1_scenario)\n",
    "        f1_v1 = f1_score(y_true, y_pred_v1_scenario)\n",
    "        \n",
    "        # M√©triques v2\n",
    "        acc_v2 = accuracy_score(y_true, y_pred_v2_scenario)\n",
    "        prec_v2 = precision_score(y_true, y_pred_v2_scenario)\n",
    "        rec_v2 = recall_score(y_true, y_pred_v2_scenario)\n",
    "        f1_v2 = f1_score(y_true, y_pred_v2_scenario)\n",
    "        \n",
    "        # ROC-AUC si disponible\n",
    "        roc_v1 = roc_auc_score(y_true, y_proba_v1[mask]) if y_proba_v1 is not None else None\n",
    "        roc_v2 = roc_auc_score(y_true, y_proba_v2[mask]) if y_proba_v2 is not None else None\n",
    "        \n",
    "        comparison_results.append({\n",
    "            'Sc√©nario': scenario,\n",
    "            '√âchantillons': len(y_true),\n",
    "            'Acc v1': acc_v1,\n",
    "            'Acc v2': acc_v2,\n",
    "            'Œî Acc': acc_v2 - acc_v1,\n",
    "            'Œî Acc %': (acc_v2 - acc_v1) / acc_v1 * 100,\n",
    "            'F1 v1': f1_v1,\n",
    "            'F1 v2': f1_v2,\n",
    "            'Œî F1': f1_v2 - f1_v1,\n",
    "            'ROC-AUC v1': roc_v1,\n",
    "            'ROC-AUC v2': roc_v2\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nüìä Sc√©nario: {scenario}\")\n",
    "        print(f\"   √âchantillons: {len(y_true):,}\")\n",
    "        print(f\"   Accuracy v1: {acc_v1:.4f} | v2: {acc_v2:.4f} | Œî: {acc_v2-acc_v1:+.4f} ({(acc_v2-acc_v1)/acc_v1*100:+.2f}%)\")\n",
    "        print(f\"   F1-Score v1: {f1_v1:.4f} | v2: {f1_v2:.4f} | Œî: {f1_v2-f1_v1:+.4f}\")\n",
    "        if roc_v1 and roc_v2:\n",
    "            print(f\"   ROC-AUC  v1: {roc_v1:.4f} | v2: {roc_v2:.4f} | Œî: {roc_v2-roc_v1:+.4f}\")\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Impossible d'effectuer la comparaison - mod√®les ou donn√©es manquants\")\n",
    "    comparison_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f82b3",
   "metadata": {},
   "source": [
    "## 3. Comparaison Globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e75f568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if comparison_df is not None:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä TABLEAU R√âCAPITULATIF\")\n",
    "    print(\"=\" * 80)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Statistiques globales\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìà STATISTIQUES GLOBALES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nüéØ Am√©lioration moyenne de l'accuracy: {comparison_df['Œî Acc'].mean():+.4f} ({comparison_df['Œî Acc %'].mean():+.2f}%)\")\n",
    "    print(f\"üéØ Am√©lioration moyenne du F1-Score: {comparison_df['Œî F1'].mean():+.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Meilleure am√©lioration: {comparison_df.loc[comparison_df['Œî Acc'].idxmax(), 'Sc√©nario']}\")\n",
    "    print(f\"   Œî Accuracy: {comparison_df['Œî Acc'].max():+.4f} ({comparison_df['Œî Acc %'].max():+.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nüìä Pire am√©lioration: {comparison_df.loc[comparison_df['Œî Acc'].idxmin(), 'Sc√©nario']}\")\n",
    "    print(f\"   Œî Accuracy: {comparison_df['Œî Acc'].min():+.4f} ({comparison_df['Œî Acc %'].min():+.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a370f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if comparison_df is not None:\n",
    "    # Visualisation de la comparaison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Accuracy par sc√©nario\n",
    "    x_pos = np.arange(len(comparison_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[0, 0].bar(x_pos - width/2, comparison_df['Acc v1'], width, label='v1 (best_move)', color='#3498db', alpha=0.8)\n",
    "    axes[0, 0].bar(x_pos + width/2, comparison_df['Acc v2'], width, label='v2 (multi-sc√©narios)', color='#e74c3c', alpha=0.8)\n",
    "    axes[0, 0].set_xlabel('Sc√©nario', fontsize=11)\n",
    "    axes[0, 0].set_ylabel('Accuracy', fontsize=11)\n",
    "    axes[0, 0].set_title('Accuracy par Sc√©nario: v1 vs v2', fontsize=13, fontweight='bold')\n",
    "    axes[0, 0].set_xticks(x_pos)\n",
    "    axes[0, 0].set_xticklabels(comparison_df['Sc√©nario'], rotation=45, ha='right')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "    axes[0, 0].set_ylim([0.85, 1.0])\n",
    "    \n",
    "    # 2. Am√©lioration de l'accuracy\n",
    "    colors = ['#2ecc71' if x > 0 else '#e74c3c' for x in comparison_df['Œî Acc']]\n",
    "    axes[0, 1].barh(comparison_df['Sc√©nario'], comparison_df['Œî Acc'], color=colors, alpha=0.8)\n",
    "    axes[0, 1].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[0, 1].set_xlabel('Œî Accuracy (v2 - v1)', fontsize=11)\n",
    "    axes[0, 1].set_title('Am√©lioration de l\\'Accuracy par Sc√©nario', fontsize=13, fontweight='bold')\n",
    "    axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 3. F1-Score par sc√©nario\n",
    "    axes[1, 0].bar(x_pos - width/2, comparison_df['F1 v1'], width, label='v1', color='#3498db', alpha=0.8)\n",
    "    axes[1, 0].bar(x_pos + width/2, comparison_df['F1 v2'], width, label='v2', color='#e74c3c', alpha=0.8)\n",
    "    axes[1, 0].set_xlabel('Sc√©nario', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('F1-Score', fontsize=11)\n",
    "    axes[1, 0].set_title('F1-Score par Sc√©nario: v1 vs v2', fontsize=13, fontweight='bold')\n",
    "    axes[1, 0].set_xticks(x_pos)\n",
    "    axes[1, 0].set_xticklabels(comparison_df['Sc√©nario'], rotation=45, ha='right')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "    axes[1, 0].set_ylim([0.85, 1.0])\n",
    "    \n",
    "    # 4. Am√©lioration en pourcentage\n",
    "    axes[1, 1].bar(comparison_df['Sc√©nario'], comparison_df['Œî Acc %'], \n",
    "                   color=['#2ecc71' if x > 0 else '#e74c3c' for x in comparison_df['Œî Acc %']], alpha=0.8)\n",
    "    axes[1, 1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[1, 1].set_xlabel('Sc√©nario', fontsize=11)\n",
    "    axes[1, 1].set_ylabel('Am√©lioration (%)', fontsize=11)\n",
    "    axes[1, 1].set_title('Am√©lioration Relative de l\\'Accuracy (%)', fontsize=13, fontweight='bold')\n",
    "    axes[1, 1].set_xticklabels(comparison_df['Sc√©nario'], rotation=45, ha='right')\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb8977",
   "metadata": {},
   "source": [
    "## 4. Analyse D√©taill√©e par Sc√©nario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b399ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_V1 and HAS_V2 and HAS_SCENARIOS:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üîç ANALYSE D√âTAILL√âE PAR SC√âNARIO\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üìä Sc√©nario: {scenario}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        mask = scenario_test == scenario\n",
    "        y_true = y_test_v2[mask]\n",
    "        y_pred_v1_scenario = y_pred_v1[mask]\n",
    "        y_pred_v2_scenario = y_pred_v2[mask]\n",
    "        \n",
    "        # Classification reports\n",
    "        print(f\"\\nüìÑ Classification Report - Mod√®le v1:\")\n",
    "        print(classification_report(y_true, y_pred_v1_scenario, \n",
    "                                    target_names=['Pok√©mon A gagne', 'Pok√©mon B gagne']))\n",
    "        \n",
    "        print(f\"\\nüìÑ Classification Report - Mod√®le v2:\")\n",
    "        print(classification_report(y_true, y_pred_v2_scenario, \n",
    "                                    target_names=['Pok√©mon A gagne', 'Pok√©mon B gagne']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7cd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_V1 and HAS_V2 and HAS_SCENARIOS and len(scenarios) <= 3:\n",
    "    # Matrices de confusion c√¥te √† c√¥te pour chaque sc√©nario\n",
    "    for scenario in scenarios:\n",
    "        mask = scenario_test == scenario\n",
    "        y_true = y_test_v2[mask]\n",
    "        y_pred_v1_scenario = y_pred_v1[mask]\n",
    "        y_pred_v2_scenario = y_pred_v2[mask]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # v1\n",
    "        ConfusionMatrixDisplay.from_predictions(\n",
    "            y_true, y_pred_v1_scenario,\n",
    "            display_labels=['A gagne', 'B gagne'],\n",
    "            cmap='Blues', ax=axes[0]\n",
    "        )\n",
    "        axes[0].set_title(f'Mod√®le v1\\n{scenario}', fontsize=13, fontweight='bold')\n",
    "        \n",
    "        # v2\n",
    "        ConfusionMatrixDisplay.from_predictions(\n",
    "            y_true, y_pred_v2_scenario,\n",
    "            display_labels=['A gagne', 'B gagne'],\n",
    "            cmap='Reds', ax=axes[1]\n",
    "        )\n",
    "        axes[1].set_title(f'Mod√®le v2\\n{scenario}', fontsize=13, fontweight='bold')\n",
    "        \n",
    "        plt.suptitle(f'Matrices de Confusion: {scenario}', fontsize=15, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02987e3a",
   "metadata": {},
   "source": [
    "## 5. Analyse des Erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94dfcdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_V1 and HAS_V2 and HAS_SCENARIOS:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üîç ANALYSE DES ERREURS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Analyser les cas o√π v1 se trompe mais v2 est correct, et vice-versa\n",
    "    v1_correct = (y_pred_v1 == y_test_v2)\n",
    "    v2_correct = (y_pred_v2 == y_test_v2)\n",
    "    \n",
    "    # Cas o√π v2 am√©liore (v1 faux, v2 correct)\n",
    "    v2_fixes = (~v1_correct) & v2_correct\n",
    "    print(f\"\\n‚úÖ Cas o√π v2 corrige les erreurs de v1: {v2_fixes.sum():,} ({v2_fixes.sum()/len(y_test_v2)*100:.2f}%)\")\n",
    "    \n",
    "    # Cas o√π v2 r√©gresse (v1 correct, v2 faux)\n",
    "    v2_breaks = v1_correct & (~v2_correct)\n",
    "    print(f\"‚ùå Cas o√π v2 r√©gresse par rapport √† v1: {v2_breaks.sum():,} ({v2_breaks.sum()/len(y_test_v2)*100:.2f}%)\")\n",
    "    \n",
    "    # Les deux se trompent\n",
    "    both_wrong = (~v1_correct) & (~v2_correct)\n",
    "    print(f\"‚ö†Ô∏è Cas o√π les deux mod√®les se trompent: {both_wrong.sum():,} ({both_wrong.sum()/len(y_test_v2)*100:.2f}%)\")\n",
    "    \n",
    "    # Les deux sont corrects\n",
    "    both_correct = v1_correct & v2_correct\n",
    "    print(f\"‚úÖ Cas o√π les deux mod√®les sont corrects: {both_correct.sum():,} ({both_correct.sum()/len(y_test_v2)*100:.2f}%)\")\n",
    "    \n",
    "    # Analyse par sc√©nario\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üìä ANALYSE PAR SC√âNARIO\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        mask = scenario_test == scenario\n",
    "        print(f\"\\nüìä {scenario}:\")\n",
    "        print(f\"   v2 corrige v1: {v2_fixes[mask].sum():,} √©chantillons\")\n",
    "        print(f\"   v2 r√©gresse:   {v2_breaks[mask].sum():,} √©chantillons\")\n",
    "        print(f\"   Balance nette: {v2_fixes[mask].sum() - v2_breaks[mask].sum():+,} √©chantillons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a186a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_V1 and HAS_V2 and HAS_SCENARIOS:\n",
    "    # Visualisation de l'analyse des erreurs\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 1. Distribution globale des corrections/r√©gressions\n",
    "    categories = ['v2 corrige v1', 'v2 r√©gresse', 'Les deux OK', 'Les deux KO']\n",
    "    counts = [v2_fixes.sum(), v2_breaks.sum(), both_correct.sum(), both_wrong.sum()]\n",
    "    colors_cat = ['#2ecc71', '#e74c3c', '#3498db', '#f39c12']\n",
    "    \n",
    "    axes[0].pie(counts, labels=categories, autopct='%1.1f%%', colors=colors_cat, startangle=90)\n",
    "    axes[0].set_title('Distribution des Pr√©dictions\\n(v1 vs v2)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 2. Balance nette par sc√©nario\n",
    "    net_improvements = []\n",
    "    for scenario in scenarios:\n",
    "        mask = scenario_test == scenario\n",
    "        net = v2_fixes[mask].sum() - v2_breaks[mask].sum()\n",
    "        net_improvements.append(net)\n",
    "    \n",
    "    colors_net = ['#2ecc71' if x > 0 else '#e74c3c' for x in net_improvements]\n",
    "    axes[1].bar(scenarios, net_improvements, color=colors_net, alpha=0.8)\n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[1].set_xlabel('Sc√©nario', fontsize=12)\n",
    "    axes[1].set_ylabel('Balance Nette\\n(corrections - r√©gressions)', fontsize=12)\n",
    "    axes[1].set_title('Impact Net du Mod√®le v2 par Sc√©nario', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xticklabels(scenarios, rotation=45, ha='right')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec7638",
   "metadata": {},
   "source": [
    "## 6. Recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cad2980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if comparison_df is not None:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üí° RECOMMANDATIONS D'UTILISATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Analyser les r√©sultats pour donner des recommandations\n",
    "    avg_improvement = comparison_df['Œî Acc %'].mean()\n",
    "    min_improvement = comparison_df['Œî Acc %'].min()\n",
    "    max_improvement = comparison_df['Œî Acc %'].max()\n",
    "    \n",
    "    print(f\"\\nüìä Am√©lioration moyenne: {avg_improvement:+.2f}%\")\n",
    "    print(f\"üìä Plage d'am√©lioration: {min_improvement:+.2f}% √† {max_improvement:+.2f}%\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üéØ RECOMMANDATIONS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if avg_improvement > 1:\n",
    "        print(f\"\\n‚úÖ Le mod√®le v2 apporte une am√©lioration significative ({avg_improvement:+.2f}% en moyenne)\")\n",
    "        print(f\"   ‚û°Ô∏è RECOMMANDATION: Utiliser le mod√®le v2 en production\")\n",
    "    elif avg_improvement > 0:\n",
    "        print(f\"\\n‚úÖ Le mod√®le v2 apporte une l√©g√®re am√©lioration ({avg_improvement:+.2f}% en moyenne)\")\n",
    "        print(f\"   ‚û°Ô∏è RECOMMANDATION: Utiliser le mod√®le v2 pour plus de robustesse\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Le mod√®le v2 n'apporte pas d'am√©lioration ({avg_improvement:+.2f}% en moyenne)\")\n",
    "        print(f\"   ‚û°Ô∏è RECOMMANDATION: Conserver le mod√®le v1 ou revoir la strat√©gie v2\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üìù D√âTAILS PAR SC√âNARIO\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for _, row in comparison_df.iterrows():\n",
    "        scenario = row['Sc√©nario']\n",
    "        delta_pct = row['Œî Acc %']\n",
    "        \n",
    "        if delta_pct > 1:\n",
    "            emoji = \"‚úÖ\"\n",
    "            message = \"Am√©lioration significative\"\n",
    "        elif delta_pct > 0:\n",
    "            emoji = \"‚ûï\"\n",
    "            message = \"L√©g√®re am√©lioration\"\n",
    "        elif delta_pct > -1:\n",
    "            emoji = \"‚ûñ\"\n",
    "            message = \"L√©g√®re r√©gression\"\n",
    "        else:\n",
    "            emoji = \"‚ùå\"\n",
    "            message = \"R√©gression significative\"\n",
    "        \n",
    "        print(f\"\\n{emoji} {scenario}:\")\n",
    "        print(f\"   {message}: {delta_pct:+.2f}%\")\n",
    "        print(f\"   Accuracy: {row['Acc v1']:.4f} ‚Üí {row['Acc v2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üéØ CONTEXTE D'UTILISATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nüìå Mod√®le v1 (best_move uniquement):\")\n",
    "    print(f\"   ‚úì Plus simple et rapide\")\n",
    "    print(f\"   ‚úì Optimis√© pour le sc√©nario 'best_move'\")\n",
    "    print(f\"   ‚úó Peut sous-performer sur d'autres sc√©narios\")\n",
    "    \n",
    "    print(f\"\\nüìå Mod√®le v2 (multi-sc√©narios):\")\n",
    "    print(f\"   ‚úì Plus robuste sur diff√©rents types de combats\")\n",
    "    print(f\"   ‚úì Meilleure g√©n√©ralisation\")\n",
    "    print(f\"   ‚úó Entra√Ænement plus long (880k √©chantillons)\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üöÄ INT√âGRATION API\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nüí° Avec le param√®tre available_moves_b de l'API:\")\n",
    "    print(f\"   ‚Ä¢ Si available_moves_b est fourni ‚Üí Sc√©nario contraint\")\n",
    "    print(f\"   ‚Ä¢ Si available_moves_b est None ‚Üí Sc√©nario best_move\")\n",
    "    print(f\"   ‚Ä¢ Le mod√®le v2 est recommand√© pour g√©rer les deux cas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec4dfec",
   "metadata": {},
   "source": [
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862e35b",
   "metadata": {},
   "source": [
    "### Synth√®se de la Comparaison\n",
    "\n",
    "#### üéØ Objectifs\n",
    "\n",
    "Ce notebook a compar√© les performances de deux approches de mod√©lisation :\n",
    "- **Mod√®le v1** : Entra√Æn√© uniquement sur le sc√©nario `best_move` (~34k √©chantillons)\n",
    "- **Mod√®le v2** : Entra√Æn√© sur 3 sc√©narios (`best_move`, `random_move`, `all_combinations`) (~880k √©chantillons)\n",
    "\n",
    "#### üìä R√©sultats Cl√©s\n",
    "\n",
    "Consultez les tableaux et graphiques ci-dessus pour :\n",
    "- L'am√©lioration de l'accuracy par sc√©nario\n",
    "- L'analyse des corrections et r√©gressions\n",
    "- Les matrices de confusion d√©taill√©es\n",
    "\n",
    "#### üí° D√©cision Finale\n",
    "\n",
    "La d√©cision d'utiliser v1 ou v2 d√©pend de :\n",
    "1. **Performance globale** : Si v2 am√©liore significativement la pr√©cision\n",
    "2. **Robustesse** : Capacit√© √† g√©rer diff√©rents types de combats\n",
    "3. **Co√ªt** : Temps d'entra√Ænement et ressources n√©cessaires\n",
    "4. **Usage API** : Besoin de g√©rer le param√®tre `available_moves_b`\n",
    "\n",
    "#### üöÄ Prochaines √âtapes\n",
    "\n",
    "1. **D√©ploiement** : Int√©grer le mod√®le choisi dans l'API\n",
    "2. **Monitoring** : Suivre les performances en production\n",
    "3. **A/B Testing** : Tester les deux mod√®les en parall√®le si n√©cessaire\n",
    "4. **Am√©lioration continue** : Collecter du feedback et r√©-entra√Æner\n",
    "\n",
    "---\n",
    "\n",
    "**‚úÖ Analyse comparative termin√©e!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
