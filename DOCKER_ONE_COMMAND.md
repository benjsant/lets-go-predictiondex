# Guide de DÃ©ploiement - One Command

**Date**: 25 janvier 2026  
**Projet**: Let's Go PredictionDex  
**Objectif**: DÃ©ployer TOUT avec une seule commande

---

## ğŸš€ DÃ©ploiement en une commande

### Commande unique (RECOMMANDÃ‰)

```bash
docker compose up --build
```

**Cette commande lance automatiquement** :

1. âœ… **PostgreSQL** (db) - Base de donnÃ©es
2. âœ… **ETL** (etl) - Import des donnÃ©es Pokemon
3. âœ… **ML Builder** (ml_builder) - EntraÃ®nement du modÃ¨le
4. âœ… **API** (api) - FastAPI backend
5. âœ… **Streamlit** (streamlit) - Interface utilisateur
6. âœ… **MLflow** (mlflow) - Tracking ML
7. âœ… **Prometheus** (prometheus) - MÃ©triques
8. âœ… **Grafana** (grafana) - Dashboards
9. âœ… **Node Exporter** (node-exporter) - MÃ©triques systÃ¨me

**DurÃ©e totale** : ~5-10 minutes (selon ressources)

---

## âš™ï¸ Configuration automatique

### Ordre d'exÃ©cution STRICT âœ…

Le docker-compose.yml impose un ordre sÃ©quentiel **avec arrÃªt complet en cas d'Ã©chec** :

```
1. ğŸ—„ï¸  BDD (db)
   â†“ healthcheck: pg_isready
   â””â”€ âœ… HEALTHY ou âŒ ARRÃŠT TOTAL

2. ğŸ“¥ ETL + ğŸ“Š MLFLOW (parallÃ¨le)
   â”œâ”€ etl
   â”‚  â†“ depends_on: db (healthy)
   â”‚  â†“ restart: "no"
   â”‚  â””â”€ âœ… EXIT 0 ou âŒ ARRÃŠT TOTAL
   â””â”€ mlflow (optionnel pour dÃ©ploiement)
      â†“ depends_on: db (healthy)
      â†“ healthcheck: /health
      â””â”€ âœ… HEALTHY

3. ğŸ¤– ML BUILDER (ml_builder)
   â†“ depends_on: etl (completed)
   â†“ restart: "no"
   â†“ DISABLE_MLFLOW_TRACKING=true (simplifie le dÃ©ploiement)
   â””â”€ âœ… EXIT 0 ou âŒ ARRÃŠT TOTAL

4. ğŸš€ API (api)
   â†“ depends_on: db (healthy) + etl + ml_builder (completed)
   â†“ healthcheck: /health
   â””â”€ âœ… HEALTHY ou âŒ ARRÃŠT TOTAL

5. ğŸ¨ STREAMLIT (streamlit)
   â†“ depends_on: api (healthy)
   â””â”€ âœ… RUNNING

6. ğŸ“Š MONITORING
   â”œâ”€ prometheus (parallÃ¨le avec API)
   â”œâ”€ node-exporter (parallÃ¨le avec API)
   â””â”€ grafana
      â†“ depends_on: prometheus + api (healthy)
      â””â”€ âœ… RUNNING
```

**âš ï¸ IMPORTANT** : Si **un seul service Ã©choue**, Docker Compose arrÃªte **toute la chaÃ®ne**. Par exemple :
- Si ETL Ã©choue â†’ ML, API, Streamlit ne dÃ©marrent JAMAIS
- Si ML Ã©choue â†’ API, Streamlit ne dÃ©marrent JAMAIS  
- Si API Ã©choue â†’ Streamlit ne dÃ©marre JAMAIS

### Variables d'environnement (fichier `.env`)

CrÃ©er un fichier `.env` Ã  la racine si nÃ©cessaire :

```env
# Database
POSTGRES_HOST=db
POSTGRES_PORT=5432
POSTGRES_DB=letsgo_db
POSTGRES_USER=letsgo_user
POSTGRES_PASSWORD=letsgo_password

# Dev mode
DEV_MODE=true

# ML Configuration (optionnel - valeurs par dÃ©faut dans docker-compose.yml)
ML_MODE=all
ML_SCENARIO_TYPE=all
ML_TUNE_HYPERPARAMS=true
ML_GRID_TYPE=fast
ML_NUM_RANDOM_SAMPLES=5
ML_MAX_COMBINATIONS=20
```

**Note** : Si le fichier `.env` n'existe pas, les valeurs par dÃ©faut du docker-compose.yml sont utilisÃ©es.

---

## ğŸ“Š Pipeline d'exÃ©cution automatique

### 1. Phase Database (30s)
```
db â†’ PostgreSQL dÃ©marre
  â†“
healthcheck: pg_isready
  â†“
âœ… db ready
```

### 2. Phase ETL (2-3 min)
```
etl â†’ Attend db healthy
  â†“
etl_entrypoint.py
  â†“
etl_pokemon/pipeline.py
  â†“
Import ~200 Pokemon + moves + types
  â†“
âœ… etl completed successfully
```

### 3. Phase ML (3-5 min)
```
ml_builder â†’ Attend etl completed
  â†“
ml_entrypoint.py
  â†“
machine_learning/run_machine_learning.py
  â†“
Dataset generation (multi-scenarios)
  â†“
Feature engineering
  â†“
Model training (XGBoost + GridSearch)
  â†“
Export models to ./models/
  â†“
âœ… ml_builder completed
```

### 4. Phase Services (30s)
```
api â†’ Attend db + etl
  â†“
api_entrypoint.py
  â†“
FastAPI server (port 8000)
  â†“
healthcheck: /health
  â†“
âœ… api healthy

streamlit â†’ Attend api healthy
  â†“
Streamlit server (port 8501)
  â†“
âœ… streamlit ready

mlflow â†’ Attend db healthy
  â†“
MLflow server (port 5000)
  â†“
healthcheck: /health
  â†“
âœ… mlflow healthy
```

### 5. Phase Monitoring (30s)
```
prometheus â†’ DÃ©marre immÃ©diatement
  â†“
Scraping mÃ©triques (port 9090)
  â†“
âœ… prometheus ready

grafana â†’ Attend prometheus
  â†“
Dashboards provisionnÃ©s (port 3000)
  â†“
âœ… grafana ready

node-exporter â†’ DÃ©marre immÃ©diatement
  â†“
MÃ©triques systÃ¨me (port 9100)
  â†“
âœ… node-exporter ready
```

---

## ğŸ¯ Services disponibles aprÃ¨s dÃ©ploiement

| Service | URL | Description |
|---------|-----|-------------|
| **API** | http://localhost:8000 | Backend FastAPI |
| **Swagger** | http://localhost:8000/docs | Documentation API |
| **Streamlit** | http://localhost:8501 | Interface utilisateur |
| **MLflow** | http://localhost:5000 | Tracking ML |
| **Grafana** | http://localhost:3000 | Dashboards monitoring |
| **Prometheus** | http://localhost:9090 | MÃ©triques |
| **Node Exporter** | http://localhost:9100/metrics | MÃ©triques systÃ¨me |

**Credentials Grafana** (si nÃ©cessaire) :
- Username: `admin`
- Password: `admin`

---

## ğŸ” VÃ©rification du dÃ©ploiement

### VÃ©rifier l'Ã©tat des services

```bash
# Status de tous les services
docker compose ps

# Logs de tous les services
docker compose logs

# Logs d'un service spÃ©cifique
docker compose logs api
docker compose logs etl
docker compose logs ml_builder
```

### Health checks automatiques

```bash
# API
curl http://localhost:8000/health
# RÃ©ponse: {"status": "healthy", ...}

# MLflow
curl http://localhost:5000/health
# RÃ©ponse: OK

# Prometheus
curl http://localhost:9090/-/healthy
# RÃ©ponse: Prometheus is Healthy
```

### VÃ©rifier les modÃ¨les ML

```bash
# Lister les modÃ¨les exportÃ©s
ls -lh models/

# Devrait contenir:
# battle_winner_model_v2.pkl
# battle_winner_metadata_v2.json
# battle_winner_scalers_v2.pkl
```

---

## ğŸ› ï¸ Commandes utiles

### DÃ©marrage

```bash
# DÃ©marrage complet (build + start)
docker compose up --build

# DÃ©marrage sans rebuild
docker compose up

# DÃ©marrage en arriÃ¨re-plan
docker compose up -d

# DÃ©marrage d'un service spÃ©cifique
docker compose up api
```

### ArrÃªt

```bash
# ArrÃªt de tous les services
docker compose down

# ArrÃªt + suppression des volumes (âš ï¸ perte de donnÃ©es)
docker compose down -v

# ArrÃªt d'un service spÃ©cifique
docker compose stop api
```

### Rebuild

```bash
# Rebuild tous les services
docker compose build

# Rebuild un service spÃ©cifique
docker compose build api

# Rebuild avec no-cache
docker compose build --no-cache
```

### Logs

```bash
# Logs en temps rÃ©el
docker compose logs -f

# Logs d'un service
docker compose logs -f api

# 100 derniÃ¨res lignes
docker compose logs --tail=100

# Logs depuis 10 minutes
docker compose logs --since 10m
```

### Maintenance

```bash
# RedÃ©marrer un service
docker compose restart api

# ExÃ©cuter une commande dans un conteneur
docker compose exec api bash
docker compose exec db psql -U letsgo_user -d letsgo_db

# Voir l'utilisation des ressources
docker stats
```

---

## ğŸ› Troubleshooting

### ProblÃ¨me : ETL Ã©choue

**SymptÃ´me** :
```
letsgo_etl exited with code 1
```

**Solution** :
```bash
# VÃ©rifier les logs ETL
docker compose logs etl

# RedÃ©marrer ETL
docker compose up etl

# Si nÃ©cessaire, rebuild
docker compose build etl
docker compose up etl
```

### ProblÃ¨me : ML Builder Ã©choue

**SymptÃ´me** :
```
letsgo_ml exited with code 1
```

**Solution** :
```bash
# VÃ©rifier les logs ML
docker compose logs ml_builder

# DÃ©sactiver GridSearch pour accÃ©lÃ©rer
# Ã‰diter docker-compose.yml:
# ML_TUNE_HYPERPARAMS: "false"

# Rebuild et restart
docker compose build ml_builder
docker compose up ml_builder
```

### ProblÃ¨me : API ne dÃ©marre pas

**SymptÃ´me** :
```
api unhealthy
```

**Solution** :
```bash
# VÃ©rifier les logs
docker compose logs api

# VÃ©rifier que ETL est complÃ©tÃ©
docker compose ps

# RedÃ©marrer
docker compose restart api
```

### ProblÃ¨me : Port dÃ©jÃ  utilisÃ©

**SymptÃ´me** :
```
Error: bind: address already in use
```

**Solution** :
```bash
# Identifier le processus utilisant le port
sudo lsof -i :8000
sudo lsof -i :5000

# Tuer le processus
kill -9 <PID>

# Ou changer le port dans docker-compose.yml
# ports:
#   - "8001:8000"
```

### ProblÃ¨me : Manque de mÃ©moire

**SymptÃ´me** :
```
ml_builder killed (OOMKilled)
```

**Solution** :
```bash
# Augmenter la mÃ©moire Docker (Docker Desktop)
# Settings > Resources > Memory: 8GB minimum

# Ou dÃ©sactiver GridSearch
# ML_TUNE_HYPERPARAMS: "false"
```

---

## ğŸ“¦ Volumes persistants

Les donnÃ©es suivantes sont persistÃ©es dans des volumes Docker :

| Volume | Contenu | Taille typique |
|--------|---------|----------------|
| `postgres_data` | Base de donnÃ©es | ~50 MB |
| `prometheus_data` | MÃ©triques Prometheus | ~100 MB |
| `grafana_data` | Config Grafana | ~10 MB |
| `mlflow_data` | Artefacts MLflow | ~200 MB |

**Backup des volumes** :

```bash
# Backup PostgreSQL
docker compose exec db pg_dump -U letsgo_user letsgo_db > backup.sql

# Restore
docker compose exec -T db psql -U letsgo_user letsgo_db < backup.sql
```

**Nettoyer les volumes** :

```bash
# âš ï¸ ATTENTION : Supprime toutes les donnÃ©es
docker compose down -v

# Nettoyer les volumes orphelins
docker volume prune
```

---

## ğŸš€ Mode dÃ©veloppement

### DÃ©veloppement avec hot-reload

Les volumes sont montÃ©s pour permettre le hot-reload :

```yaml
api:
  volumes:
    - ./api_pokemon:/app/api_pokemon  # Hot-reload API
    - ./core:/app/core                 # Hot-reload models

streamlit:
  volumes:
    - ./interface:/app/interface       # Hot-reload Streamlit
```

**Modifications en temps rÃ©el** :
1. Ã‰diter `api_pokemon/routes/prediction_route.py`
2. FastAPI recharge automatiquement
3. Tester : `curl http://localhost:8000/docs`

### DÃ©veloppement sans Docker

```bash
# 1. DÃ©marrer uniquement la DB
docker compose up db -d

# 2. Setup environnement local
export POSTGRES_HOST=localhost
export POSTGRES_PORT=5432

# 3. Activer venv
source .venv/bin/activate

# 4. Lancer API en local
cd api_pokemon
uvicorn main:app --reload --port 8000

# 5. Lancer Streamlit en local
cd interface
streamlit run app.py
```

---

## ğŸ¯ Configuration avancÃ©e

### Personnaliser le ML Pipeline

Ã‰diter `docker-compose.yml` section `ml_builder` :

```yaml
environment:
  # Skip training if model exists (faster restarts)
  ML_SKIP_IF_EXISTS: "true"  # false to force retrain
  
  # Mode: all, dataset, train, evaluate
  ML_MODE: "train"
  
  # Scenarios: best_move, random_move, all_combinations, all
  ML_SCENARIO_TYPE: "best_move"
  
  # GridSearch: true/false
  ML_TUNE_HYPERPARAMS: "true"
  
  # Grid: fast (8 combos) or extended (243 combos)
  ML_GRID_TYPE: "fast"
  
  # Random sampling
  ML_NUM_RANDOM_SAMPLES: "10"
  
  # Max combinations
  ML_MAX_COMBINATIONS: "50"
```

### DÃ©sactiver des services

```bash
# Ne pas lancer Streamlit
docker compose up --scale streamlit=0

# Ne pas lancer Monitoring
docker compose up --scale prometheus=0 --scale grafana=0 --scale node-exporter=0

# Ne pas lancer MLflow
docker compose up --scale mlflow=0
```

---

## âœ… Checklist de dÃ©ploiement

Avant de lancer `docker compose up --build` :

- [ ] Docker et Docker Compose installÃ©s
- [ ] Au moins 8GB RAM disponible
- [ ] Au moins 10GB espace disque
- [ ] Ports libres : 8000, 8501, 5000, 3000, 9090, 9100, 5432
- [ ] Connexion internet (pour pull images)
- [ ] Fichier `.env` crÃ©Ã© (optionnel)

AprÃ¨s le dÃ©marrage :

- [ ] Tous les services sont `Up` ou `Exited (0)` : `docker compose ps`
- [ ] API health check : `curl localhost:8000/health`
- [ ] Interface accessible : http://localhost:8501
- [ ] Grafana accessible : http://localhost:3000
- [ ] MLflow accessible : http://localhost:5000
- [ ] ModÃ¨les exportÃ©s : `ls models/battle_winner_*.pkl`

---

## ğŸ‰ DÃ©ploiement rÃ©ussi !

Si tous les services sont opÃ©rationnels, le projet est prÃªt :

âœ… **Base de donnÃ©es** remplie avec ~200 Pokemon  
âœ… **ModÃ¨le ML** entraÃ®nÃ© avec accuracy > 80%  
âœ… **API** exposant le modÃ¨le de prÃ©diction  
âœ… **Interface** utilisateur interactive  
âœ… **Monitoring** Prometheus + Grafana  
âœ… **MLflow** pour tracking des expÃ©riences  

**Tester l'application** :
1. Ouvrir http://localhost:8501
2. Aller sur "Compare" (page 2)
3. SÃ©lectionner 2 Pokemon
4. Voir la prÃ©diction du combat

---

**Auteur** : GitHub Copilot + drawile  
**Date** : 25 janvier 2026  
**Version** : 1.0 - Production Ready
