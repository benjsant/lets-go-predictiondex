"""
Scrapy settings for pokepedia_scraper

Projet pÃ©dagogique â€“ PokÃ©mon Let's Go (LGPE)
Objectif :
- Scraping responsable de PokÃ©pÃ©dia
- DonnÃ©es Ã©ducatives (mÃ©caniques PokÃ©mon)
- Conforme E1 (identification, robots.txt, logs, cache)

Auteur : Projet letsgo_predictiondex
"""

# ==================================================
# ðŸ§± Configuration de base Scrapy
# ==================================================

BOT_NAME = "pokepedia_scraper"

SPIDER_MODULES = ["pokepedia_scraper.spiders"]
NEWSPIDER_MODULE = "pokepedia_scraper.spiders"


# ==================================================
# ðŸ§‘â€ðŸ’» Identification claire du bot (IMPORTANT E1)
# ==================================================
# â†’ Transparence totale sur l'usage
# â†’ PokÃ©pÃ©dia peut identifier l'intention pÃ©dagogique

USER_AGENT = (
    "Mozilla/5.0 (X11; Linux x86_64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/120.0 Safari/537.36 "
    "(Educational project â€“ PokÃ©mon Let's Go data analysis)"
)


# ==================================================
# ðŸ¤– Respect strict des rÃ¨gles du site
# ==================================================

ROBOTSTXT_OBEY = True


# ==================================================
# ðŸ¢ Comportement humain / non agressif
# ==================================================
# Objectif :
# - Ne pas surcharger PokÃ©pÃ©dia
# - Simuler un utilisateur rÃ©el
# - Rester dans des seuils acceptables

CONCURRENT_REQUESTS = 8
CONCURRENT_REQUESTS_PER_DOMAIN = 2

DOWNLOAD_DELAY = 1.2
RANDOMIZE_DOWNLOAD_DELAY = True

DOWNLOAD_TIMEOUT = 15


# ==================================================
# ðŸ” Retry contrÃ´lÃ© (erreurs rÃ©seau uniquement)
# ==================================================
# Pas de spam :
# - Peu de retries
# - Seulement pour erreurs serveur ou timeout

RETRY_ENABLED = True
RETRY_TIMES = 2

RETRY_HTTP_CODES = [
    500, 502, 503, 504, 522, 524, 408
]


# ==================================================
# ðŸš¦ AutoThrottle (adaptation automatique)
# ==================================================
# Scrapy adapte la vitesse selon la rÃ©ponse du site

AUTOTHROTTLE_ENABLED = True
AUTOTHROTTLE_START_DELAY = 1.0
AUTOTHROTTLE_MAX_DELAY = 5.0
AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0
AUTOTHROTTLE_DEBUG = False


# ==================================================
# ðŸ§ª Pipelines (post-traitement des donnÃ©es)
# ==================================================
# Centralisation :
# - nettoyage
# - normalisation
# - futur stockage BDD

ITEM_PIPELINES = {
    "pokepedia_scraper.pipelines.PokemonMovePipeline": 300,
}


# ==================================================
# ðŸ’¾ Cache HTTP (ESSENTIEL pour PokÃ©pÃ©dia)
# ==================================================
# Objectifs :
# - Ã‰viter de re-scraper inutilement
# - RÃ©duire la charge serveur
# - AccÃ©lÃ©rer le dev / debug

HTTPCACHE_ENABLED = True
HTTPCACHE_EXPIRATION_SECS = 3600  # 1 heure
HTTPCACHE_DIR = "httpcache"

HTTPCACHE_IGNORE_HTTP_CODES = [
    500, 502, 503, 504
]

HTTPCACHE_STORAGE = (
    "scrapy.extensions.httpcache.FilesystemCacheStorage"
)


# ==================================================
# ðŸ“œ Logs propres et exploitables
# ==================================================

LOG_LEVEL = "INFO"


# ==================================================
# ðŸ“¤ Export & encodage
# ==================================================

FEED_EXPORT_ENCODING = "utf-8"


# ==================================================
# âš™ï¸ CompatibilitÃ© Scrapy moderne (>= 2.10)
# ==================================================

REQUEST_FINGERPRINTER_IMPLEMENTATION = "2.7"

TWISTED_REACTOR = (
    "twisted.internet.asyncioreactor.AsyncioSelectorReactor"
)
